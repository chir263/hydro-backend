    1  themes git:(master) ls
    2  themes
    3  sudo apt install fonts-powerline
    4  sudo vim ~/.oh-my-zsh/themes/agnoster.zsh-theme
    5  jaa
    6  chmod +x a.sh
    7  ./a.sh
    8  vim a.sh
    9  vim HelloWorld.java
   10  java HelloWorld.class
   11  java HelloWorld.java
   12  sudo apt install mysql
   13  sudo systemctl stop mysql
   14  sudo apt purge mysql-server mysql-client mysql-common mysql-server-core-* mysql-client-core-*\n
   15  sudo rm -rf /etc/mysql /var/lib/mysql /var/log/mysql
   16  sudo apt autoclean
   17  close
   18  njk
   19  oh my zsh
   20  matplotlib
   21  python -u "/media/chirag/DATA/CODE AMA/flask/iotproj/abc/main.py"
   22  cd "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/1/" && g++ q1.cpp -o q1 && "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/1/"q1
   23  gcc q9.c q9.s
   24  gcc q10.c q10.s
   25  gcc q11.c q11.s
   26  gcc q11.c q11.s -g
   27  cat
   28  cleat
   29  exxi
   30  cat q10.c
   31  gcc q2.c q2.s
   32  cd "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/2/" && g++ aa.cpp -o aa && "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/2/"aa
   33  gu
   34  gcc q6.c q6.s
   35  gcc q12.c q12.s
   36  man limits
   37  man limits.h
   38  man limit.h
   39  man limit
   40  touch abc.html
   41  xrandr
   42  xrandr | grep '*'
   43  cd "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/3/" && g++ q3.cpp -o q3 && "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/3/"q3
   44  cd "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/5/" && g++ q5.cpp -o q5 && "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/5/"q5
   45  pip install settings
   46  pip3 install settings
   47  python -u "/media/chirag/DATA/iot-project/abc (1) (1)/abc (1)/abc (1)/abc/abc/main.py"
   48  touch hl.cpp
   49  cd "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/5/" && g++ q5__.cpp -o q5__ && "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/5/"q5__
   50  hvh
   51  hvhjkvh
   52  cleart
   53  fasf
   54  Sds
   55  sd
   56  sdg
   57  dsgdsssssssss
   58  adkfdsfsdff
   59  fs
   60  s
   61  ddddd
   62  f
   63  d
   64  \\ndsf\\nsdf\\ndsf
   65  \ipython
   66  hbh
   67  habibi
   68  gcc
   69  gcc --version
   70  knj
   71  mknkj j j
   72  cat .zshrc
   73  nvim
   74  cd "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/6/" && g++ hll.cpp -o hll && "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/6/"hll
   75  gcc hl.cpp q6.cpp
   76  fsd
   77  {\n    int n;\n    cin >> n;\n    int arr[n];\n    for (int i = 0; i < n ;i ++)
   78  cd "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/6/" && g++ hl.cpp -o hl && "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/6/"hl
   79  cd "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/6/" && gcc a.c -o a && "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/6/"a
   80  cd "/media/chirag/DATA/CODE AMA/CP/" && g++ 1336A.cpp -o 1336A && "/media/chirag/DATA/CODE AMA/CP/"1336A
   81  cd "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/6/" && g++ q6.cpp -o q6 && "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/6/"q6
   82  g++ -g q6__.cpp 
   83  cd "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/6/" && g++ q6__.cpp -o q6__ && "/media/chirag/DATA/CODE AMA/SEM 2/dsa/assignment/ASSIGNMENT 5/6/"q6__
   84  sudo apt install atea
   85  sudo apt install steam
   86  sudo apt remove steam
   87  touch jquery
   88  sudo apt list --upgradable
   89  ./moss.pl main.c q4.c
   90  zoom
   91  0 0
   92  0 1
   93  1 1
   94  cd "/media/chirag/DATA/CODE AMA/CP/" && g++ 1701A.cpp -o 1701A && "/media/chirag/DATA/CODE AMA/CP/"1701A
   95  cd "/media/chirag/DATA/CODE AMA/CP/" && g++ 1701B.cpp -o 1701B && "/media/chirag/DATA/CODE AMA/CP/"1701B
   96  cd "/media/chirag/DATA/CODE AMA/CP/" && g++ 1701C.cpp -o 1701C && "/media/chirag/DATA/CODE AMA/CP/"1701C
   97  cd "/media/chirag/DATA/CODE AMA/CP/" && g++ 1699A.cpp -o 1699A && "/media/chirag/DATA/CODE AMA/CP/"1699A
   98  cd "/media/chirag/DATA/CODE AMA/CP/" && g++ 1699B.cpp -o 1699B && "/media/chirag/DATA/CODE AMA/CP/"1699B
   99  python main.oy
  100  node "/media/chirag/DATA/CODE AMA/javascript/nodejs/tutorial/osapp.js"
  101  node "/media/chirag/DATA/CODE AMA/javascript/nodejs/tutorial/pathapp.js"
  102  node "/media/chirag/DATA/CODE AMA/javascript/nodejs/tutorial/fsapp.js"
  103  node "/media/chirag/DATA/CODE AMA/javascript/nodejs/tutorial/fsappasync.js"
  104  node "/media/chirag/DATA/CODE AMA/javascript/nodejs/tutorial/httpapp.js"
  105  npm --
  106  npm --v
  107  node --versio
  108  sudo apt install nodejs
  109  sudo apt install npm
  110  npm install --global nodemon
  111  sudo npm install --global nodemon
  112  node "/media/chirag/DATA/CODE AMA/javascript/nodejs/tutorial/app.js"
  113  cd "/media/chirag/DATA/CODE AMA/javascript/nodejs/tutorial/" && g++ 1692A.cpp -o 1692A && "/media/chirag/DATA/CODE AMA/javascript/nodejs/tutorial/"1692A
  114  cd "/media/chirag/DATA/CODE AMA/javascript/nodejs/tutorial/" && g++ 1692B.cpp -o 1692B && "/media/chirag/DATA/CODE AMA/javascript/nodejs/tutorial/"1692B
  115  nodemon eventapp.js
  116  node cretebf.js
  117  node "/media/chirag/DATA/CODE AMA/javascript/nodejs/tutorial/createbf.js"
  118  nodemon streamapp.js
  119  git clone https://github.com/john-smilga/node-express-course.git
  120  cd '/media/chirag/DATA/CODE AMA/javascript/nodejs/project-johnsmilga/node-express-course/02-express-tutorial'
  121  npm install expree --save
  122  sudo npm install expree --save
  123  sudo npm install express --save
  124  sudo npm install express@4.17.1 -- save
  125  sudo npm install express@4.17.1
  126  nodemon '/media/chirag/DATA/CODE AMA/javascript/nodejs/project-johnsmilga/node-express-course/02-express-tutorial/app.js'
  127  sudo snap install postman
  128  postman
  129  pip install qrcode
  130  python -u "/media/chirag/DATA/CODE AMA/python/projects/qr code/main.py"
  131  pip install pil
  132  pip install pillow
  133  python readqr.py
  134  pip install PySide2
  135  pip uninstall PySide2
  136  python -u "/media/chirag/DATA/CODE AMA/ml/numpy/main.py"
  137  pip install pandas
  138  pip install lxml
  139  python -u "/media/chirag/DATA/CODE AMA/python/automation/table-extraction/tb-ex.py"
  140  ipython -u "/media/chirag/DATA/CODE AMA/python/automation/table-extraction/read-csv-from-web.py"
  141  python -u "/media/chirag/DATA/CODE AMA/python/automation/table-extraction/read-csv-from-web.py"
  142  pip install tk
  143  pip install ghostscript
  144  pip install camlot
  145  pip install camelot
  146  pip uninstall camelot
  147  pip install camelot-py
  148  pip uninstall camelot-py
  149  pip install camelot-py[cv]
  150  pip install "camelot-py[base]"
  151  python ex-pdf.py
  152  python -u "/media/chirag/DATA/CODE AMA/python/automation/table-extraction/ex-pdf.py"
  153  froll
  154  r 2021101100
  155  python -u "/media/chirag/DATA/CODE AMA/IIITH/ex-rolls.py"
  156  pip install pynput
  157  python find-roll.py
  158  touch find-roll.sh
  159  python find-roll.py 
  160  chmod +x find-roll.sh
  161  ./find-roll.sh asd asd
  162  zsh find-roll.sh asd asd
  163  bash find-roll.sh asd asd
  164  bash "/media/chirag/DATA/CODE AMA/IIITH/find-roll.sh"
  165  bash find-roll.sh asd asddsf
  166  bash find-roll.sh r 2021101100
  167  bash find-roll.sh
  168  bash find-roll.sh n *yash*
  169  bash find-roll.sh r #yash#
  170  bash find-roll.sh r 2021
  171  bash find-roll.sh n chirag
  172  bash find-roll.sh n chirag#
  173  bash find-roll.sh n yahs#
  174  bash find-roll.sh n yash#
  175  bash find-roll.sh n #yash#
  176  bash find-roll.sh n #chirag#
  177  python find-roll.py n chirag
  178  python find-roll.py n chirag#
  179  python find-roll.py n #chirag#
  180  python find-roll.py b #cse#
  181  python find-roll.py b #cse
  182  python find-roll.py b cse#
  183  python find-roll.py b #se
  184  python find-roll.py n #kawde
  185  python find-roll.py n jain#
  186  python find-roll.py n #jain
  187  python find-roll.py n #
  188  python find-roll.py n #2021101100
  189  python find-roll.py n 2021101100
  190  python find-roll.py r 2021101100
  191  python find-roll.py r 2021101100#
  192  python find-roll.py r #2021101100#
  193  python find-roll.py r #2021101100
  194  python -u "/media/chirag/DATA/CODE AMA/IIITH/find-roll.py"
  195  python find-roll.py r #1100
  196  python find-roll.py r $1100
  197  python find-roll.py r 1100
  198  python find-roll.py r *1100
  199  python find-roll.py r %1100
  200  bash find-roll.sh n %chirag%
  201  bash find-roll.sh r %chirag%
  202  bash find-roll.sh r %1100%
  203  bash find-roll.sh r %101100%
  204  bash find-roll.sh n yahs%
  205  bash find-roll.sh n yash%
  206  bash find-roll.sh n %jain
  207  roll21 12 312 3
  208  roll21 r 2021
  209  -
  210  ./zshrc
  211  .zshrc
  212  echo $ZSH_CUSTOM
  213  ls $ZSH_CUSTOM
  214  ls $ZSH_CUSTOM -al
  215  ls plugins
  216  cat example.zsh
  217  cd /home/chirag/.oh-my-zsh
  218  ls custom
  219  cat custom/example.zsh
  220  cat oh-my-zsh.sh
  221  cd plugins
  222  cd aliases
  223  cat aliases.plugin.zsh
  224  cd custom
  225  touch aliases.zsh
  226  roll21 n %vanshika
  227  roll21 n %vansh
  228  roll21 n %vanshika%
  229  roll21 n vanshika%
  230  roll21 %jain
  231  source ~/.zshrc
  232  roll21 n chr%
  233  roll21 n yath%
  234  roll21 n %gupta
  235  roll21 n %bansal
  236  roll21 n %goel
  237  roll21 n %goyal
  238  roll21 n %agarwal
  239  roll21 n %aggarwal
  240  roll21 n %wal%
  241  roll21 n chirag%
  242  roll21 n %vansh%
  243  roll21 n %garg%
  244  roll21 n %sai%
  245  bahs
  246  sudo apt-get install mongodb
  247  sudo service mongodb start
  248  virtualenv
  249  exit()\nasd
  250  exit\nasd
  251  git clone https://github.com/zsh-users/zsh-autosuggestions ~/.zsh/zsh-autosuggestions
  252  vim ~/.zshrc
  253  roll21 n harsh%
  254  aliases
  255  aliase
  256  al
  257  alias
  258  roll21 n chir%
  259  sudo apt uninstall mongodb
  260  sudo service mongodb stop
  261  sudo apt-get purge mongodb-org*
  262  sudo apt-get purge mongo*
  263  sudo apt-get purge mongodb mongodb-clients mongodb-server mongodb-dev
  264  sudo apt-get purge mongodb-10gen
  265  python -u "/media/chirag/DATA/CODE_AMA/ml/pandas/start.py"
  266  python -u "/media/chirag/DATA/CODE_AMA/ml/pandas/start2.py"
  267  python -u "/media/chirag/DATA/CODE_AMA/ml/matplotlib/plot_.py"
  268  python -u "/media/chirag/DATA/CODE_AMA/ml/seaborn/start.py"
  269  pip install selenium
  270  python -u "/media/chirag/DATA/CODE_AMA/python/automation/web-scraping/start.py"
  271  touch titanic.csv
  272  python -u "/media/chirag/DATA/CODE_AMA/ml/titanic eda/eda.py"
  273  cd /tmp && curl https://repo.anaconda.com/archive/Anaconda3-2021.11-Linux-x86_64.sh --output anaconda.sh
  274  rm -r tmp
  275  sudo rm -r tmp
  276  ls temp
  277  ls tmp
  278  pip install jupyter
  279  jupyter notebook --allow-root
  280  Jupyter notebook
  281  sudo apt remove jupyter
  282  sudo apt remove Jupyter
  283  pip uninstall jupyter
  284  rol
  285  cc
  286  touch 50_Startups.csv
  287  chromedriver
  288  path
  289  whereis chromedriver
  290  cd /media/chirag/DATA/chromedriver_linux64starter
  291  cd /media/chirag/DATA/chromedriver_linux64
  292  python -u "/media/chirag/DATA/CODE_AMA/selenium/starting_webdriver.py"
  293  python -u "/media/chirag/DATA/CODE_AMA/selenium/bot/main.py"
  294  roll21 r 1070
  295  roll21 r %1070
  296  roll21 b cse
  297  roll21 b 2%
  298  roll21 n %kumar
  299  roll21 n agra%
  300  roll21 n swayam%
  301  roll21 n %agra%
  302  neofetch
  303  sh
  304  roll21 n %bansal%
  305  roll21
  306  roll21 n rohan%
  307  cd .zshrc
  308  /.zshrc
  309  vim .zshrc
  310  history | grep autocomplete
  311  ims
  312  node populate.js
  313  node "/media/chirag/DATA/CODE_AMA/javascript/nodejs/project-johnsmilga/node-express-course/03-task-manager/starter/app.js"
  314  ip
  315  ip a
  316  node "/media/chirag/DATA/CODE_AMA/javascript/nodejs/project-johnsmilga/node-express-course/04-store-api/starter/populate.js"
  317  node "/media/chirag/DATA/CODE_AMA/regex/start.js"
  318  node "/media/chirag/DATA/CODE_AMA/regex/match-literal-string.js"
  319  node "/media/chirag/DATA/CODE_AMA/regex/wildcard-period.js"
  320  node "/media/chirag/DATA/CODE_AMA/regex/match-single-c-not-specified.js"
  321  node "/media/chirag/DATA/CODE_AMA/regex/lazy-matching.js"
  322  node "/media/chirag/DATA/CODE_AMA/regex/beginning-string-patterns.js"
  323  node "/media/chirag/DATA/CODE_AMA/regex/ending-string-pattern.js"
  324  node "/media/chirag/DATA/CODE_AMA/regex/match-all-letters-num.js"
  325  node "/media/chirag/DATA/CODE_AMA/regex/restrict-possible-username.js"
  326  node "/media/chirag/DATA/CODE_AMA/regex/match-whitespace.js"
  327  node "/media/chirag/DATA/CODE_AMA/regex/match-non-whitesp.js"
  328  node "/media/chirag/DATA/CODE_AMA/regex/specify-up-low.js"
  329  node "/media/chirag/DATA/CODE_AMA/regex/pos-neg-lookahead.js"
  330  node "/media/chirag/DATA/CODE_AMA/javascript/nodejs/project-johnsmilga/node-express-course/04-store-api/starter/app.js"
  331  cd 
  332  npx create-react-app tutorial
  333  cd jwtauth/server
  334  nodemon
  335  help nodemon
  336  nodemon --help
  337  express
  338  npm i bcryptjs cookie-parser cord dotenv express jsonwebtoken
  339  node "/media/chirag/DATA/CODE_AMA/javascript/JWT-Token/jwtauth/jwtauth/src/index.js"
  340  using namespace std;
  341  int main()\n{\n    int t;\n    cin >> t;\n    while (t--)\n    {\n        int n;\n        cin >> n;\n        int x = n - n / 2;\n        for (int i = n / 2; i >= 1; i--)
  342  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1711A.cpp -o 1711A && "/media/chirag/DATA/CODE_AMA/CP/"1711A
  343  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1698C.cpp -o 1698C && "/media/chirag/DATA/CODE_AMA/CP/"1698C
  344  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1703E.cpp -o 1703E && "/media/chirag/DATA/CODE_AMA/CP/"1703E
  345  010
  346  11100
  347  11011
  348  01011
  349  10011
  350  11000
  351  01000
  352  10101
  353  01010
  354  00010
  355  01001
  356  11001
  357  00000
  358  11111
  359  10110
  360  01111
  361  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1703D.cpp -o 1703D && "/media/chirag/DATA/CODE_AMA/CP/"1703D
  362  3
  363  x
  364  xx
  365  xxx
  366  8
  367  codeforc
  368  es
  369  codes
  370  forc
  371  forces
  372  e
  373  code
  374  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1703F.cpp -o 1703F && "/media/chirag/DATA/CODE_AMA/CP/"1703F
  375  python ma
  376  python main.py dsa
  377  python main.py dsa dsm cp
  378  python main.py dsa dsm cpro
  379  python main.py dsa grade dsm cpro
  380  python main.py dsa grd dsm cpro
  381  roll21 n aditya%
  382  python /media/chirag/DATA/CODE_AMA/IIITH/moodle_bot/main.py
  383  cd /path
  384  mood la
  385  mood la grd cso ps
  386  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 520B.cpp -o 520B && "/media/chirag/DATA/CODE_AMA/CP/"520B
  387  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 520B_.cpp -o 520B_ && "/media/chirag/DATA/CODE_AMA/CP/"520B_
  388  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 489C.cpp -o 489C && "/media/chirag/DATA/CODE_AMA/CP/"489C
  389  zsh --
  390  gnome-terminal --
  391  gnome-terminal -- echo rs
  392  gnome-terminal --tab -- zsh -c "asd"
  393  gnome-terminal --tab -- zsh -c "la"
  394  gnome-terminal -- zsh -c "la"
  395  gnome-terminal -- zsh 
  396  gnome-terminal -- mood
  397  zsh "mood"
  398  zsh -c "mood ra"
  399  zsh -c "mood"
  400  zsh -c "ls"
  401  zsh -c "la"
  402  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1714B.cpp -o 1714B && "/media/chirag/DATA/CODE_AMA/CP/"1714B
  403  mood at la grd cpro
  404  mood cso
  405  mood cso grd cpro la
  406  perl 
  407  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1714G.cpp -o 1714G && "/media/chirag/DATA/CODE_AMA/CP/"1714G
  408  python -u "/media/chirag/DATA/CODE_AMA/IIITH/moodle_bot/bot/console.py"
  409  python -u "/media/chirag/DATA/CODE_AMA/IIITH/moodle_bot/bot/moodle.py"
  410  9 1000 2000
  411  10 30 35
  412  1 1000000000 1000000000
  413  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1708B.cpp -o 1708B && "/media/chirag/DATA/CODE_AMA/CP/"1708B
  414  mood ve
  415  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 520C.cpp -o 520C && "/media/chirag/DATA/CODE_AMA/CP/"520C
  416  mood osna
  417  mood osn cpro
  418  mood osn cpro dsm la
  419  mood osn cpro grd dsm
  420  mood cpro gins
  421  mood dsm gins=lecture
  422  mood cpro grd gins=ass_1
  423  mood cpro gins=ass_1 grd
  424  mood cpro gins=ass_1
  425  mood cpro ins=ass_1
  426  mood osn ins=asS_1
  427  mood osn ins
  428  roll21 n keval%
  429  user.json
  430  touch user.json
  431  python -u "/media/chirag/DATA/CODE_AMA/IIITH/moodle_bot/main.py"
  432  mood ra 
  433  cpro
  434  pip install cryptography
  435  git statuus
  436  ..
  437  mood cpro dsm
  438  mood cpro grd
  439  mood cpro ins
  440  mood cpro ins=ass_3
  441  git commit -m "first version foor moodle bot"
  442  git commit -m "first version for moodle bot"
  443  git remote add origin https://github.com/chir263/IIITH-MOODLE-BOT.git
  444  mood at 
  445  mood osn ins=ass_1
  446  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ BITOBYT.cpp -o BITOBYT && "/media/chirag/DATA/CODE_AMA/CP/"BITOBYT
  447  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1713C.cpp -o 1713C && "/media/chirag/DATA/CODE_AMA/CP/"1713C
  448  mood os ins=ass_1
  449  cd "/media/chirag/DATA/CODE_AMA/SEM 3/osn/ASSIGNMENT/ASSIGNMENT 1/1/" && gcc q1.c -o q1 && "/media/chirag/DATA/CODE_AMA/SEM 3/osn/ASSIGNMENT/ASSIGNMENT 1/1/"q1
  450  ./q1
  451  gcc -g q1.c
  452  gcc -g q1.c -lm
  453  ./moss.pl q1_.c on.c
  454  man lseek
  455  gcc -g q1_.c -lm
  456  man write
  457  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 893C.cpp -o 893C && "/media/chirag/DATA/CODE_AMA/CP/"893C
  458  mood ra ins=ass_1
  459  cd "/media/chirag/DATA/CODE_AMA/SEM 3/osn/ASSIGNMENT/ASSIGNMENT 1/2/" && gcc q2_.c -o q2_ && "/media/chirag/DATA/CODE_AMA/SEM 3/osn/ASSIGNMENT/ASSIGNMENT 1/2/"q2_
  460  cd "/media/chirag/DATA/CODE_AMA/SEM 3/osn/ASSIGNMENT/ASSIGNMENT 1/2/" && gcc test.c -o test && "/media/chirag/DATA/CODE_AMA/SEM 3/osn/ASSIGNMENT/ASSIGNMENT 1/2/"test
  461  gcc -g q2_.c -lm
  462  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1106D.cpp -o 1106D && "/media/chirag/DATA/CODE_AMA/CP/"1106D
  463  cd "/media/chirag/DATA/CODE_AMA/CP/cc/starter51/" && g++ q6.cpp -o q6 && "/media/chirag/DATA/CODE_AMA/CP/cc/starter51/"q6
  464  2 4
  465  11
  466  3 3
  467  101
  468  gcc q2_.c -lm
  469  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 120F.cpp -o 120F && "/media/chirag/DATA/CODE_AMA/CP/"120F
  470  gcc -g 120F.cpp
  471  g++ -g 120F.cpp
  472  1912 1
  473  5 6
  474  999 1
  475  88 2
  476  12 100
  477  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1513C.cpp -o 1513C && "/media/chirag/DATA/CODE_AMA/CP/"1513C
  478  g++ -g 1519C.cpp
  479  g++ -g -Wall 1519C.cpp
  480  mood at ins=intr
  481  cd "/media/chirag/DATA/CODE_AMA/SEM 3/osn/ASSIGNMENT/ASSIGNMENT 1/3/" && gcc q3_.c -o q3_ && "/media/chirag/DATA/CODE_AMA/SEM 3/osn/ASSIGNMENT/ASSIGNMENT 1/3/"q3_
  482  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 212E.cpp -o 212E && "/media/chirag/DATA/CODE_AMA/CP/"212E
  483  gcc q3_.c -lm
  484  gcc q1_.c
  485  ./a.out sad/testaa
  486  gcc -g q1_.c
  487  ./a.out sad/testaa Assignment/1_testaa sad
  488  gcc -g q3_.c
  489  ./a.out sad/testaa Assignment/1_testaa abc
  490  gcc q2_.c
  491  ./a.out temp.txt 3 7
  492  ./a.out temp.txt
  493  cd "/media/chirag/DATA/CODE_AMA/SEM 3/osn/ASSIGNMENT/ASSIGNMENT 1/1/" && gcc test.c -o test && "/media/chirag/DATA/CODE_AMA/SEM 3/osn/ASSIGNMENT/ASSIGNMENT 1/1/"test
  494  ./a.out testaa
  495  tar -czvf file.tar.gz 2021101100_Assignment1
  496  tar -czvf 2021101100_Assignment1.tar.gz 2021101100_Assignment1
  497  tar -czvf 2021101100.tar.gz 2021101100_Assignment1
  498  perl
  499  perl -v
  500  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1720A.cpp -o 1720A && "/media/chirag/DATA/CODE_AMA/CP/"1720A
  501  0 1 228 179
  502  100 3 25 6
  503  999999999 300000000 666666666 100000000
  504  33 15 0 84
  505  mood at ins=pro
  506  dash
  507  mood aad ins=prob
  508  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 339D.cpp -o 339D && "/media/chirag/DATA/CODE_AMA/CP/"339D
  509  1 4
  510  mood at ins=6
  511  mood at ins=intro
  512  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1719C.cpp -o 1719C && "/media/chirag/DATA/CODE_AMA/CP/"1719C
  513  ./a.out f1 f2 ass
  514  man exit
  515  gcc ex.c -o ex
  516  gcc fork.c
  517  mood aad
  518  ./shell
  519  man wait
  520  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1359C.cpp -o 1359C && "/media/chirag/DATA/CODE_AMA/CP/"1359C
  521  python -u "/media/chirag/DATA/CODE_AMA/test.py"
  522  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1207C.cpp -o 1207C && "/media/chirag/DATA/CODE_AMA/CP/"1207C
  523  8 1 1
  524  00110010
  525  9 100000000 100000000
  526  010101010
  527  2 5 1
  528  00
  529  gcc main.c shellPrompt.c
  530  app install
  531  man chdir
  532  gcc main.c shellPrompt.c commands.c
  533  gcc main.c shellPrompt.c commands.c cd.c
  534  pwd asda
  535  gcc main.c shellPrompt.c commands.c cd.c pwd.c
  536  python -u "/media/chirag/DATA/CODE_AMA/SEM 3/automata/ASSIGNMENT 1/1/rule1.py"
  537  cd /media/chirag/DATA/CODE_AMA/SEM_3/osn/ASSIGNMENT/ASSIGNMENT_2/ASSIGNMENT2/s/
  538  echo $PWD
  539  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c l
  540  echo "'chirga'"
  541  at ins=sip
  542  python -u "/media/chirag/DATA/CODE_AMA/SEM_3/automata/ASSIGNMENT 1/1/q1/rule1.py"
  543  python rule1.py
  544  ls on.c
  545  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c
  546  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c
  547  touch history.txt
  548  gcc main.c history.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c 
  549  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c 
  550  cat history.txt
  551  echo sdsf    dsg g df  hg    fgh
  552  cd home
  553  cd ASSIGNMENT2
  554  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c
  555  echo sdfsfdsg  dsg sg dsg   commands.bjbhj
  556  echo asvsdb&
  557  echo dfsdf &
  558  sleep 4&
  559  sf
  560  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c
  561  touch main.py
  562  python rule.py
  563  tar -czvf 2021101100_mid.tar.gz 2021101100_mid
  564  ls command.c
  565  ls commanda.c
  566  ls commands.c
  567  ls -al commands.c
  568  ls -a commands.c
  569  ls -a commands.c -l pwd.c
  570  touch sad
  571  touch .sad
  572  sudo apt-get install xfce4-terminal
  573  claer
  574  zsh
  575  sql
  576  mod
  577  cd arduino
  578  cd Arduino
  579  touch a.js
  580  nodejs a.js
  581  cd "/media/chirag/DATA/CODE_AMA/CP/cc/starters54/" && g++ q5.cpp -o q5 && "/media/chirag/DATA/CODE_AMA/CP/cc/starters54/"q5
  582  at ins=ass
  583  quit
  584  mood at ins
  585  man find
  586  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c
  587  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discover.c
  588  .
  589  ./
  590  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c
  591  mood os
  592  discover
  593  vdsbdf
  594  ps -al
  595  ps -el
  596  echo safsasa; python
  597  sleep 4& echo hi
  598  sleep 5& echo hi
  599  ceef
  600  ee
  601  rff
  602  ./vsh
  603  ./a.
  604  gdb a.out
  605  asfa;asfasfasg;safgs
  606  man time_t
  607  man time
  608  sleep 2 &
  609  sleep 3 &
  610  gcc 
  611  gcc cshell.c
  612  gcc 4a.c
  613  gcc 4b.c
  614  gcc hw.c
  615  cd attr
  616  find . -regex '.*\.\(c\|cpp\|h\)$' -print
  617  find . -regex '.*/.*\.\(c\|cpp\|h\)$'
  618  cd map_files
  619  cat io
  620  cd task
  621  cd 7484
  622  mood ps ins=ann
  623  cd 1926
  624  cat status
  625  cat stat
  626  sleep 3 & sleep 6
  627  sleep 3&
  628  ls -l s
  629  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c -g
  630  README.md
  631  mak
  632  ./ma
  633  ./mai
  634  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 356A.cpp -o 356A && "/media/chirag/DATA/CODE_AMA/CP/"356A
  635  1 4 4
  636  python &
  637  vim &
  638  gedit&
  639  roll21 n %jain%
  640  mood at=ass
  641  mood at ins=ass
  642  touch dsu.cpp
  643  tar -czvf 2021101100_assign2.tar.gz 2021101100_assign2
  644  mood at
  645  ./moss.pl ls.c ls_.c
  646  ./moss.pl cd.c cd_.c
  647  ./moss.pl history.c history_.c
  648  ./moss.pl pinfo.c pinfo_.c
  649  ./moss.pl echo.c echo_.c
  650  ./moss.pl commands.c execute_com_.c
  651  ./moss.pl commands_.c execute_com.c
  652  cd "/media/chirag/DATA/CODE_AMA/SEM_3/automata/ASSIGNMENT 1/q2/" && g++ q2.cpp -o q2 && "/media/chirag/DATA/CODE_AMA/SEM_3/automata/ASSIGNMENT 1/q2/"q2
  653  cd "/media/chirag/DATA/CODE_AMA/SEM_3/automata/ASSIGNMENT 1/q2/" && g++ q2.cpp -o q2 -fsanitize=address && "/media/chirag/DATA/CODE_AMA/SEM_3/automata/ASSIGNMENT 1/q2/"q2 
  654  gcc q2.cpp -fsanitize=address
  655  gcc q2.cpp -g -fsanitize=address
  656  ./tsg
  657  ./tcg.sh
  658  ./tcg.sh 50
  659  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c -g -fsanitize=address -Wall
  660  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c -g -fsanitize=address
  661  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redir.c -g -fsanitize=address -Wall
  662  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redir.c -g -fsanitize=address
  663  pip install subprocess
  664  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redir.c redirection.c -g -fsanitize=address
  665  ./moss.pl redirection.c redirection_.c
  666  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c -g -fsanitize=address
  667  cd "/media/chirag/DATA/CODE_AMA/SEM_3/automata/ASSIGNMENT 1/q2/evalscript_auto/student_programs/2021101222/" && g++ q2.cpp -o q2 && "/media/chirag/DATA/CODE_AMA/SEM_3/automata/ASSIGNMENT 1/q2/evalscript_auto/student_programs/2021101222/"q2
  668  cd "/media/chirag/DATA/CODE_AMA/SEM_3/automata/ASSIGNMENT 1/q2/evalscript_auto/" && g++ test.cpp -o test && "/media/chirag/DATA/CODE_AMA/SEM_3/automata/ASSIGNMENT 1/q2/evalscript_auto/"test
  669  g++ q2.cpp -g -fsanitize=address
  670  ls -l > a.txt
  671  cat a.txt
  672  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c piping.c -g -fsanitize=address
  673  jobs -r
  674  ./moss.pl program.cpp rps.cpp
  675  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c piping.c -g 
  676  q
  677  bsh
  678  cd "/media/chirag/DATA/CODE_AMA/SEM_3/osn/ASSIGNMENT/ASSIGNMENT_2/new/ASSIGNMENT_2/2021101100_assign2/" && gcc test.c -o test && "/media/chirag/DATA/CODE_AMA/SEM_3/osn/ASSIGNMENT/ASSIGNMENT_2/new/ASSIGNMENT_2/2021101100_assign2/"test
  679  sudo apt-get install git build-essential libreadline-dev
  680  cd usr
  681  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c piping.c user_defined.c -g 
  682  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c piping.c user_defined.c -g  -rl
  683  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c piping.c user_defined.c -g  -l
  684  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c piping.c user_defined.c -g
  685  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c piping.c user_defined.c -g -lreadline -l
  686  mood at ins=sip
  687  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c piping.c user_defined.c -g -lreadline
  688  touch temp.c
  689  gcc temp.c
  690  gcc temp.c -lreadline
  691  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c piping.c user_defined.c autocomplete.c -g -lreadline
  692  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c piping.c user_defined.c autocomplete.c -g -fsanitize=address
  693  cd "/media/chirag/DATA/CODE_AMA/SEM_3/osn/ASSIGNMENT/ASSIGNMENT_2/new/ASSIGNMENT_2/2021101100_assign2/" && gcc input.c -o input && "/media/chirag/DATA/CODE_AMA/SEM_3/osn/ASSIGNMENT/ASSIGNMENT_2/new/ASSIGNMENT_2/2021101100_assign2/"input
  694  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c piping.c user_defined.c autocomplete.c -g 
  695  bash ./tcg.sh
  696  jobs
  697  gcc rps.cpp
  698  g++ rps.cpp
  699  python eval.py
  700  ps 27947
  701  ps
  702  echo chirag | cat
  703  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c piping.c user_defined.c autocomplete.c input.c -fsanitize=address -g 
  704  ls -al | head -3
  705  sudo mkdir -p /etc/apt/keyrings\n curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
  706  ^[[200~echo \\n  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\n  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null~
  707  echo \\n  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\n  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
  708  sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin
  709  apt-cache madison docker-ce
  710  sudo apt-get install docker-ce=<VERSION_STRING> docker-ce-cli=<VERSION_STRING> containerd.io docker-compose-plugin
  711  gcc main.c shellPrompt.c commands.c cd.c pwd.c echo.c ls.c pinfo.c history.c execute.c discovery.c redirection.c piping.c user_defined.c autocomplete.c input.c  -g 
  712  Dbash
  713  cat /proc/18386/stat
  714  cat /proc/18472/stat
  715  hkj
  716  sudo apt install apt-transport-https curl
  717  sudo curl -fsSLo /usr/share/keyrings/brave-browser-archive-keyring.gpg https://brave-browser-apt-release.s3.brave.com/brave-browser-archive-keyring.gpg
  718  echo "deb [signed-by=/usr/share/keyrings/brave-browser-archive-keyring.gpg arch=amd64] https://brave-browser-apt-release.s3.brave.com/ stable main"|sudo tee /etc/apt/sources.list.d/brave-browser-release.list\n
  719  sudo apt install brave-browser
  720  ./moss.pl redirection.c org.c
  721  m
  722  M
  723  ma
  724  cat *.c > out.c
  725  cat *.c > in.c
  726  ./moss.pl in.c out.c
  727  nano &
  728  roll21 r %1094
  729  roll21 r %1002
  730  roll21 r %1011
  731  roll21 r %1014
  732  roll21 r %1017
  733  roll21 r %1028
  734  roll21 r %1035
  735  roll21 r %1037
  736  roll21 r %1038
  737  roll21 r %1040
  738  roll21 r %1042
  739  roll21 r %1045
  740  roll21 r %1049
  741  roll21 r %1055
  742  roll21 r %1058
  743  roll21 r %1061
  744  roll21 r %1062
  745  ls chiragasds ASSIGNMENT_2
  746  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 101341A.cpp -o 101341A && "/media/chirag/DATA/CODE_AMA/CP/"101341A
  747  python q1/rule.py
  748  python q2/rule.py
  749  python q3/rule.py
  750  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 277A.cpp -o 277A && "/media/chirag/DATA/CODE_AMA/CP/"277A
  751  2 3 4
  752  2 4 5
  753  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 741B.cpp -o 741B && "/media/chirag/DATA/CODE_AMA/CP/"741B
  754  date
  755  sudo apt install wget ca-certificates
  756  wget --quiet -O - https://www.postgresql.org/media/keys/ACCC4CF8.asc
  757  sudo apt install postgresql postgresql-contrib
  758  sudo systemctl start postgresql.service
  759  psql
  760  sudo -i -u postgres
  761  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1446A.cpp -o 1446A && "/media/chirag/DATA/CODE_AMA/CP/"1446A
  762  7 12
  763  1 1 1 17 1 1 1
  764  ./arduino
  765  sudo apt-get install git build-essential gdb-multiarch qemu-system-misc gcc-riscv64-linux-gnu binutils-riscv64-linux-gnu \n
  766  sudo apt-get remove qemu-system-misc
  767  sudo apt-get install qemu-system-misc=1:4.2-3ubuntu6\n
  768  cat /etc/debian_version
  769  cd xv6-riscv-riscv
  770  git clone https://github.com/chir263/Codes.git
  771  cd C++
  772  cd "/media/chirag/DATA/CODE_AMA/hacktober/Codes/C++/" && g++ longest_increasing_subsequence.cpp -o longest_increasing_subsequence && "/media/chirag/DATA/CODE_AMA/hacktober/Codes/C++/"longest_increasing_subsequence
  773  git commit -m "Longest Increasing Subsequence added"
  774  touch pa.txt
  775  code longest_increasing_subsequence.c
  776  cd "/media/chirag/DATA/CODE_AMA/hacktober/Codes/C/" && gcc longest_increasing_subsequence.c -o longest_increasing_subsequence && "/media/chirag/DATA/CODE_AMA/hacktober/Codes/C/"longest_increasing_subsequence
  777  cd  Codes
  778  cd C
  779  git commit -m "Longest Increasing Subsequence in C added"
  780  cd c++
  781  code longest_increasing_subsequence.cpp
  782  git clone https://github.com/chir263/Hacktoberfeast-2022.git
  783  cd Hacktoberfeast-2022
  784  rm c++
  785  mkdir c++
  786  git commit -m "Longest Increasing Subsequence in C++ added"
  787  gcc main.c
  788  gcc main.c deque.c
  789  cd Hacktoberfest-2022
  790  git clone https://github.com/chir263/Hacktoberfest_2022.git
  791  cd Hacktoberfest_2022
  792  git checkout -b branch_queue_deque
  793  git commit -m "DEQUE implemented in C Linked-List added"
  794  git push origin branch_queue_deque
  795  git clone https://github.com/chir263/HACKTOBERFEST-2022.git
  796  cd HACKTOBERFEST-2022
  797  git checkout -b branch_dsa_lis
  798  cd DSA
  799  git push origin branch_dsa_lis
  800  git clone https://github.com/chir263/Hacktober-2022.git
  801  cd Hacktober-2022
  802  git checkout -b branch_snow_animat_js
  803  git commit -m "Snow animation in JS"
  804  git push origin branch_snow_animat_js
  805  git clone https://github.com/chir263/Hacktoberfest-2022_.git
  806  cd Hacktoberfest-2022_
  807  rmdit .git
  808  rmdir .git
  809  man rmdir
  810  ls -1l
  811  git clone https://github.com/chir263/Hacktoberfest-2023.git
  812  cd Hacktoberfest-2023
  813  git commit -m "Space Invader game in Python Pygame"
  814  git clone https://github.com/chir263/Hacktoberfest2022.git
  815  git commit -m "name in contributor list"
  816  git clone https://github.com/chir263/Codefornewccoder.git
  817  cd Codefornewccoder
  818  git checkout -b branch_cpp_lis
  819  git commit -m "Longest increasing subsequence"
  820  git push origin branch_cpp_lis
  821  git checkout -b branch_space_invader_py
  822  git commit -m "SPACE INVADER GAME IN PYTHON PYGAME"
  823  git push origin branch_space_invader_py
  824  la
  825  -ls
  826  git clone https://github.com/freyam/frxv6.git
  827  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1559D1.cpp -o 1559D1 && "/media/chirag/DATA/CODE_AMA/CP/"1559D1
  828  git commit -m "ADDED SYSCALLS STRACE, SIGALARM, SIGRETURN"
  829  git remote add origin https://github.com/chir263/osn_assign_4.git
  830  git commit -m "IMPLEMENTED PBS BUT NOT TESTED"
  831  git remote add upstream https://github.com/pranav-kirsur/xv6-assignment-os.git
  832  git pull upstream
  833  git clone https://github.com/AbhijnanVegi/xv6-tutorial.git
  834  man setpgid
  835  man waitpid
  836  man tcsetpgrp
  837  git clone https://github.com/liusy58/xv6.git
  838  touch a.c
  839  touch b.c
  840  ./moss.pl a.c b.c
  841  touch c.c
  842  ./moss.pl a.c b.c c.c
  843  echo $USER
  844  mood cso grd
  845  mood
  846  roll21 r %1072
  847  roll21 n %chir
  848  roll21 n %chir%
  849  roll21 n aman%
  850  roll21 n yash%
  851  roll21 n %yash%
  852  roll21 b cs%
  853  roll21 b c%
  854  java -jar cEncryptor InstallerC_KIT.jar
  855  java -jar cEncryptor Installer.jar
  856  java -jar "cEncryptor Installer.jar"
  857  java -jar CMesBox.jar
  858  mood esw
  859  git commit -m "some changes"
  860  mood ls grd
  861  roll21 n rhy%
  862  roll21 r %1100
  863  roll21 b e%
  864  cd $ZSH_CUSTOM
  865  vim aliases.zsh
  866  make qemu SCHEDULER=PBS
  867  make qemu SCHEDULER=FCFS
  868  make qemu SCHEDULER=MLFQ
  869  python plot.py
  870  tar -czvf osn_assign_4-master.tar.gz osn_assign_4-master
  871  git clone https://github.com/Tanvisn/ESW-Team-13.git
  872  npm install crypto-js
  873  npm audit
  874  java -jar iluVirus.jar
  875  cd "/media/chirag/DATA/CODE_AMA/CP/icpc16/" && g++ 1754C2.cpp -o 1754C2 && "/media/chirag/DATA/CODE_AMA/CP/icpc16/"1754C2
  876  sudo apt remove mysql-client-core-8.0
  877  rm -rf mysql
  878  mood ps ins=19
  879  use dna;
  880  sudo apt-get install --reinstall gnome-control-center
  881  gnome-control-center display
  882  gnome-control-center
  883  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1749C.cpp -o 1749C && "/media/chirag/DATA/CODE_AMA/CP/"1749C
  884  4 4 4 4
  885  1
  886  5
  887  1 3 2 1 1
  888  Chloe Scott
  889  sudo su
  890  man pthread_create
  891  sem_init
  892  man sem_init
  893  cd "/media/chirag/DATA/CODE_AMA/SEM_3/osn/ASSIGNMENT/assignment 5/" && gcc q1.c -o q1 && "/media/chirag/DATA/CODE_AMA/SEM_3/osn/ASSIGNMENT/assignment 5/"q1
  894  node app.js
  895  node start
  896  odsk\\ndfds
  897  gcc mutex.c -lpthread
  898  mood osn
  899  gcc q1a.c -lpthread
  900  ./server_prog.cpp
  901  man bzero
  902  man c_str
  903  g++ server_prog.cpp
  904  ./a.o
  905  ./a.out 1900
  906  ./a.out 1902
  907  cd "/media/chirag/DATA/CODE_AMA_old/SEM 2/dsa/assignment/ASSIGNMENT 5/4/" && g++ q4.cpp -o q4 && "/media/chirag/DATA/CODE_AMA_old/SEM 2/dsa/assignment/ASSIGNMENT 5/4/"q4
  908  g++ server.cpp
  909  ./a.out 1906
  910  ./a.out 1910
  911  ./a.out 1911
  912  ./a.out 1913
  913  ./a.out 1916
  914  ./a.out 1925
  915  ./a.out 1931
  916  g++ client_sim.cpp -o client
  917  g++ server_prog.cpp -o server
  918  ./a.out 1937
  919  ./a.out 1950
  920  ./a.out 1957
  921  ./a.out 1967
  922  ./a.out 1977
  923  ./a.out 1987
  924  ./a.out 1997
  925  ./a.out 2007
  926  ./a.out 2017
  927  ./a.out 2027
  928  ./a.out 2037
  929  g++ server.cpp -lpthread -fsanitize=address
  930  ./a.out 2042
  931  ./a.out 2047
  932  ./a.out 2052
  933  ./a.out 2057
  934  ./a.out 2062
  935  ./a.out 2067
  936  ./a.out 2072
  937  ./a.out 2077
  938  ./a.out 2082
  939  ./a.out 2087
  940  ./a.out 2102
  941  ./a.out 2107
  942  ./a.out 2112
  943  gdb a.out 2117
  944  ./a.out 2121
  945  gdb a.out 2122
  946  ./a.out 2126
  947  ./a.out 2132
  948  ./a.out 2137
  949  ./a.out 2142
  950  ./a.out 2147
  951  ./a.out 2152
  952  ./a.out 2157
  953  g++ -g server.cpp -lpthread 
  954  ./a.out 2162
  955  ./server
  956  ./server 2100
  957  g++ client.cpp -o cliennt
  958  ./server 2106
  959  ./server 2110
  960  ./server 2114
  961  ./server 2120
  962  ./server 2126
  963  ./server 2200
  964  ./server 2204
  965  g++ -g server.cpp -o server -lpthread 
  966  ./server 2210
  967  cd "/media/chirag/DATA/CODE_AMA/SEM_3/osn/ASSIGNMENT/assignment 5/q3/" && g++ test.cpp -o test && "/media/chirag/DATA/CODE_AMA/SEM_3/osn/ASSIGNMENT/assignment 5/q3/"test
  968  ./server 2215
  969  ./server 2300
  970  ./server 2305
  971  netstat
  972  ./server 2310
  973  ./server 2320
  974  g++ server.cpp -lpthread
  975  ./server 2325
  976  ./server 2330
  977  ./server 2335
  978  ./server 2340
  979  ./server 2345
  980  ./server 2350
  981  ./server 2355
  982  ./server 2360
  983  ./server 2365
  984  touch readme.md
  985  mood ra
  986  0 3 40
  987  ./server 2375 2385
  988  0 3 6
  989  3 4 6
  990  0 2 2
  991  2 5 1 
  992  ./server 12000 16000
  993  ./server 12010 16010
  994  ./server 21000 22000
  995  ./server 21500 22500
  996  pip install dash
  997  sudo pip install requests --upgrade
  998  touch post.json
  999  cd "/media/chirag/DATA/CODE_AMA/CP/lockout 2022/2/" && g++ c.cpp -o c && "/media/chirag/DATA/CODE_AMA/CP/lockout 2022/2/"c
 1000  ./server 2370 2380
 1001  ./server 2470 2480
 1002  ./server 2570 2580
 1003  ./server 2590 2600
 1004  ./server 2610 2620
 1005  ./server 2630 2640
 1006  ./server 2650 2660
 1007  ./server 2670 2680
 1008  ./server 2690 2700
 1009  ./server 2710 2720
 1010  0 2 50
 1011  1 2 15
 1012  2 3 20
 1013  ./server 2730 2740
 1014  ./server 2750 2760
 1015  ./server 2770 2780
 1016  ./server 2790 2800
 1017  ./server 2810 2820
 1018  ./server 2830 2840
 1019  ./server 2850 2860
 1020  ./server 2870 2880
 1021  ./server 2890 2900
 1022  ./server 2910 2920
 1023  ./server 2930 2940
 1024  ./server 2950 2960
 1025  ./server 2970 2980
 1026  ./server 2990 3000
 1027  ./server 3010 3020
 1028  ./server 3030 3040
 1029  ./server 3050 3060
 1030  ./server 3070 3080
 1031  tar -czvf 2021101100.tar.gz 2021101100
 1032  history 10
 1033  tar -czvf 2021101100.tar.gz 2021101100\n
 1034  gcc q1b.c -lpthread
 1035  g++ server.cpp -o server -lpthread
 1036  g++ client.cpp -o client
 1037  ./server 3090 3100
 1038  ./client
 1039  cd Sleep-Gang-iot-project-main
 1040  LS
 1041  gcc q1.c -lpthread
 1042  got init
 1043  git commit -m "esw_proj_backend"
 1044  git remote add origin https://github.com/chir263/esw_backend.git
 1045  cat .gitignore
 1046  git commit -m "esw_proj_backend_"
 1047  sudo ufw status
 1048  node -- v
 1049  curl https://cli-assets.heroku.com/install-ubuntu.sh | sh
 1050  heroku --version
 1051  heroku login
 1052  heroku login -i
 1053  heroku create eswapi
 1054  git commit -m "esw_proj_backend__"
 1055  git push --force origin master
 1056  git remote add origin https://git.heroku.com/eswapi.git
 1057  pip install pymysql
 1058  sudo nano /etc/mysql/my.cnf
 1059  sudo service mysql restart
 1060  pip import PrettyTable
 1061  pip install PrettyTable
 1062  python -u "/media/chirag/DATA/CODE_AMA/dna/DBconnection.py"
 1063  python -m pip install -U prettytable
 1064  sudo apt autoremove mysql
 1065  sudo apt autoremove mysql-server
 1066  sudo apt update && sudo apt upgrade
 1067  sudo apt autoremove
 1068  sudo apt install mysql-server
 1069  ^[[200~sudo /etc/init.d/mysql start
 1070  sudo /etc/init.d/mysql start\n
 1071  sudo mysql_secure_installation
 1072  sudo vim /etc/mysql/my.cnf
 1073  ^[[200~sudo service mysql restart
 1074  ~sudo service mysql restart\n
 1075  sudo service mysql restart\n
 1076  python -u "/media/chirag/DATA/CODE_AMA/dna/test.py"
 1077  python -u "/media/chirag/DATA/CODE_AMA/dna/functional_req.py"
 1078  mysql -uroot -pPassword1!
 1079  mysql -uroot -pPassword1! <dna.sql
 1080  cd videos
 1081  clea
 1082  cleara
 1083  python -u "/media/chirag/DATA/CODE_AMA/dna/main.py"
 1084  python flask-live-chart.py
 1085  make qemu
 1086  make clean
 1087  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1759E.cpp -o 1759E && "/media/chirag/DATA/CODE_AMA/CP/"1759E
 1088  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 982C.cpp -o 982C && "/media/chirag/DATA/CODE_AMA/CP/"982C
 1089  cd "/media/chirag/DATA/CODE_AMA/CP/binary_search/" && g++ a2.cpp -o a2 && "/media/chirag/DATA/CODE_AMA/CP/binary_search/"a2
 1090  cd "/media/chirag/DATA/CODE_AMA/CP/binary_search/" && g++ b2.cpp -o b2 && "/media/chirag/DATA/CODE_AMA/CP/binary_search/"b2
 1091  743
 1092  457
 1093  539
 1094  cd "/media/chirag/DATA/CODE_AMA/CP/binary_search/" && g++ b3.cpp -o b3 && "/media/chirag/DATA/CODE_AMA/CP/binary_search/"b3
 1095  get 3
 1096  union 2 3
 1097  get 2
 1098  union 1 3
 1099  union 4 5
 1100  union 4 1
 1101  get 5
 1102  cd "/media/chirag/DATA/CODE_AMA/CP/dsu/" && g++ a2.cpp -o a2 && "/media/chirag/DATA/CODE_AMA/CP/dsu/"a2
 1103  cd "/media/chirag/DATA/CODE_AMA/CP/dp/" && g++ prob2.cpp -o prob2 && "/media/chirag/DATA/CODE_AMA/CP/dp/"prob2
 1104  cd "/media/chirag/DATA/CODE_AMA/CP/dp/" && g++ prob2_query.cpp -o prob2_query && "/media/chirag/DATA/CODE_AMA/CP/dp/"prob2_query
 1105  fa
 1106  cd "/media/chirag/DATA/CODE_AMA/CP/2_pointers/" && g++ b7.cpp -o b7 && "/media/chirag/DATA/CODE_AMA/CP/2_pointers/"b7
 1107  cd "/media/chirag/DATA/CODE_AMA/CP/segtree/" && g++ a1.cpp -o a1 && "/media/chirag/DATA/CODE_AMA/CP/segtree/"a1
 1108  cd "/media/chirag/DATA/CODE_AMA/CP/dp/" && g++ a3.cpp -o a3 && "/media/chirag/DATA/CODE_AMA/CP/dp/"a3
 1109  cd abc
 1110  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ klees_algo.cpp -o klees_algo && "/media/chirag/DATA/CODE_AMA/CP/"klees_algo
 1111  cd "/media/chirag/DATA/CODE_AMA/CP/dsu/" && g++ b3_sol2.cpp -o b3_sol2 && "/media/chirag/DATA/CODE_AMA/CP/dsu/"b3_sol2
 1112  sudo dmidecode -t memory
 1113  touch new
 1114  code new
 1115  g++ 3.cpp
 1116  cd "/media/chirag/DATA/CODE_AMA/CP/dp/atcoder/" && g++ m.cpp -o m && "/media/chirag/DATA/CODE_AMA/CP/dp/atcoder/"m
 1117  cd "/media/chirag/DATA/CODE_AMA/CP/dp/" && g++ 1726C.cpp -o 1726C && "/media/chirag/DATA/CODE_AMA/CP/dp/"1726C
 1118  sudo apt-get install gnome-power-manager
 1119  cd "/media/chirag/DATA/CODE_AMA/CP/CSES/dp/" && g++ mini_coins.cpp -o mini_coins && "/media/chirag/DATA/CODE_AMA/CP/CSES/dp/"mini_coins
 1120  g++ coin_comb2.cpp -Wall
 1121  cd "/media/chirag/DATA/CODE_AMA/CP/CSES/dp/" && g++ coin_comb2.cpp -o coin_comb2 && "/media/chirag/DATA/CODE_AMA/CP/CSES/dp/"coin_comb2
 1122  cd "/media/chirag/DATA/CODE_AMA/CP/CSES/dp/" && g++ array_desc.cpp -o array_desc && "/media/chirag/DATA/CODE_AMA/CP/CSES/dp/"array_desc
 1123  cd "/media/chirag/DATA/CODE_AMA/CP/CSES/dp/" && g++ two_sets11.cpp -o two_sets11 && "/media/chirag/DATA/CODE_AMA/CP/CSES/dp/"two_sets11
 1124  cd "/media/chirag/DATA/CODE_AMA/CP/CSES/dp/" && g++ weighted_int_sched.cpp -o weighted_int_sched && "/media/chirag/DATA/CODE_AMA/CP/CSES/dp/"weighted_int_sched
 1125  cd "/media/chirag/DATA/CODE_AMA/CP/divisiblity/" && g++ a.cpp -o a && "/media/chirag/DATA/CODE_AMA/CP/divisiblity/"a
 1126  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1730B.cpp -o 1730B && "/media/chirag/DATA/CODE_AMA/CP/"1730B
 1127  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 677B.cpp -o 677B && "/media/chirag/DATA/CODE_AMA/CP/"677B
 1128  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1766D.cpp -o 1766D && "/media/chirag/DATA/CODE_AMA/CP/"1766D
 1129  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 518D.cpp -o 518D && "/media/chirag/DATA/CODE_AMA/CP/"518D
 1130  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1553C.cpp -o 1553C && "/media/chirag/DATA/CODE_AMA/CP/"1553C
 1131  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1680C.cpp -o 1680C && "/media/chirag/DATA/CODE_AMA/CP/"1680C
 1132  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1349A.cpp -o 1349A && "/media/chirag/DATA/CODE_AMA/CP/"1349A
 1133  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 920E.cpp -o 920E && "/media/chirag/DATA/CODE_AMA/CP/"920E
 1134  g++ c4_bfs.cpp -fsanitize
 1135  cd "/media/chirag/DATA/CODE_AMA/CP/binary_search/" && g++ c4_bfs.cpp -o c4_bfs && "/media/chirag/DATA/CODE_AMA/CP/binary_search/"c4_bfs
 1136  g++ c4_bfs.cpp -fsanitize=address
 1137  cd "/media/chirag/DATA/CODE_AMA/CP/binary_search/" && g++ 1242B.cpp -o 1242B && "/media/chirag/DATA/CODE_AMA/CP/binary_search/"1242B
 1138  cd "/media/chirag/DATA/CODE_AMA/CP/CSES/soorting/" && g++ apartments.cpp -o apartments && "/media/chirag/DATA/CODE_AMA/CP/CSES/soorting/"apartments
 1139  cd "/media/chirag/DATA/CODE_AMA/CP/CSES/soorting/" && g++ concert_ticket.cpp -o concert_ticket && "/media/chirag/DATA/CODE_AMA/CP/CSES/soorting/"concert_ticket
 1140  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 385C.cpp -o 385C && "/media/chirag/DATA/CODE_AMA/CP/"385C
 1141  7
 1142  20 20
 1143  8 13
 1144  13 13
 1145  6 14
 1146  3 5
 1147  15 17
 1148  341 1792
 1149  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1176E.cpp -o 1176E && "/media/chirag/DATA/CODE_AMA/CP/"1176E
 1150  cd "/media/chirag/DATA/CODE_AMA/CP/CSES/soorting/" && g++ Towers.cpp -o Towers && "/media/chirag/DATA/CODE_AMA/CP/CSES/soorting/"Towers
 1151  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1497E.cpp -o 1497E && "/media/chirag/DATA/CODE_AMA/CP/"1497E
 1152  cd "/media/chirag/DATA/CODE_AMA/CP/CSES/graphs/" && g++ counting_rooms.cpp -o counting_rooms && "/media/chirag/DATA/CODE_AMA/CP/CSES/graphs/"counting_rooms
 1153  roll21 n ayan%
 1154  cd s
 1155  cd starter
 1156  cd jss
 1157  node a.js
 1158  touch index.js
 1159  code.
 1160  npm install 
 1161  touch .env
 1162  cd react-course-v3-main
 1163  npx create-react-app@latest backroads-app
 1164  npm install & npm start
 1165  cd se
 1166  cd setup
 1167  cd "/media/chirag/DATA/CODE_AMA/CP/CSES/soorting/" && g++ 1056D.cpp -o 1056D && "/media/chirag/DATA/CODE_AMA/CP/CSES/soorting/"1056D
 1168  chmod +x moss.pl
 1169  ./moss.pl ques.c try.c
 1170  cd "/media/chirag/DATA/" && gcc aak.c -o aak && "/media/chirag/DATA/"aak
 1171  gcc aak.c
 1172  ./a.out
 1173  cd "/media/chirag/DATA/" && g++ tst.cpp -o tst && "/media/chirag/DATA/"tst
 1174  mkdir abc
 1175  16 17 14 20 20 11 22
 1176  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1324E.cpp -o 1324E && "/media/chirag/DATA/CODE_AMA/CP/"1324E
 1177  cd "/media/chirag/DATA/CODE_AMA/CP/csoc_2021/dp/" && g++ i.cpp -o i && "/media/chirag/DATA/CODE_AMA/CP/csoc_2021/dp/"i
 1178  npx create-react-app setup-antd frontend
 1179  yarn
 1180  yarn add antd
 1181  npm install antd
 1182  npx create-react-app@16.2.1 frontend
 1183  npx create-react-app@v16.2.1 frontend
 1184  npx create-react-app@v16.1.0 frontend
 1185  npx create-react-app@16.1.0 frontend
 1186  npx create-react-app@16 frontend
 1187  cd fr
 1188  npm install @mui/material @mui/styled-engine-sc styled-components
 1189  npm install @material-ui/core
 1190  npm install @mui/icons-material
 1191  hrop
 1192  ^[[200~npm install @mui/material @emotion/react @emotion/styled --legacy-peer-deps~
 1193  [200~npm install @mui/material @emotion/react @emotion/styled --legacy-peer-deps~
 1194  npm install @mui/material @emotion/react @emotion/styled --legacy-peer-deps
 1195  npm install @mui/icons-material --legacy-peer-deps
 1196  npm sr
 1197  npm install axios
 1198  npm install react-router-dom
 1199  npm
 1200  cd "/media/chirag/DATA/CODE_AMA/CP/CSES/soorting/" && g++ sliding_median_set.cpp -o sliding_median_set && "/media/chirag/DATA/CODE_AMA/CP/CSES/soorting/"sliding_median_set
 1201  npm test
 1202  git commit -m "dass_as1__backend__"
 1203  git remote add origin https://github.com/chir263/dass_as1_backend.git
 1204  git commit -m "dass_as1__backend__2"
 1205  git commit -m "dass_as1__backend__3"
 1206  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 219D.cpp -o 219D && "/media/chirag/DATA/CODE_AMA/CP/"219D
 1207  npm install @material-ui/icons
 1208  npm install @material-ui/icons-material
 1209  pws
 1210  node "/media/chirag/DATA/CODE_AMA/dass/assignment 1/frontend/frontend/src/test.js"
 1211  npm npm start
 1212  git commit -m "dass_as1__backend__4"
 1213  git commit -m "dass_as1__backend__5"
 1214  git commit -m "dass_as1__backend__6"
 1215  git st
 1216  git commit -m "dass_as1__frontend__1"
 1217  git remote add origin https://github.com/chir263/dass_as1_frontend.git
 1218  npm s
 1219  node "/media/chirag/DATA/CODE_AMA/dass/assignment 1/frontend/frontend/src/Pages/dashboard/components/sidebar/test.js"
 1220  git commit -m "dass_as1__frontend__2"
 1221  git commit -m "dass_as1__backend__7"
 1222  git commit -m "dass_as1__frontend__3"
 1223  git commit -m "dass_as1__backend__8"
 1224  git commit -m "dass_as1__frontend__4"
 1225  pip install PIL
 1226  pip install Pillow
 1227  python -u "/media/chirag/DATA/CODE_AMA/science2/ass1/q1.py"
 1228  python -u "/media/chirag/DATA/CODE_AMA/science2/ass1/q3.py"
 1229  python -u "/media/chirag/DATA/CODE_AMA/science2/ass1/q4.py"
 1230  node "/media/chirag/DATA/CODE_AMA/dass/assignment 1/backend/controllers/test.js"
 1231  npm install @coreui/react-chartjs
 1232  npm install recharts
 1233  git commit -m "dass_as1__frontend__5"
 1234  git commit -m "dass_as1__backend__9"
 1235  git commit -m "dass_as1__frontend__6"
 1236  git commit -m "dass_as1__frontend__7"
 1237  git commit -m "dass_as1__frontend__8"
 1238  git commit -m "dass_as1__frontend__9"
 1239  npm install fuse.js
 1240  cd "/media/chirag/DATA/CODE_AMA/CP/CSES/tree_algo/" && g++ TreeDistancesI.cpp -o TreeDistancesI && "/media/chirag/DATA/CODE_AMA/CP/CSES/tree_algo/"TreeDistancesI
 1241  python -u "/media/chirag/DATA/CODE_AMA/science2/ass1/1/q1.py"
 1242  python -u "/media/chirag/DATA/CODE_AMA/science2/ass1/3/q3.py"
 1243  touch pass
 1244  no
 1245  npm install && npm start
 1246  sudo kill $(sudo lsof -t -i:5005)
 1247  git commit -m "dass_as1__backend__10"
 1248  git commit -m "dass_as1__frontend__10"
 1249  cd "/media/chirag/DATA/CODE_AMA/CP/CSES/tree_algo/" && g++ finwick_tree.cpp -o finwick_tree && "/media/chirag/DATA/CODE_AMA/CP/CSES/tree_algo/"finwick_tree
 1250  cd "/media/chirag/DATA/CODE_AMA/CP/segtree/" && g++ b1.cpp -o b1 && "/media/chirag/DATA/CODE_AMA/CP/segtree/"b1
 1251  4 3
 1252  3 -1
 1253  cd "/media/chirag/DATA/CODE_AMA/CP/segtree/" && g++ b2.cpp -o b2 && "/media/chirag/DATA/CODE_AMA/CP/segtree/"b2
 1254  2 0
 1255  2 1
 1256  2 2
 1257  1 2
 1258  1 0
 1259  python -u "/media/chirag/DATA/CODE_AMA/mdl/MDL_Assignment2/2.3/2.3.1.ipynb"
 1260  python -u "/media/chirag/DATA/CODE_AMA/mdl/MDL_Assignment2/2.3/bonus.ipynb"
 1261  npm install socket.io-client
 1262  jupyter  notebook
 1263  cd .. ;cd ..
 1264  cd atom-cms
 1265  npm install -g typescript
 1266  sudo npm install -g typescript
 1267  tsc -v
 1268  ts-node "/media/chirag/DATA/CODE_AMA/dass/project/typescript/intro.ts"
 1269  tcs intro.ts
 1270  tsc intro.ts
 1271  sudo kill -9 $(sudo lsof -t -i:5005)
 1272  cd frontend; cd frontend
 1273  cd socket
 1274  cd ..;cd frontend;cd frontend
 1275  cd ..;cd ..;cd socket
 1276  sudo apt remove docker-desktop
 1277  sudo apt-install docker.io
 1278  npm install socket.io
 1279  git commit -m "dass_as1__backend__1"
 1280  git commit -m "dass_as1__frontend__11"
 1281  git commit -m "dass_as1__frontend__12"
 1282  git commit -m "dass_as1__frontend__13"
 1283  node --v
 1284  sudo systemctl status docker
 1285  sudo apt install docker-compose
 1286  sudi docker-compose up
 1287  nim .env
 1288  vim .env
 1289  npm version
 1290  docker-compose up
 1291  python -u "/media/chirag/DATA/CODE_AMA/science2/ass2/q2.py"
 1292  python -u "/media/chirag/DATA/CODE_AMA/science2/ass2/q3.py"
 1293  CO
 1294  python -u "/media/chirag/DATA/CODE_AMA/science2/ass2/q1.py"
 1295  python -u "/media/chirag/DATA/CODE_AMA/science2/ass2/1/q1.py"
 1296  python -u "/media/chirag/DATA/CODE_AMA/science2/ass2/2/q2.py"
 1297  python -u "/media/chirag/DATA/CODE_AMA/science2/ass2/3/vin.py"
 1298  python -u "/media/chirag/DATA/CODE_AMA/science2/ass2/3/q3.py"
 1299  hardinfo
 1300  git config
 1301  git config --global
 1302  git config --global user.name
 1303  pip install --user --upgrade cookiecutter
 1304  nvm
 1305  wget -qO- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.3/install.sh | bash
 1306  sudo apt install curl 
 1307  curl https://raw.githubusercontent.com/creationix/nvm/master/install.sh | bash 
 1308  source ~/.bashrc 
 1309  nvm --version
 1310  npm install -g yo
 1311  sudo npm install -g yo
 1312  npm install yarn@3
 1313  npm install yarn
 1314  sudo npm install -g corepack
 1315  corepack prepare yarn@stable --activate
 1316  yarn -v
 1317  mkdir my_project;\ncd my_project
 1318  sudo cookiecutter https://github.com/collective/cookiecutter-plone-starter
 1319  pipx install virtualenv
 1320  pip install virtualenv
 1321  cookiecutter --version
 1322  cookiecutter https://github.com/collective/cookiecutter-plone-starter
 1323  mkdir training
 1324  cd training
 1325  sudo make build
 1326  rm rm -fr .git
 1327  git clone https://gitlab.com/chir263/atom-cms.git
 1328  git remote add origin https://gitlab.com/chir263/atom-cms.git
 1329  git checkout -b r1_submission_v1.0
 1330  git commit -m "R1 V1.0 submission"
 1331  npm install;npm start
 1332  sudo apt install python3.8-venv
 1333  cd .ssh
 1334  nim id_ed25519
 1335  vim known_hosts
 1336  rm id_ed25519.pub
 1337  rm id_ed25519
 1338  ssh-keygen -t ed25519 -C "jainchirag263@gmail.com"
 1339  eval "$(ssh-agent -s)"
 1340  ssh-add ~/.ssh/id_ed25519
 1341  vim id_ed25519.pub
 1342  vim id_ed25519
 1343  find buildout
 1344  find -la buildout.cfg
 1345  find buildout.cfg
 1346  cd instance
 1347  cd etc
 1348  cd var
 1349  cd log
 1350  cd cache
 1351  cd filestorage
 1352  cd site
 1353  cd python3.8
 1354  cd lib
 1355  cd share
 1356  cd ..;cd ..
 1357  /usr/local/Plone/venv/bin/addzopeuser
 1358  cd /usr/local/Plone/venv/bin/addzopeuser
 1359  cd /usr
 1360  cd /local/Plone/venv/bin/addzopeuser
 1361  cd /local/Plone/venv/
 1362  cd /local/Plone/
 1363  cd /local
 1364  cd local/Plone/venv/bin/addzopeuser
 1365  cd local/Plone
 1366  cd local
 1367  git clone https://github.com/collective/training_buildout.git backend
 1368  make build
 1369  sudo apt install kazam
 1370  sudo apt install python3-cairo python3-xlib
 1371  git push -u origin r1_submission_v1.0
 1372  clone https://gitlab.com/DASS2k23/DASS2k23-Team-3.git
 1373  git commit -m "R1 V1.0 submission updated"
 1374  git remote add origin https://gitlab.com/DASS2k23/DASS2k23-Team-3.git
 1375  git fetch origin dev
 1376  git merge origin dev
 1377  git push -u --force origin dev
 1378  python -u "/media/chirag/DATA/2021101100_assign2 (1)/2021101100_assign2/code.ipynb"
 1379  mvabc .abc
 1380  docker-compose up build
 1381  docker-compose up --build
 1382  docker build
 1383  docker-build
 1384  docker-compose build
 1385  sudo docker-compose build
 1386  sudo docker-compose up
 1387  npx create-react-app airtable-api
 1388  npm i airtable styled-components
 1389  git clone https://github.com/codeSTACKr/goal-manager-react.git
 1390  npm i use-airtable
 1391  npm install --save airtable use-airtable
 1392  npm install --save airtable use-airtable-crud
 1393  npm install use-airtable-crud
 1394  python -u "/home/chirag/.cache/.fr-EqBh1B/ass1/1/q1.py"
 1395  python -u "/home/chirag/.cache/.fr-Zn0Kry/ass1/3/q3.py"
 1396  python -u "/home/chirag/.cache/.fr-tprAfz/ass1/4/q4.py"
 1397  python -u "/home/chirag/.cache/.fr-KH0KVy/ass2/1/q1.py"
 1398  python -u "/home/chirag/.cache/.fr-6hh7By/ass2/3/q3.py"
 1399  python q2.py
 1400  python q4.py
 1401  python q3.py
 1402  mv abc .abc
 1403  mv .abc abc
 1404  npm i global-time@1.5.1
 1405  npm i global-time@latest
 1406  git checkout -b phase1
 1407  git commit -m "Phase 1"
 1408  git push -u phase1
 1409  git push -u origin phase1
 1410  npx create react-app proj
 1411  touch dass.txt
 1412  npx create-react-app project
 1413  npm install paraphrase
 1414  npm uninstall paraphrase
 1415  npm install papaparse
 1416  touch temp.csv
 1417  roll21 n s%
 1418  mood ps
 1419  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1625C.cpp -o 1625C && "/media/chirag/DATA/CODE_AMA/CP/"1625C
 1420  npx create-react-app test-drag
 1421  cd test-drag
 1422  git clone --single-branch --branch part-0-starting-point git@github.com:colbyfayock/my-final-space-characters.git
 1423  npm install; npm start
 1424  touch _redirects
 1425  5 4 1
 1426  1 5 4 3 2
 1427  5 4 4
 1428  10 20 30 40 50
 1429  10 7 3
 1430  4 6 8 2 9 9 7 4 10 9
 1431  1\n5 4 4\n10 20 30 40 50
 1432  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1389B.cpp -o 1389B && "/media/chirag/DATA/CODE_AMA/CP/"1389B
 1433  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1389B_rec.cpp -o 1389B_rec && "/media/chirag/DATA/CODE_AMA/CP/"1389B_rec
 1434  npm install react-beautiful-dnd
 1435  npm uninstall react-beautiful-dnd
 1436  npm install react-beautiful-dnd@13.0.0
 1437  git checkout -b phase2
 1438  git commit -m "Phase 2"
 1439  git commit -m "Phase 2.1"
 1440  git push -u origin phase2
 1441  touch lab3.html
 1442  touch data.tsv
 1443  spotify
 1444  sudo remove spotify
 1445  sudo uninstall spotify
 1446  sudo apt-remove spotify
 1447  python replay.py
 1448  mkdir lec[2..60]
 1449  mkdir s{2..50}
 1450  mkdir lec{2..50}
 1451  node data.js
 1452  cd world-map
 1453  touch abc
 1454  git commit -m "first commit"\n
 1455  aaaaa
 1456  python -u "/media/chirag/DATA/CODE_AMA/dass/assignment4/DASS_A3_codebase/DASS_A3_codebase/src/test.py"
 1457  git commit -m "second commit"\n
 1458  python test_bonus.py
 1459  python q1.py
 1460  python -u "/media/chirag/DATA/CODE_AMA/mdl/assign3/q1.py"
 1461  make start
 1462  git commit -m "Shell"
 1463  git remote add origin https://github.com/chir263/dataVis-project.git
 1464  git remove origin
 1465  git remote add origin https://github.com/chir263/Cshell.git
 1466  git commit -m "frontend"
 1467  git commit -m "MERN"
 1468  python -u "/media/chirag/DATA/CODE_AMA/mdl/2021101100/2021101100.py"
 1469  python -u "/home/chirag/.cache/.fr-WVwRTj/2021101100/2021101100.py"
 1470  rm .git
 1471  rmdir -p .git
 1472  rmdir -a .git
 1473  rmdir --help
 1474  rmdir -v .git
 1475  rm -r .git
 1476  rm .gitignore 
 1477  git commit -m "MERN1"
 1478  git remote add origin https://github.com/chir263/MERN_APP.git
 1479  kill
 1480  help kill
 1481  man help
 1482  man kill
 1483  kjbb
 1484  man scandir
 1485  cd 2021101100_assign3
 1486  git commit -m "commit"
 1487  man setpgrp
 1488  cd proc
 1489  python -u "/media/chirag/DATA/Bio_slides/Bio_slides/test.py"
 1490  touch pat
 1491  git clone https://gitlab.com/DASS2k23/DASS2k23-Team-3.git
 1492  cd DASS2k23-Team-3
 1493  git clone --branch dev https://gitlab.com/DASS2k23/DASS2k23-Team-3.git
 1494  git branch -a
 1495  git commit -m "final"
 1496  git push -u origin master --force
 1497  git commit -m "R2 SUBMISSION FINAL"
 1498  touch prestation.txt
 1499  c
 1500  rmdir -r .git
 1501  rmdir -rf .git
 1502  git commit -m "DV PROJ SUBMISSION FINAL"
 1503  git remote add origin https://github.com/chir263/DataVisualizationProject.git
 1504  vim game.py
 1505  touch __init__.py
 1506  ls src
 1507  python game.py
 1508  git internals
 1509  git init internals
 1510  cd internals
 1511  git commit -m "create empty dir"
 1512  git show e69de
 1513  git show 6e60
 1514  git show f93e
 1515  git ls-tree f9
 1516  git ls-tree f93e
 1517  sudo apt install gitk
 1518  gitk
 1519  cat .git/refs/heads/master
 1520  git show --pretty=raw 6e60
 1521  git commit -m "FINAL UPDATE"
 1522  git remote add origin https://github.com/chir263/DNA_Project.git
 1523  git push --force -u origin master
 1524  cd "/media/chirag/DATA/CODE_AMA/CP/interviewbit/" && g++ large_fact.cpp -o large_fact && "/media/chirag/DATA/CODE_AMA/CP/interviewbit/"large_fact
 1525  npm install -g npm
 1526  sudo npm install -g npm
 1527  nvm list available
 1528  npm install -g node
 1529  sudo npm install -g node
 1530  sudo npm cache clean -f
 1531  sudo npm install -g n
 1532  sudo n stable
 1533  npx dalai alpaca install 7B
 1534  sudo apt-get install build-essential python3-venv -y
 1535  npx dalai llama install 7B
 1536  npx dalai serve
 1537  npm uninstall dalai
 1538  npm uninstall --save-dev dalai
 1539  npm uninstall --save-dev dalai llama
 1540  npm uninstall --save-dev alpaca
 1541  npm uninstall alpaca
 1542  npm uninstall dalai alpaca
 1543  dalai
 1544  git clone https://gitlab.com/vlead-projects/summer-internship-2023.git
 1545  git commit -m "Chirag May 15 Update"
 1546  git clone https://github.com/kevin-powell/JAMStack-blog-starter.git
 1547  git clone https://github.com/chir263/repo-template.git
 1548  npm install @11ty/eleventy --save-dev
 1549  git commit -m "commit 1"
 1550  pip install langchain
 1551  pip install openai
 1552  pip install huggingface_hub
 1553  pip install nomic
 1554  pip install pygpt1all
 1555  pip install pygpt4all
 1556  cd .nomic
 1557  rm gpt4all
 1558  rm gpt4all-lora-quantized.bin
 1559  git clone https://github.com/wombyz/gpt4all_langchain_chatbots.git
 1560  vim .git
 1561  python pygpt4all_setup.py
 1562  pip install langchain=0.0.149
 1563  pip install langchain==0.0.149
 1564  python -u "/media/chirag/DATA/CODE_AMA/GPT4ALL/gpt4all_langchain_chatbots/basic_langchain_setup.py"
 1565  python3 --v
 1566  python3 -v
 1567  python3 -V
 1568  python3 basic_langchain_setup.py
 1569  python -u "/media/chirag/DATA/CODE_AMA/GPT4ALL/gpt4all_langchain_chatbots/pygpt4all_setup.py"
 1570  python3 pygpt4all_setup.py
 1571  sudo apt install python3.10
 1572  python -u "/media/chirag/DATA/CODE_AMA/langchain/intro.ipynb"
 1573  jupyter
 1574  jupyter --help
 1575  git clone https://github.com/virtual-labs/ph3-lab-mgmt.git
 1576  mkdir experiments
 1577  node main.js build --validateEslint --validateExpdesc --src=../experiments/exp-adder-circuit-iiith
 1578  git clone https://github.com/virtual-labs/exp-adder-circuit-iiith.git
 1579  git clone https://github.com/chir263/ph3-template.git
 1580  git remote add origin https://github.com/chir263/test-exp.git
 1581  git push -u origin -f main
 1582  node main.js build --validateEslint --validateExpdesc --src=../test
 1583  node main.js build --validateEslint --validateExpdesc --src=../exp-adder-circuit-iiith
 1584  node main.js build --validateEslint --validateExpdesc --src=../exp-adder-circuit-iiith-main
 1585  cd "/media/chirag/DATA/CODE_AMA/CP/interviewbit/" && g++ kth-perm-sequence.cpp -o kth-perm-sequence && "/media/chirag/DATA/CODE_AMA/CP/interviewbit/"kth-perm-sequence
 1586  git clone https://github.com/chir263/test-exp.git
 1587  git clone https://github.com/chir263/test-exp-2.git
 1588  git clone https://github.com/raj-vlabs/decap-cms-sample.git
 1589  git remote add origin https://github.com/chir263/my-jar.git
 1590  git pull origin
 1591  git remote add origin https://github.com/chir263/center-cms.git
 1592  git pu
 1593  python -u "/media/chirag/DATA/CODE_AMA/GPT4ALL/nomic_setup.py"
 1594  6\n1   3\n1   5 \n2   5cd "/media/chirag/DATA/CODE_AMA/CP/goog/" && g++ XOR query.cpp -o XOR query && "/media/chirag/DATA/CODE_AMA/CP/goog/"XOR query\n1   6\n1   7\n2   6
 1595  cd "/media/chirag/DATA/CODE_AMA/CP/goog/" && g++ XOR query.cpp -o XOR query && "/media/chirag/DATA/CODE_AMA/CP/goog/"XOR query
 1596  cd "/media/chirag/DATA/CODE_AMA/CP/goog/" && g++ XOR_query.cpp -o XOR_query && "/media/chirag/DATA/CODE_AMA/CP/goog/"XOR_query
 1597  git clone https://github.com/YashK2003/CF-Stalker-.git
 1598  node index.js
 1599  git remote add origin https://github.com/chir263/esw_frontend.git
 1600  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ kth-perm.cpp -o kth-perm && "/media/chirag/DATA/CODE_AMA/CP/"kth-perm
 1601  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1098A.cpp -o 1098A && "/media/chirag/DATA/CODE_AMA/CP/"1098A
 1602  mkdir .git\objects
 1603  mkdir .git\refs
 1604  mkdir .git\refs\heads
 1605  tree /f
 1606  mkdir .git
 1607  mkdit objects
 1608  mkdir objects
 1609  mkdir refs
 1610  mkdir refs/heads
 1611  touch HEAD
 1612  echo ref: refs/heads/master > .git\HEAD
 1613  echo ref: refs/heads/master > .git/HEAD
 1614  cat .git/HEAD
 1615  echo Brief channel is awsome | git hash-object --stdin
 1616  tree .git/objects
 1617  echo Brief channel is awsome | git hash-object --stdin -w
 1618  git cat-file -t 2eced18dc258c754b9bbc29022d11985ad5605d5
 1619  ;rm .gitHEAD
 1620  tree .
 1621  git update-index --add --cacheinfo 10064 2eced18dc258c754b9bbc29022d11985ad5605d5 brief.txt
 1622  la -la
 1623  git cat-file -p 2eced18dc258c754b9bbc29022d11985ad5605d5
 1624  git cat-file -p 2eced18dc258c754b9bbc29022d11985ad5605d5 > brief.txt
 1625  git write-tree 
 1626  git cat-file -t e0d681251096defa74d8f752ddffe252d2337b61
 1627  git cat-file -p e0d681251096defa74d8f752ddffe252d2337b61
 1628  git commit-tree e0d681251096defa74d8f752ddffe252d2337b61 -m "Initial commit"
 1629  git cat-file -t f4f4e3b7163a64434c297d4b0b3cf27c9f0e2e10
 1630  git cat-file -p f4f4e3b7163a64434c297d4b0b3cf27c9f0e2e10
 1631  ls -al .git\index
 1632  echo f4f4e3b7163a64434c297d4b0b3cf27c9f0e2e10 > .git\refs\heads\master
 1633  rm .gitrefsheadsmaster
 1634  echo f4f4e3b7163a64434c297d4b0b3cf27c9f0e2e10 > .git/refs/heads/master
 1635  tree .git
 1636  4
 1637  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1006E.cpp -o 1006E && "/media/chirag/DATA/CODE_AMA/CP/"1006E
 1638  3 1
 1639  1 5
 1640  7 3
 1641  1 8
 1642  1 9
 1643  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ test.cpp -o test && "/media/chirag/DATA/CODE_AMA/CP/"test
 1644  2 3
 1645  4 6
 1646  1\nJJP JJ
 1647  8 9cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1281B.cpp -o 1281B && "/media/chirag/DATA/CODE_AMA/CP/"1281B
 1648  cd "/media/chirag/DATA/CODE_AMA/CP/" && g++ 1281B.cpp -o 1281B && "/media/chirag/DATA/CODE_AMA/CP/"1281B
 1649  git commit -m "16th May Chirag"
 1650  git remote add origin https://github.com/virtual-labs-cms/engineers-forum.git
 1651  git clone error: failed to push some refs to 'https://github.com/virtual-labs-cms/engineers-forum.git'
 1652  git clone https://github.com/virtual-labs-cms/engineers-forum.git
 1653  git push origin main
 1654  git commit -m "engineers forum"
 1655  cd "/media/chirag/DATA/CODE_AMA/CP/div3-881/" && g++ 1843D.cpp -o 1843D && "/media/chirag/DATA/CODE_AMA/CP/div3-881/"1843D
 1656  git push -u origin -f master
 1657  chmod 400 tutorialkey.pem\n\n
 1658  ssh -i "tutorialkey.pem" ubuntu@ec2-54-236-215-116.compute-1.amazonaws.com
 1659  cd "/media/chirag/DATA/" && g++ 1625C.cpp -o 1625C && "/media/chirag/DATA/"1625C
 1660  chmod 400 test2.pem\n\n
 1661  gedit test2.pem
 1662  ssh -i "test2.pem" ubuntu@ec2-3-86-81-204.compute-1.amazonaws.com\n
 1663  rm -fr .git
 1664  git remote add origin https://github.com/chir263/cms.git
 1665  git clone https://github.com/chir263/exp-aes-iiith.git
 1666  git remote add origin https://github.com/virtual-labs/app-exp-create-web.git
 1667  sudo apt-get --only-upgrade install google-chrome-stable
 1668  touch x.cpp
 1669  git commit -m "RELEASE 1 CMS"
 1670  git commit -m "Added README and docs"
 1671  python3 -m http.server 8000
 1672  git commit -m "aes"
 1673  cd "/media/chirag/DATA/" && g++ longest-valid-sub.cpp -o longest-valid-sub && "/media/chirag/DATA/"longest-valid-sub
 1674  git commit -m "cms"
 1675  mutation_observer.md
 1676  touch mutation_observer.md
 1677  cd "/media/chirag/DATA/CODE_AMA/CP/rubrik/" && g++ c.cpp -o c && "/media/chirag/DATA/CODE_AMA/CP/rubrik/"c
 1678  cd "/media/chirag/DATA/CODE_AMA/CP/sprinklr/" && g++ q2.cpp -o q2 && "/media/chirag/DATA/CODE_AMA/CP/sprinklr/"q2
 1679  cd "/media/chirag/DATA/CODE_AMA/CP/sprinklr/" && g++ gs1.cpp -o gs1 && "/media/chirag/DATA/CODE_AMA/CP/sprinklr/"gs1
 1680  git commit -m "updated"
 1681  git push -u origin 
 1682  npx create-react-app test
 1683  cd test
 1684  python -u "/media/chirag/DATA/CODE_AMA/CP/sprinklr/abc.py"
 1685  3 2 1
 1686  1 100
 1687  6
 1688  5 500
 1689  2 2 2 2 2
 1690  2 365
 1691  3 4
 1692  10000 2023
 1693  10 635472106413848880
 1694  9181 4243 7777 1859 2017 4397 14 9390 2245 7225
 1695  7 176345687772781240
 1696  9202 9407 9229 6257 7743 5738 7966
 1697  14 865563946464579627
 1698  3654 5483 1657 7571 1639 9815 122 9468 3079 2666 5498 4540 7861 5384
 1699  19 977162053008871403
 1700  9169 9520 9209 9013 9300 9843 9933 9454 9960 9167 9964 9701 9251 9404 9462 9277 9661 9164 9161
 1701  18 886531871815571953
 1702  google
 1703  python -u "/media/chirag/DATA/CODE_AMA/oa/google/isos.py"
 1704  cd "/media/chirag/DATA/CODE_AMA/oa/google/" && g++ x.cpp -o x && "/media/chirag/DATA/CODE_AMA/oa/google/"x
 1705  cd "/media/chirag/DATA/Downloads/" && g++ 1.cpp -o 1 && "/media/chirag/DATA/Downloads/"1
 1706  I google 1
 1707  I sprinklr 10
 1708  I spring 2
 1709  Q apple
 1710  cd "/media/chirag/DATA/Downloads/" && g++ d.cpp -o d && "/media/chirag/DATA/Downloads/"d
 1711  cd "/media/chirag/DATA/Downloads/" && gcc p.c -o p && "/media/chirag/DATA/Downloads/"p
 1712  touch abcd.txt
 1713  cd "/home/chirag/Desktop/" && g++ xx.cpp -o xx && "/home/chirag/Desktop/"xx
 1714  touch texh_guide.md
 1715  touch user_guide.md
 1716  touch content_creator.md
 1717  git clone https://github.com/PawanOsman/ChatGPT.git
 1718  cd ChatGPT
 1719  python -u "/media/chirag/DATA/VLABS/semantic-search/docs/proxy.py"
 1720  cd "/home/chirag/Desktop/" && g++ xxx.cpp -o xxx && "/home/chirag/Desktop/"xxx
 1721  pip install markdownify
 1722  python -u "/media/chirag/DATA/VLABS/semantic-search/read_docs.py"
 1723  touch qdrant_API.txt
 1724  cd "/home/chirag/" && g++ a.cpp -o a && "/home/chirag/"a
 1725  pip install markdown
 1726  ##-troubleshooting
 1727  python -u "/media/chirag/DATA/VLABS/semantic-search/test.py"
 1728  python -u "/media/chirag/DATA/VLABS/semantic-search/main.py"
 1729  pip install -U sentence-transformers
 1730  python -u "/media/chirag/DATA/VLABS/semantic-search/t.py"
 1731  python -u "/media/chirag/DATA/VLABS/semantic-search/main.ipynb"
 1732  python -u "/media/chirag/DATA/VLABS/semantic-search/document_parser.py"
 1733  chmod 400 testenc.pem
 1734  ssh -i "testenc.pem" ubuntu@ec2-52-36-246-157.us-west-2.compute.amazonaws.com
 1735  git init\ngit add README.md\ngit commit -m "first commit"\ngit branch -M main\ngit remote add origin https://github.com/chir263/semantic-search.git\ngit push -u origin main
 1736  git remote add origin https://github.com/chir263/semantic-search.git
 1737  git push -f -u origin master
 1738  pip install dot-env
 1739  git --version
 1740  git branch dev\n
 1741  git origin
 1742  git remote add origin https://github.com/virtual-labs/tool-doc-search.git
 1743  git clone https://github.com/virtual-labs/tool-doc-search.git
 1744  rm -rf .git*
 1745  git checkout -b dev
 1746  git commit -m "semantic-search first update"
 1747  git rm --cached .env
 1748  git commit -m "Remove .env from version control"\n
 1749  sudo apt install golang-go\n
 1750  go mod init
 1751  go mod init hello
 1752  go run "/media/chirag/DATA/golang/01-hello/main.go"
 1753  go help 
 1754  go mod init variables
 1755  go run "/media/chirag/DATA/golang/02-variables/main.go"
 1756  go mod init userinput
 1757  go run "/media/chirag/DATA/golang/03-user-input/main.go"
 1758  go mod init conversion
 1759  go run "/media/chirag/DATA/golang/04-conversion/main.go"
 1760  go mod init mymath
 1761  go run "/media/chirag/DATA/golang/05-mymath/main.go"
 1762  go run "/media/chirag/DATA/golang/06-time/main.go"
 1763  GOOS="linux" go build
 1764  ./06-time
 1765  go run "/media/chirag/DATA/golang/07-mypointer/main.go"
 1766  go run "/media/chirag/DATA/golang/08-myarray/main.go"
 1767  cd "/home/chirag/" && g++ aak.cpp -o aak && "/home/chirag/"aak
 1768  go run "/media/chirag/DATA/golang/09-slices/main.go"
 1769  go run "/media/chirag/DATA/golang/10-maps/main.go"
 1770  go run "/media/chirag/DATA/golang/11-struct/main.go"
 1771  go run "/media/chirag/DATA/golang/12-ifelse/main.go"
 1772  go run "/media/chirag/DATA/golang/13-switch/main.go"
 1773  go run "/media/chirag/DATA/golang/14-loops/main.go"
 1774  go run "/media/chirag/DATA/golang/15-functions/main.go"
 1775  go run "/media/chirag/DATA/golang/16-methods/main.go"
 1776  go run "/media/chirag/DATA/golang/17-defer/main.go"
 1777  go run "/media/chirag/DATA/golang/18-files/main.go"
 1778  go run "/media/chirag/DATA/golang/19-webrequest/main.go"
 1779  sudo apt install code\n
 1780  go --v
 1781  go -v
 1782  go version
 1783  sudo apt-get purge golang-*\n
 1784  which go\n
 1785  sudo apt install golang-go
 1786  sudo apt uninstall golang-go
 1787  sudo apt remove golang-go
 1788  tar -xzf go1.21.0.linux-amd64.tar.gz -C /usr/local/
 1789  sudo tar -xzf go1.21.0.linux-amd64.tar.gz -C /usr/local/
 1790  sudo nano /etc/profile
 1791  ^[[200~source /etc/profile
 1792  ~source /etc/profile\n
 1793  source /etc/profile\n
 1794  go version\n
 1795  sudo nano /etc/profile\n
 1796  sudo nano .zshrc\n
 1797  restart
 1798  go
 1799  go mod init urls
 1800  go run "/media/chirag/DATA/golang/20-urls/main.go"
 1801  go mod init getreq
 1802  go run "/media/chirag/DATA/golang/21-getreq/main.go"
 1803  cd "/media/chirag/DATA/msft/" && g++ r1x.cpp -o r1x && "/media/chirag/DATA/msft/"r1x
 1804  pip install gdown html2text\n
 1805  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/util-testing/google-doc.py"
 1806  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/document_parser.py"
 1807  git commit -m "Added google doc functionality"\n
 1808  go run "/media/chirag/DATA/golang/22-json/main.go"
 1809  go mod init github.com/chir263/mymodules
 1810  go env
 1811  go mod verify
 1812  go list
 1813  go list all modules
 1814  go list all
 1815  go list -m all
 1816  ./mymodules
 1817  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/main.ipynb"
 1818  pip install ipywidgets pandas
 1819  git commit -m "Added doc filter"\n
 1820  cd "/media/chirag/DATA/flipkart/" && g++ a.cpp -o a && "/media/chirag/DATA/flipkart/"a
 1821  cd "/media/chirag/DATA/flipkart/" && g++ b.cpp -o b && "/media/chirag/DATA/flipkart/"b
 1822  git commit -m "Added search limit"\n
 1823  go run "/media/chirag/DATA/golang/23-mymodule/main.go"
 1824  go mod init github.com/chir263/buildapi
 1825  go get -u github.com/gorilla/mux
 1826  go run "/media/chirag/DATA/golang/24-buildapi/main.go"
 1827  go build .
 1828  ./buildapi
 1829  go mod init github.com/chir263/mongoapi
 1830  go get go.mongodb.org/mongo-driver/mongo
 1831  java -jar C_KIT.jar
 1832  roll21 n %jain
 1833  go mod tidy
 1834  git commit -m "updated"\n
 1835  cd "/media/chirag/DATA/rayaan/" && g++ a.cpp -o a && "/media/chirag/DATA/rayaan/"a
 1836  cd "/media/chirag/DATA/oa/" && g++ wf.cpp -o wf && "/media/chirag/DATA/oa/"wf
 1837  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/doc-search.py"
 1838  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/doc_search.py"
 1839  go run main.go
 1840  go run "/media/chirag/DATA/golang/25-mongoapi/main.go"
 1841  go run "/media/chirag/DATA/golang/26-goroutines/main.go"
 1842  go run "/media/chirag/DATA/golang/26-mutexAndWeightGroups/main.go"
 1843  go run "/media/chirag/DATA/golang/26-mutexAndWeightGroups/main.go" --race
 1844  go run "/media/chirag/DATA/golang/28-channels/main.go"
 1845  google chrome --disable-web-security
 1846  google-chrome --disable-web-security
 1847  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/main.py"
 1848  git commit -m "added qdrant-cloud, payload indexing, page-title filtering"\n
 1849  touch libs.txt
 1850  python run.py
 1851  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/run.py"
 1852  git commit -m "added Flask server"\n
 1853  git commit -m "added sample md"\n
 1854  wget -qO - https://hub.unity3d.com/linux/keys/public | gpg --dearmor | sudo tee /usr/share/keyrings/Unity_Technologies_ApS.gpg > /dev/null
 1855  sudo sh -c 'echo "deb [signed-by=/usr/share/keyrings/Unity_Technologies_ApS.gpg] https://hub.unity3d.com/linux/repos/deb stable main" > /etc/apt/sources.list.d/unityhub.list'
 1856  sudo apt-get install unityhub
 1857  sudo snap install rider --classic
 1858  sudo apt-get install mono-complete msbuild
 1859  wget https://packages.microsoft.com/config/ubuntu/20.04/packages-microsoft-prod.deb -O packages-microsoft-prod.deb\nsudo dpkg -i packages-microsoft-prod.deb\nrm packages-microsoft-prod.deb
 1860  sudo apt-get update && \\n  sudo apt-get install -y dotnet-sdk-7.0
 1861  sudo apt install ca-certificates gnupg\nsudo gpg --homedir /tmp --no-default-keyring --keyring /usr/share/keyrings/mono-official-archive-keyring.gpg --keyserver hkp://keyserver.ubuntu.com:80 --recv-keys 3FA7E0328081BFF6A14DA29AA6A19B38D3D831EF\necho "deb [signed-by=/usr/share/keyrings/mono-official-archive-keyring.gpg] https://download.mono-project.com/repo/ubuntu stable-focal main" | sudo tee /etc/apt/sources.list.d/mono-official-stable.list\nsudo apt update
 1862  sudo apt install mono-devel
 1863  sudo apt install awscli
 1864  sudo apt install maven\n
 1865  sudo apt install openjdk-11-jdk\n
 1866  virtualbox
 1867  virtualbox --v
 1868  vboxmanage --version
 1869  curl -O https://releases.hashicorp.com/vagrant/2.2.9/vagrant_2.2.9_x86_64.deb
 1870  sudo apt install ./vagrant_2.2.9_x86_64.deb\n\n
 1871  vagrant
 1872  ~/.config/UnityHub/logs
 1873  cd ~/.config/UnityHub/logs
 1874  cd ~/.config/UnityHub
 1875  cd .config
 1876  cd unityhub
 1877  rm .config/unity3d .config/unityhub -rf 
 1878  unitt
 1879  python -u "/media/chirag/DATA/CODE_AMA/science 1/assign_2_2.py"
 1880  cd "/media/chirag/DATA/" && g++ y.cpp -o y && "/media/chirag/DATA/"y
 1881  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/utils/doc_search.py"
 1882  pip install google-auth-oauthlib
 1883  pip install google-api-python-client
 1884  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/google-oauth/app.py"
 1885  git clone https://github.com/code-specialist/flask_google_login.git
 1886  pip install --upgrade google-auth google-auth-oauthlib google-auth-httplib2
 1887  pip install --upgrade google-api-python-client\n
 1888  kill -9 15907
 1889  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/flask_google_login/app.py"
 1890  python3 -m venv tool-doc-search\n
 1891  source tool-doc-search/bin/activate\n
 1892  cd include
 1893  cd vl
 1894  cd tool-doc-search
 1895  rm -r tool-doc-search
 1896  cd -al
 1897  node "/home/chirag/x.js"
 1898  python test.py > x.html
 1899  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/flask_google_login/test.py"
 1900  sudo add-apt-repository ppa:inkscape.dev/stable\nsudo apt update\nsudo apt install inkscape
 1901  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/blueprints/insert_doc.py"
 1902  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/blueprints/insert_doc.py"python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/server.py"
 1903  cd "/home/chirag/" && g++ ak.cpp -o ak && "/home/chirag/"ak
 1904  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/test.py"
 1905  git commit -m "added authentication with inserting document"\n
 1906  ls -l
 1907  sudo npm install appfairy -g\n
 1908  create react-app
 1909  npx create react-app
 1910  npm create react-app
 1911  sudo npm create-react-app\n
 1912  npx create-react-app tool-doc-search
 1913  pip install -U flask-cors
 1914  unity-editor
 1915  unity
 1916  git commit -m "created insert_doc page"\n
 1917  git commit -m "frontend for document search VLABS"
 1918  git remote add origin https://github.com/chir263/doc_search_frontend.git
 1919  git push -u origin
 1920  cd "/media/chirag/DATA/CODE_AMA/" && g++ c.cpp -o c && "/media/chirag/DATA/CODE_AMA/"c
 1921  npx create-react-app my-app
 1922  npm install react-konva konva tailwindcss\n
 1923  git clone https://github.com/oasis10702/konva-simple-example.git
 1924  git clone https://github.com/chir263/react-konva.git
 1925  cd react-konva
 1926  npm i --force
 1927  npm i --legacy-peer-deps
 1928  npx tailwindcss init
 1929  npm install tailwindcss
 1930  npm install tailwindcss postcss autoprefixer@^9.8.6
 1931  npm install react-scripts@latest
 1932  git commit -m "project init"
 1933  git remote add origin https://github.com/chir263/ihub-annotation-history-task.git
 1934  git commit -m "completed with bonus"
 1935  npm build
 1936  git commit -m "completed with delete"
 1937  git commit -m "completed with comments"
 1938  sudo apt install indicator-stickynotes\n
 1939  sudo add-apt-repository ppa:umang/indicator-stickynotes\nsudo apt-get update\nsudo apt-get install indicator-stickynotes
 1940  sudo apt-get remove insync.
 1941  cd "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/templates/" && g++ x.cpp -o x && "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/templates/"x
 1942  git commit -m "changed identifier to url and added inserted_by field"
 1943  purple-task
 1944  sudo apt install libavcodec-dev\n
 1945  npm run start
 1946  npm build start
 1947  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/server.py"
 1948  source tool-doc-search/bin/activate
 1949  cd venv
 1950  git sta
 1951  git commit -m "added multi doc upload"
 1952  git push -u -f origin dev
 1953  chmod 400 package
 1954  sudo chmod +x node_modules/.bin/react-scripts
 1955  cd Ima
 1956  CREATE USER 'dfs_root'@'localhost' IDENTIFIED BY 'dfsRoot*123';\n
 1957  mysql -uroot -pPassword1! 
 1958  mysql -udfs_root -pdfsRoot*123
 1959  sudo systemctl restart mysql. service.
 1960  sudo systemctl restart mysql. service
 1961  sudo systemctl restart mysql.service
 1962  mysql -udfs_root -p
 1963  touch render.js.txt
 1964  touch x.py
 1965  python -u "/media/chirag/DATA/x.py"
 1966  sudo apt-get install pavucontrol
 1967  sudo apt-get update
 1968  sudo apt-get upgrade\n
 1969  pulseaudio -k && pulseaudio --start\n
 1970  sudo lshw -C sound
 1971  sudo apt-get remove --purge alsa-base pulseaudio\nsudo apt-get install alsa-base pulseaudio\nsudo alsa force-reload
 1972  [bluetooth]# scan on
 1973  alsamixer
 1974  sudo systemctl status bluetooth.service
 1975  sudo systemctl start bluetooth.service\n
 1976  sudo vim /etc/bluetooth/main.conf\n
 1977  sudo apt install bluez
 1978  sudo systemctl enable bluetooth.service\nsudo systemctl start bluetooth.service
 1979  bluetoothctl
 1980  sudo add-apt-repository ppa:pipewire-debian/pipewire-upstream\n
 1981  sudo apt install pipewire
 1982  sudo apt install libspa-0.2-bluetooth
 1983  sudo apt install pipewire-audio-client-libraries
 1984  systemctl  user daemon-reload
 1985  systemctl -user daemon-reload
 1986  systemctl - user daemon-reload
 1987  systemctl --user daemon-reload
 1988  systemctl  --user --now disable pulseaudio.service pulseaudio.socket
 1989  systemctl --user --now enable pipewire pipewire-pulse
 1990  systemctl --user mask pulseaudio
 1991  systemctl --user --now enable pipewire-media-session.service
 1992  pactl info\n
 1993  git commit -m "added new page update docs"
 1994  git clone https://github.com/chir263/Image-Annotation-Tool.git
 1995  git remote add upstream https://github.com/pranshul24/Image-Annotation-Tool.git\n
 1996  git checkout -b dev-frontend
 1997  touch hello.txt
 1998  git commit -m "test commit"
 1999  git push origin feature-branch
 2000  git commit -m "added sliding div"
 2001  git commit -m "added update docs page"
 2002  npm update react-icons
 2003  git commit -m "improved layout for imagepage"
 2004  git commit -m "integrated insert page, added logging"
 2005  git commit -m "added left bottom bar, maximize-shrink and label box styling"
 2006  git commit -m "added delete functionality"
 2007  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/utils/test.py"
 2008  cd "/media/chirag/DATA/" && g++ xy.cpp -o xy && "/media/chirag/DATA/"xy
 2009  cd "/media/chirag/DATA/" && g++ xy2.cpp -o xy2 && "/media/chirag/DATA/"xy2
 2010  touch app.yaml
 2011  git commit -m "worked on understanding canvas"
 2012  npm install -D tailwindcss postcss autoprefixer\nnpx tailwindcss init
 2013  git commit -m "worked on some ui improvement tailwind"
 2014  git commit -m "added README.md and frontend folder"
 2015  git commit -m "updated README"
 2016  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/utils/document_parser.py"
 2017  git clone https://github.com/virtual-labs/app-exp-create-web.git
 2018  git commit -m "update user-doc.md"
 2019  git push origin master
 2020  git commit -m "add created_by, updated_by, last_updated, created_at. did cosmetic changes. improved page indication. added select all checkbox"
 2021  git commit -m "added pagination"
 2022  git commit -m "fpush"
 2023  git commit -m "added next/prev buttons with initial view"
 2024  python3 -m venv tool-doc-search-venv\n
 2025  source tool-doc-search-venv/bin/activate\n
 2026  pip install google-auth-oauthlib\n
 2027  pip install sentence-transformers\n
 2028  pip install pdfminer.six\n
 2029  sudo du -sh /var/cache/apt \n
 2030  du -sh ~/.cache/thumbnails\n
 2031  pip install tools
 2032  pip install PyMuPDF
 2033  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/util-testing/pdf.py"
 2034  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/util-testing/pdf.py" > test.txt
 2035  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/util-testing/pdf.py" > test1.txt
 2036  git commit -m "added optional page title, github doc-type"
 2037  git push origin dev
 2038  npm s 
 2039  npm start\\n
 2040  sudo kill -9 `sudo lsof -t -i:3031`
 2041  git commit -m "canvas changes"
 2042  git push origin dev-frontend
 2043  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/util-testing/test.py"
 2044  mkdir dfs-backend
 2045  npm init -y
 2046  npm install express
 2047  touch app.js
 2048  npm install dotenv\n
 2049  node "/media/chirag/DATA/dfs/dfs-backend/app.js"
 2050  npm install cors\n
 2051  npm install nodemon
 2052  npm install cors
 2053  npm install http-status-codes
 2054  npm install neo4j-driver
 2055  cd  dfs-backend
 2056  git commit -m "initial setup for backend"
 2057  git remote add origin https://github.com/chir263/DFS-Project.git
 2058  node "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/static/js/document_type.js"
 2059  sudo kill -9 $(sudo lsof -t -i:5000)\n
 2060  cd "/media/chirag/DATA/" && g++ xy1.cpp -o xy1 && "/media/chirag/DATA/"xy1
 2061  python -u "/media/chirag/DATA/ak/x.py"
 2062  git commit -m "added support for unknown docs/links"
 2063  pip install orgparse
 2064  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/util-testing/t.py"
 2065  pip uninstall orgparse
 2066  git commit -m "added support for org-mod"
 2067  python -u "/media/chirag/DATA/xxx.py"
 2068  python xxx.py
 2069  npm install react-scripts --save
 2070  sudo chmod +x node_modules/.bin/react-scripts\n
 2071  npm update feather-icons
 2072  npm install -g npm stable\n\n
 2073  sudo npm cache clean -f\nsudo npm install -g n\nsudo n stable\n
 2074  sudo n latest
 2075  npm -v
 2076  npm install feather-icons
 2077  npm install react-rnd react-modal framer-motion styled-components react-router-dom tailwindcss twin.macro
 2078  npm outdated
 2079  export NODE_OPTIONS=--openssl-legacy-provider
 2080  chmod 400 package.json
 2081  git remote add origin https://github.com/ppt1524/DFS-Project-frontend.git
 2082  git commit -m "initial setuup"
 2083  git branch main
 2084  git checkout -b main
 2085  git commit -m "initial setup"
 2086  git push -u -f origin main
 2087  python pp.py > train.json
 2088  pip install flaskwebgui
 2089  pip uninstall flaskwebgui
 2090  pip install flaskwebgui==0.2.1
 2091  node "/media/chirag/DATA/megathon/app/static/index.js"
 2092  python -u "/media/chirag/DATA/megathon/app/app.py"
 2093  python -m venv myenv\n
 2094  pip i -m requirements.txt
 2095  pip install -m requirements.txt
 2096  sudo kill -9 `sudo lsof -t -i:5000`\n
 2097  source myenv/bin/activate\n
 2098  git commit -m "added support for xlsx"
 2099  pip install llmsherpa\n
 2100  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/pdf-parser/main.py"> i.html
 2101  git commit -m "added xlsx table view in frontend"
 2102  pip uninstall -r u.txt
 2103  ypip install pip-autoremove\n
 2104  pip install pip-autoremove\n
 2105  pip-autoremove\n
 2106  pip uninstall numpy
 2107  cd /home/chirag/.local/lib/python3.8/site-packages/
 2108  pip uninstall pandads
 2109  pip uninstall pandas
 2110  pip uninstall sentence_transformers
 2111  pip uninstall torch
 2112  pip uninstall torchvision
 2113  pip uninstall transformers
 2114  pip uninstall sentence-transformers
 2115  pip uninstall scikit-learn
 2116  pip uninstall docker
 2117  pip uninstall docker-compose
 2118  pip uninstall dockerpty
 2119  pip uninstall fitz
 2120  pip uninstall Flask
 2121  pip uninstall Flask-Cors
 2122  pip uninstall Flask-Login
 2123  pip uninstall Flask-SQLAlchemy
 2124  pip uninstall huggingface-hub
 2125  pip uninstall langchain
 2126  pip list
 2127  pip list > libs.txt
 2128  git clone https://github.com/jayghevariya/Healthcare-Knowledge-Graph_Data-Builders.git
 2129  cd Healthcare-Knowledge-Graph_Data-Builders
 2130  rm .env
 2131  rm .gitignore
 2132  touch README.md
 2133  git commit -m "mid evals"
 2134  git commit -m "imagepage ui redesigned"
 2135  source venv/bin/activate\n
 2136  pip install pypdf2
 2137  python page_num.py
 2138  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/pdf-parser/page_num.py"
 2139  python page_num.py > test
 2140  python main.py > test
 2141  git commit -m "added pdf parsing util"
 2142  sudo apt-get install powerline fonts-powerline\n
 2143  git clone https://github.com/bhilburn/powerlevel9k.git ~/.oh-my-zsh/custom/themes/powerlevel9k
 2144  gedit .zshrc\n
 2145  chsh -s /bin/zsh\n
 2146  sudo apt install zsh
 2147  bash
 2148  sh -c "$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)"
 2149  git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ~/powerlevel10k\necho 'source ~/powerlevel10k/powerlevel10k.zsh-theme' >>~/.zshrc
 2150  gedit ~/.zshrc\n
 2151  cd .
 2152  git clone --depth=1 https://github.com/romkatv/powerlevel10k.git ${ZSH_CUSTOM:-$HOME/.oh-my-zsh/custom}/themes/powerlevel10k
 2153  p10k configure
 2154  cd
 2155  cd Downloads
 2156  vim .gitignore
 2157  locate netbeans\n
 2158  ~/netbeans
 2159  sudo apt-get remove netbeans\n
 2160  sudo apt-get remove --purge netbeans\n
 2161  disk
 2162  dpkg-query -Wf '${Installed-Size}\t${Package}\n' | sort -n | tail -n 10\n
 2163  dpkg-query -Wf '${Installed-Size}\t${Package}\n' | sort -n | tail -n 30\n
 2164  sudo apt remove zoom\n
 2165  sudo apt remove qemu-system-misc
 2166  dpkg-query -Wf '${Installed-Size}\t${Package}\n' | sort -n | tail -n 100\n
 2167  sudo apt-get remove insync
 2168  sudo apt-get purge insync-beta-ubuntu && sudo apt-get autoremove\n
 2169  rm -rf ~/.config/Insync
 2170  sudo apt-get remove heroku heroku-toolbelt
 2171  sudo rm /etc/apt/sources.list.d/heroku.list
 2172  which heroku
 2173  cd /usr/bin/heroku
 2174  cd /usr/bin/
 2175  sudo apt-get remove heroku
 2176  sudo apt-get autoremove
 2177  sudo apt remove github-desktop
 2178  sudo apt remove --purge github-desktop\n
 2179  sudo apt-get remove arduino\nsudo apt-get remove --auto-remove arduino\nsudo apt-get purge arduino\nsudo apt-get purge --auto-remove arduino
 2180  which arduino
 2181  sudo apt-get remove --auto-remove arduino
 2182  ./uninstall.sh
 2183  sudo ./uninstall.sh
 2184  find ~/.cache/ -depth -type f -atime +365 \n
 2185  find ~/.cache/ -type f -atime +365 -delete\n
 2186  cd ~p
 2187  cd ~
 2188  cd /home
 2189  cd chirag
 2190  ls -la
 2191  rm -rf Arduino
 2192  rm -rf .arduino15
 2193  cd /DATA
 2194  cd /media/chirag/DATA
 2195  mv .cache /media/chirag/DATA/cache-backup-2-11-2023
 2196  cd "/media/chirag/DATA/ak/" && g++ x.cpp -o x && "/media/chirag/DATA/ak/"x
 2197  cd answers
 2198  touch PS1-1.ipynb
 2199  python -u "/media/chirag/DATA/cs229/cs229-2018-autumn-main/problem-sets/PS1/src/p01b_logreg.py"
 2200  source /media/chirag/DATA/cs229/cs229-2018-autumn-main/problem-sets/PS1/.venv/bin/activate
 2201  conda
 2202  sudo apt install github-desktop
 2203  pip install PyPDF2
 2204  python main.py > test.json
 2205  git commit -m "added support for drive/pdf"
 2206  git commit -m "resolved pdf bug / optimised page no algorithm"
 2207  git commit -m "display page no. on frontend"
 2208  source /media/chirag/DATA/cs229/cs229-2018-autumn-main/problem-sets/PS1/answers/venv/bin/activate
 2209  pip install numpy
 2210  npm i react-content-loader --save
 2211  python github_private.py
 2212  source v
 2213  cd f
 2214  git commit -m "refractored react page with some modifications"
 2215  cd "/media/chirag/DATA/" && g++ x.cpp -o x && "/media/chirag/DATA/"x
 2216  cd blueprints
 2217  code swap.img
 2218  git commit -m "added src field in payload"
 2219  git merge
 2220  sudo apt install notion-app-enhanced;
 2221  echo "deb [trusted=yes] https://apt.fury.io/notion-repackaged/ /" | sudo tee /etc/apt/sources.list.d/notion-repackaged.list\n
 2222  notion
 2223  sudo remove notion-enhancer;
 2224  sudo uninstall notion-enhancer;
 2225  sudo dnf install notion-app\n
 2226  sudo apt install notion-app-enhanced\n
 2227  sudo apt remove notion-app-enhanced\n
 2228  npm remove -g notion-enhancer\n\n
 2229  sudo apt install epiphany-browser\n
 2230  sudo apt install notion-app\n
 2231  sudo apt remove notion-app\n
 2232  cd frontendsource /media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/venv/bin/activate
 2233  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/util-testing/pdf_parser.py"
 2234  cd util-testing
 2235  python pdf_parser.py
 2236  source /media/chirag/DATA/VLABS/vlabs-semantic-search/pdf-parser/venv/bin/activate
 2237  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/pdf-parser/main.py"
 2238  pip install fitz
 2239  pip install frontend
 2240  python xx.py
 2241  mysql -u root -p
 2242  sudo mysql -u root -p
 2243  sudo mysql -uroot -p
 2244  sudo systemctl stop mysql.service\n
 2245  sudo systemctl set-environment MYSQLD_OPTS="--skip-networking --skip-grant-tables"\n
 2246  sudo systemctl start mysql.service\n
 2247  sudo systemctl status mysql.service\n
 2248  git commit -m "update README.md"
 2249  ( find ./ -name '*.p' -print0 | xargs -0 cat ) | wc -l\n
 2250  find ./ -name '*.py' -print0 | xargs -0 cat ) | wc -l\n
 2251  ( find ./ -name '*.py' -print0 | xargs -0 cat ) | wc -l\n
 2252  ( find ./ -name '*.php' -print0 | xargs -0 cat ) | wc -l\n
 2253  git commit -m "added vlabs secret files and done with accessibility"
 2254  git commit -m "updated requirements.txt"
 2255  git commit -m "updated github accessibility logic"
 2256  mysql
 2257  sudo mysql
 2258  sudo mysql -u root\n
 2259  sudo mysql -u root -p\n
 2260  sudo mysql -u dfs_user -p\n
 2261  scala
 2262  npm ijsonwebtoken
 2263  git commit -m "added jwt authorization, redesigned mysql schema, commented unused routes, modified server code post.js"
 2264  mysqldump -u dfs_user -p dfs_db > new_schema.sql
 2265  /media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/venv/bin/python
 2266  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/util-testing/github_private.py"
 2267  git commit -m "added support for github private docs"
 2268  git commit -m "added src and accessibility filters to search page"
 2269  git commit -m "added annotator table with assign annotator feature"
 2270  git push -u origin dev-frontend
 2271  git pull origin dev-frontend
 2272  git lo
 2273  npm i decompress
 2274  git checkout master
 2275  git clone https://github.com/pranshul24/Image-Annotation-Tool.git
 2276  cd Image-Annotation-Tool
 2277  git branch -b chirag-infopage
 2278  git checkout -b chirag-infopage
 2279  git commit -m "fixed left sidebar bug"
 2280  exit
 2281  npm i mongoose
 2282  touch /etc/apt/sources.list.d/mongodb-org-7.0.list
 2283  sudo touch /etc/apt/sources.list.d/mongodb-org-7.0.list
 2284  sudo systemctl start mongod
 2285  sudo service mongod restart\nsudo systemctl status mongod\n
 2286  # Stop the MongoDB service\nsudo service mongod stop\n\n# Remove MongoDB packages\nsudo apt-get purge mongodb-org*\n\n# Remove MongoDB data directory\nsudo rm -r /var/log/mongodb\nsudo rm -r /var/lib/mongodb\n\n# Remove the MongoDB user\nsudo userdel -r mongodb\n\n# Remove the MongoDB configuration directory\nsudo rm -r /etc/mongod.conf\n
 2287  sudo dpkg -i mongodb-org-server_7.0.3_amd64.deb
 2288  sudo systemctl service mongod stop
 2289  sudo systemctl stop mongod
 2290  npm uninstall mongoose
 2291  npm i mongoose=5.13.2
 2292  npm i mongoose@5.13.2
 2293  git commit -m "link icon added"
 2294  npx create-react-app react-flow-test
 2295  cd react-flow-test
 2296  npm install reactflow\n\n
 2297  git remote show origin
 2298  git commit -m "added react flow comp"
 2299  sudo kill 'sudo lsof -t -i:5001'\n
 2300  sudo kill -9 `sudo lsof -t -i:5001`\n
 2301  git commit -m "added chat, checkbox, select border and tooltip"
 2302  npx create-react-app react-highlight-texter
 2303  npm install react-highlight-words
 2304  git commit -m "added highlight text feature, ranked results, other cosmetics changes + refractored react page"
 2305  git commit -m "renamed frontend folder"
 2306  cd .. 
 2307  wget https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb
 2308  sudo apt-get purge mongodb-org*\nsudo rm -r /var/log/mongodb\nsudo rm -r /var/lib/mongodb
 2309  sudo apt purge mongo*
 2310  dpkg -l | grep mongo
 2311  sudo sed -i '/mongodb/d' /var/lib/dpkg/statoverride
 2312  sudo nano /var/lib/dpkg/statoverride\n
 2313  sudo dpkg -i google-chrome-stable_current_amd64.deb
 2314  sudo systemctl status mongod
 2315  git commit -m "added drive folder upload feature"
 2316  source /media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/venv/bin/activate
 2317  python -u "/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/util-testing/url-formatter.py"
 2318  git commit -m "impoved string match ranking with log function, added url formatter for google links"
 2319  git commit -m "added delete folder functionality"
 2320  cd "/media/chirag/DATA/" && g++ 930A.cpp -o 930A && "/media/chirag/DATA/"930A
 2321  cood
 2322  npx create-react-app d3-react
 2323  npm i d3
 2324  npm i reactflow
 2325  git commit -m "pre-final commit"
 2326  git commit -m "pre-final-1 commit"
 2327  git commit -m "pre-final-2 commit"
 2328  npm i uuid
 2329  git commit -m "handles failures while parsing and upserting"
 2330  git commit -m "added image route and updated annotators table"
 2331  git commit -m "added result pane for upadte, handled upsering errors and tested folder utility"
 2332  sudo snap remove unityhub\n
 2333  sudo apt remove unityhub\n
 2334  git commit -m "added/updated chat with reload, modified get_images api for annotators and admin/mod"
 2335  mongod
 2336  mongodb
 2337  mongo
 2338  sudo rm -r /var/log/mongodb /var/lib/mongodb\n
 2339  sudo apt-get purge mongodb-org*\n
 2340  sudo apt-get purge mongod*\n
 2341  sudo apt-get purge mongod\n
 2342  sudo service mongod stop\n\n
 2343  sudo apt-get purge "mongodb-org*"\n\n
 2344  sudo rm -r /var/log/mongodb\nsudo rm -r /var/lib/mongodb
 2345  service mongod status
 2346  cat /etc/lsb-release
 2347  sudo apt-get install gnupg curl
 2348  curl -fsSL https://pgp.mongodb.com/server-7.0.asc | \\n   sudo gpg -o /usr/share/keyrings/mongodb-server-7.0.gpg \\n   --dearmor
 2349  y
 2350  echo "deb [ arch=amd64,arm64 signed-by=/usr/share/keyrings/mongodb-server-7.0.gpg ] https://repo.mongodb.org/apt/ubuntu focal/mongodb-org/7.0 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-7.0.list
 2351  sudo apt-get install -y mongodb-org
 2352  echo "mongodb-org hold" | sudo dpkg --set-selections\necho "mongodb-org-database hold" | sudo dpkg --set-selections\necho "mongodb-org-server hold" | sudo dpkg --set-selections\necho "mongodb-mongosh hold" | sudo dpkg --set-selections\necho "mongodb-org-mongos hold" | sudo dpkg --set-selections\necho "mongodb-org-tools hold" | sudo dpkg --set-selections
 2353  sudo systemctl start mongod\n
 2354  sudo systemctl enable mongod\n
 2355  sudo systemctl restart mongod\n
 2356  sudo rm -rf /tmp/mongodb-27017.sock\nsudo service mongod start\n
 2357  sudo systemctl status mongod\n
 2358  tree utils
 2359  tree static
 2360  tree blueprints
 2361  tree error
 2362  tree templates
 2363  tree secrets
 2364  tree search-page-react
 2365  ls search-page-react
 2366  git commit -m "added developer doc"
 2367  git commit -m "updated developer doc"
 2368  sudo apt install resolvconf
 2369  systemctl start resolvconf
 2370  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.0/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.0/pythonFiles/deactivate/zsh/envVars.txt
 2371  git commit -m "updated folder upsertion with optional title and checkbox to include files"
 2372  systemctl enable resolvconf
 2373  sudo openvpn --config ubuntu_new.ovpn
 2374  git commit -m "added edit/delete functionality for a massage in ChatBox"
 2375  git commit -m "added assign user/moderator component handling all admin/mod/annotator roles"
 2376  git commit -m "added mongo dump"
 2377  git clone https://github.com/rug-compling/conllu-viewer.git
 2378  ./extract
 2379  ./form
 2380  sudo apt update\nsudo apt install apache2\n
 2381  sudo systemctl start apache2\n
 2382  systemctl status apache2
 2383  cd ../../..
 2384  cd BTP
 2385  touch index.html
 2386  sudo cp index.html /var/www/html/\n
 2387  cd /var/www/html/
 2388  cat index.html
 2389  sudo chown -R www-data:www-data /var/www/html\nsudo chmod -R 755 /var/www/html\n
 2390  sudo a2enmod cgi\n
 2391  sudo nano /etc/apache2/sites-available/000-default.conf\n
 2392  nano /usr/lib/cgi-bin/your-script.sh\n
 2393  chmod 400 /usr/lib/cgi-bin/your-script.sh
 2394  cd /usr/lib/cgi-bin/
 2395  touch script.sh
 2396  sudo nano /usr/lib/cgi-bin/your-script.sh
 2397  mv script.sh your-script.sh
 2398  sudo nano your-script.sh
 2399  sudo chmod +x /usr/lib/cgi-bin/your-script.sh\n
 2400  sudo systemctl restart apache2\n
 2401  sudo nano /var/log/apache2/error.log\n
 2402  ./conllu2svg example.conllu
 2403  ./conllu2svg example.conllu > text.html
 2404  pip install flask
 2405  git init\ngit add README.md\ngit commit -m "first commit"\ngit branch -M main\ngit remote add origin https://github.com/chir263/CONLLU-BTP-Task.git\ngit push -u origin main
 2406  git rm cached
 2407  git rm -cached
 2408  git rm --cached
 2409  git rm -cached venv
 2410  git rm --cached venv
 2411  git rm -r --cached venv
 2412  git commit -m "added .gitignore"
 2413  git commit -m "added requirements.text"
 2414  git clone https://github.com/iamadhee/llm-influencer.git
 2415  git clone https://github.com/huggingface/hfapi.git
 2416  python -u "/media/chirag/DATA/VLABS/social-media-post-generator/hf/hfapi/example.py"
 2417  git commit -m "updated docs"
 2418  pip -v
 2419  python --version
 2420  sudo apt update \nsudo apt install apt-transport-https ca-certificates gnupg 
 2421  curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add - \n
 2422  echo "deb https://packages.cloud.google.com/apt cloud-sdk main" | sudo tee -a /etc/apt/sources.list.d/google-cloud-sdk.list 
 2423  sudo apt update  \nsudo apt install google-cloud-sdk 
 2424  sudo gcloud init \n
 2425  ls
 2426  mkdir ast
 2427  gcloud app deploy
 2428  gcloud auth login
 2429  gcloud config set project 398511
 2430  gcloud config set project document-search-398511
 2431  ls
 2432  gcloud app deploy
 2433  code .
 2434  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 2435  ls -al
 2436  cd ..
 2437  ls -al
 2438  code .
 2439  rm -rf .git
 2440  gcloud auth login
 2441  gcloud config set project document-search-398511
 2442  gcloud app deploy
 2443  code .
 2444  npm start
 2445  mysql -u dfs_root -p
 2446  npm start
 2447  mogosh
 2448  mongosh
 2449  clear
 2450  npm start
 2451  htop
 2452  git status
 2453  git add .
 2454  git commit -m "added save and retieve annotation feature"
 2455  git push -u origin chirag-infopage
 2456  gcloud auth login
 2457  gcloud config set project document-search-398511
 2458  gcloud app deploy
 2459  pip --version
 2460  gcloud app deploy
 2461  pip --version
 2462  python --version
 2463  gcloud app deploy
 2464  code /usr/lib/google-cloud-sdk/platform/google_appengine/google/appengine/tools/devappserver2/runtime_factories.py\n
 2465  code /usr/lib/google-cloud-sdk/platform/google_appengine/google/\n
 2466  cd /usr/lib/google-cloud-sdk
 2467  ls
 2468  cd platform
 2469  l
 2470  ls
 2471  cd bq
 2472  ls
 2473  gcloud app deploy
 2474  gcloud auth login
 2475  gcloud config set project document-search-398511
 2476  gcloud app deploy
 2477  sudo rm python_compat.cpython-311.pyc
 2478  gcloud app deploy
 2479  code .
 2480  gcloud app deploy
 2481  python --version
 2482  gcloud app deploy
 2483  code .
 2484  gcloud components update\n
 2485  gcloud app deploy
 2486  code .
 2487  gcloud --version
 2488  gcloud app deploy
 2489  gcloud app deploy --timeout=20m
 2490  gcloud config set app/cloud_build_timeout 1200
 2491  gcloud app deploy
 2492  code .
 2493  cl
 2494  cle
 2495  clear
 2496  npm start
 2497  clear
 2498  npm start
 2499  clear
 2500  npm start
 2501  code .
 2502  gcloud app deploy
 2503  code .
 2504  gcloud app browse
 2505  pip freeze > requirements.txt
 2506  source venv/bin/activate
 2507  pip freeze > requirements.txt
 2508  code .
 2509  gcloud app deploy
 2510  code .
 2511  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 2512  source venv/bin/activate
 2513  clear
 2514  source venv/bin/activate
 2515  python server.py
 2516  python main.py
 2517  clear
 2518  gcloud app deploy
 2519  gcloud auth login
 2520  gcloud config set project document-search-398511
 2521  gcloud config set app/cloud_build_timeout 1200
 2522  gcloud app deploy
 2523  clear
 2524  npm start
 2525  python main.py
 2526  git status
 2527  code .
 2528  gcloud app deploy
 2529  gcloud app browse
 2530  npm run build
 2531  python main.py
 2532  gcloud app deploy
 2533  gcloud app browse
 2534  gcloud app deploy
 2535  gcloud app browse
 2536  python main.py
 2537  gcloud app deploy
 2538  gcloud app browse
 2539  code .
 2540  mysql -u dfs_root -p
 2541  clear
 2542  npm start
 2543  clear
 2544  npm start
 2545  clear
 2546  npm start
 2547  mongosh
 2548  code .
 2549  gcloud auth login
 2550  gcloud config set project document-search-398511
 2551  gcloud app deploy
 2552  gcloud app browse
 2553  python 
 2554  gcloud app browse
 2555  gcloud app deploy
 2556  gcloud app browse
 2557  code .
 2558  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 2559  source venv/bin/activate
 2560  python main.py
 2561  code .
 2562  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 2563  source venv/bin/activate
 2564  python main.py
 2565  clear
 2566  python main.py
 2567  npx create-react-app frontend
 2568  code .
 2569  cd .git
 2570  cd ..
 2571  rm -rf .git
 2572  cd backend
 2573  npm start
 2574  cd frontend
 2575  npm start
 2576  cd frontend
 2577  npm install -D tailwindcss\nnpx tailwindcss init\n
 2578  npm start
 2579  cd ../backend
 2580  npm install save googleapis
 2581  npm install googleapis
 2582  rm -rf .git
 2583  npm i nodemon
 2584  npm start
 2585  node
 2586  npm start
 2587  cd frontend
 2588  npm install --save jsoneditor jsoneditor-react\n
 2589  npm install jsoneditor jsoneditor-react\n
 2590  ls
 2591  npm install jsoneditor-react\n
 2592  npm install jsoneditor
 2593  npm install jsoneditor-react\n
 2594  ^[[200~npm i --save react-json-editor-ajrm~
 2595  npm i --save react-json-editor-ajrm
 2596  npm i jsoneditor-react
 2597  npm i jsoneditor-react@3.1.2\n
 2598  npm i jsoneditor@9.0.0
 2599  npm i jsoneditor-react@3.1.2\n
 2600  npm install react@17.0.0 react-dom@17.0.0\n
 2601  npm i jsoneditor-react@3.1.2\n
 2602  npm i jsoneditor-react@3.1.2 --force\n
 2603  npm start
 2604  npm i axios
 2605  import axios
 2606  npm i axios
 2607  npm i axios --force
 2608  npm install octokit/rest.js\n
 2609  npm i octokit
 2610  npm start
 2611  npm install @octokit/rest
 2612  clear
 2613  npm start
 2614  npm install @octokit/rest\n
 2615  npm start
 2616  npm cache clean --force\n
 2617  npm start
 2618  npm install @octokit/rest\n'
 2619  npm install @octokit/rest\n
 2620  npm config set registry https://registry.npmjs.org/\n
 2621  npm start
 2622  code .
 2623  clear
 2624  npm start
 2625  npm uninstall octokit
 2626  npm i @octokit/rest
 2627  npm i js-base64
 2628  clear
 2629  npm start
 2630  clear
 2631  npm start
 2632  clear
 2633  npm start
 2634  clear
 2635  npm i react-loading\n
 2636  npm i react-loading --force\n
 2637  npm run build
 2638  co
 2639  code .
 2640  git status
 2641  git init
 2642  rm -rf .git
 2643  cd ..
 2644  git init
 2645  git status
 2646  git add .
 2647  git commit -m "init setup"
 2648  git remote add origin https://github.com/chir263/vlabs-lab-deployment.git\ngit push -u origin main\n
 2649  git push -u origin master
 2650  git add .
 2651  git commit -m "init setup"
 2652  git push -u origin master
 2653  ht
 2654  htop
 2655  code .
 2656  clear
 2657  npm start
 2658  cd frontend
 2659  clear
 2660  npm start
 2661  code .
 2662  clear
 2663  npm start
 2664  clear
 2665  npm start
 2666  code .
 2667  clear
 2668  npm start
 2669  clear
 2670  npm start
 2671  clear
 2672  npm start
 2673  clear
 2674  npm start
 2675  npm i ajv
 2676  npm i ajv --force
 2677  npm i ajv@6.12.6
 2678  npm i ajv@6.12.6 --force
 2679  clear
 2680  npm start
 2681  git status
 2682  git add .
 2683  git commit -m "added validation to descriptor and add labs feature"
 2684  git push -u origin master
 2685  code .
 2686  clear
 2687  npm start
 2688  clear
 2689  npm start
 2690  git log
 2691  htop
 2692  code .
 2693  clear
 2694  npm start
 2695  clear
 2696  npm start
 2697  git clone https://github.com/john-smilga/react-course-v3.git
 2698  code .
 2699  git clone https://github.com/jherr/fcc-state.git
 2700  code .
 2701  
 2702  npm i; npm start
 2703  npm dev
 2704  npm preview
 2705  vite
 2706  vite preview
 2707  npm run dev
 2708  code .
 2709  clear
 2710  cd frontend
 2711  npm start
 2712  cd backend
 2713  npm start
 2714  code .
 2715  clear
 2716  npm start
 2717  clear
 2718  npm start
 2719  htop
 2720  git status
 2721  git add .
 2722  git commit -m "added deployment lab list feature"
 2723  git push -u origin master
 2724  code .
 2725  cd backend
 2726  npm start
 2727  cd frontend
 2728  npm start
 2729  cd frontend
 2730  npm i better-ajv-errors
 2731  npm i better-ajv-errors --force
 2732  npm uninstall better-ajv-errors
 2733  npm uninstall better-ajv-errors --force
 2734  npm i better-ajv-errors
 2735  npm update\n
 2736  npm i better-ajv-errors --force
 2737  npm uninstall better-ajv-errors --force
 2738  code .
 2739  clear
 2740  npm start
 2741  clear
 2742  npm start
 2743  code .
 2744  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 2745  python app.py
 2746  source venv/bin/activate
 2747  app.py
 2748  python app.py
 2749  code .
 2750  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 2751  git clone https://github.com/UniversalDependencies/universaldependencies.github.io.git
 2752  code .
 2753  touch example.conllu
 2754  npx create-next-app@latest tutorial
 2755  code .
 2756  npm run dev
 2757  npm i axios bcryptjs jsonwebtoken nodemailer react-hot-toast mongoose
 2758  htop
 2759  git clone https://github.com/keithweaver/MERN-boilerplate.git
 2760  code .
 2761  npm install
 2762  npm install --force
 2763  code .
 2764  clear
 2765  npm start
 2766  clear
 2767  npm start
 2768  cd backend
 2769  npm i passport passport-github2\n
 2770  npm i react-router-dom
 2771  npm i react-router-dom --force
 2772  npm start
 2773  npm install @testing-library/jest-dom@latest\n
 2774  npm install @testing-library/react@latest\n
 2775  npm install @testing-library/react@11.2.7\n
 2776  npm install @testing-library/jest-dom@5.14.1\n
 2777  npm install @testing-library/user-event@12.8.3\n
 2778  git status
 2779  git add .
 2780  git commit -m "added github oauth with cosmetic changes"
 2781  git push -u origin master
 2782  code .
 2783  npm run dev
 2784  code .
 2785  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 2786  touch ex.conllu
 2787  node conllu2svg.js ex.conllu > index.html
 2788  code .
 2789  node "/media/chirag/DATA/BTP/dsds/index.js"
 2790  npm init
 2791  npm i express body-parser
 2792  node "/media/chirag/DATA/BTP/dsds/index.js"
 2793  npm i nodemon
 2794  npm start
 2795  npm i cors
 2796  npm start
 2797  echo "# btp-conllu-server" >> README.md\ngit init\ngit add README.md\ngit commit -m "first commit"\ngit branch -M main\ngit remote add origin https://github.com/chir263/btp-conllu-server.git\ngit push -u origin main
 2798  git add .
 2799  git commit -m "init setup"
 2800  git push -u origin main
 2801  touch token
 2802  code .
 2803  git status
 2804  git add .
 2805  git commit -m "updated error handling"
 2806  git push -u origin main
 2807  code .
 2808  npm run build
 2809  code .
 2810  clear
 2811  npm start
 2812  clear
 2813  npm start
 2814  kill $(lsof -ti :$3000)
 2815  sudo kill -9 $(sudo lsof -t -i:3000)\n
 2816  npm start
 2817  code .
 2818  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 2819  clear
 2820  source venv/bin/activate
 2821  python main.py
 2822  cd search-page-reacta
 2823  cd search-page-react
 2824  npm start
 2825  code .
 2826  source venv/bin/activate
 2827  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 2828  pip install googleapiclient
 2829  pip install google-api-python-client google-auth-httplib2 google-auth-oauthlib PyPDF2\n
 2830  python test.py
 2831  pip install PyMuPDF==1.18.16
 2832  python test.py
 2833  python main.py
 2834  cd ^[[200~/media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/utils/pdf_downloads/~
 2835  cd media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/utils/pdf_downloads
 2836  cd /media/chirag/DATA/VLABS/vlabs-semantic-search/tool-doc-search/utils/pdf_downloads
 2837  code .
 2838  gcloud auth login
 2839  gcloud config set project document-search-398511
 2840  gcloud app deploy
 2841  gcloud app browse
 2842  code .
 2843  python app.py
 2844  source venv/bin/activate
 2845  python -m venv venv\n
 2846  source venv/bin/activate
 2847  pip install -r requirements.txt
 2848  python app.py
 2849  pip install googleapiclient
 2850  pip install google-api-python-client\n
 2851  pip install oauth2client\n
 2852  python app.py
 2853  code .
 2854  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 2855  source venv/bin/activate
 2856  python main.py
 2857  python
 2858  code .
 2859  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 2860  clear
 2861  source venv/bin/activate
 2862  python main.py
 2863  code .
 2864  gcloud app browse
 2865  gcloud app deploy
 2866  gcloud app browse
 2867  clear
 2868  sudo apt install build-essential\nsudo apt install mpich
 2869  clear
 2870  code .
 2871  npm start
 2872  npm run build
 2873  code .
 2874  mpicc mpi-example.c
 2875  mpirun -np 1 a.out
 2876  mpirun -np 1 ./a.out
 2877  code .
 2878  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 2879  clear
 2880  source venv/bin/activate
 2881  python main.py
 2882  clear
 2883  python main.py
 2884  htop
 2885  lsof -i :5000
 2886  htop
 2887  code .
 2888  gcloud app deploy
 2889  gcloud app logs tail -s default
 2890  gcloud app browse
 2891  code .
 2892  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 2893  python main.py
 2894  clear
 2895  source venv/bin/activate
 2896  python main.py
 2897  gcloud app deploy
 2898  gcloud app logs tail -s default
 2899  gcloud app browse
 2900  code .
 2901  cd backend
 2902  npm start
 2903  cd frontend
 2904  npm start
 2905  gcloud app logs tail -s default
 2906  clear
 2907  git status
 2908  git add .
 2909  git commit -m "updated for first dployment"
 2910  git push -u origin dev
 2911  git add .
 2912  git commit -m "updated readme"
 2913  git push -u origin dev -f
 2914  code .
 2915  clear
 2916  npm start
 2917  clear
 2918  npm start
 2919  sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys E298A3A825C0D65DFD57CBB651716619E084DAB9
 2920  sudo add-apt-repository 'deb https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/'
 2921  sudo apt install r-base
 2922  sudo -i R
 2923  sudo apt-key adv --keyserver keys.gnupg.net --recv-keys 3F32EE77E331692F\n
 2924  sudo add-apt-repository "deb http://cran.rstudio.com/bin/linux/ubuntu $(lsb_release -cs)-cran40/"\n
 2925  sudo apt install -y rstudio\n
 2926  sudo apt update\n
 2927  sudo apt install -y rstudio\n
 2928  sudo apt install gdebi-core
 2929  sudo apt install r-base
 2930  wget https://download2.rstudio.org/server/bionic/amd64/rstudio-server-2021.09.1-372-amd64.deb\n
 2931  sudo gdebi rstudio-server-2021.09.1-372-amd64.deb\n
 2932  rstudio
 2933  wget https://download1.rstudio.org/electron/focal/amd64/rstudio-2023.06.1-524-amd64.deb\nsudo apt install -f ./rstudio-2023.06.1-524-amd64.deb
 2934  rstudio
 2935  mpi
 2936  code .
 2937  git status
 2938  node conllu2svg.js input.conllu > index.html
 2939  git add .
 2940  git commit -m "added some cosmetic changes"
 2941  git push -u origin main
 2942  lscpu
 2943  htop
 2944  code .
 2945  clear
 2946  npm start
 2947  clear
 2948  npm start
 2949  code .
 2950  npm run dev
 2951  code .
 2952  mpicc mpi_nqueens.c -o mpi_nqueens\n
 2953  mpicc q1.c -o q1
 2954  mpicc q1.cpp -o q1
 2955  mpirun -np 4 ./q1
 2956  mpicc q1.cpp -o q1
 2957  mpirun -np 4 ./q1
 2958  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q1/" && g++ q1_orig.cpp -o q1_orig && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q1/"q1_orig
 2959  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q1/" && g++ q1.cpp -o q1 && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q1/"q1
 2960  mpirun -np 4 ./q1
 2961  mpicc q1.cpp -o q1
 2962  mpirun -np 4 ./q1
 2963  mpicc q1.cpp -o q1
 2964  mpirun -np 4 ./q1
 2965  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q1/" && g++ q1_orig.cpp -o q1_orig && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q1/"q1_orig
 2966  mpicc q1.cpp -o q1
 2967  mpirun -np 4 ./q1
 2968  mpirun -np 8 ./q1
 2969  mpirun -np 6 ./q1
 2970  mpirun -np 8 ./q1
 2971  mpicc q1.cpp -o q1
 2972  mpirun -np 4 ./q1
 2973  clear
 2974  mpirun -np 4 ./q1
 2975  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q1/" && g++ q1_orig.cpp -o q1_orig && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q1/"q1_orig
 2976  mpirun -np 4 ./q1
 2977  code .
 2978  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/" && g++ q2.cpp -o q2 && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/"q2
 2979  mpicc q2.cpp -o q2
 2980  clear
 2981  mpicc q2.cpp -o q2
 2982  mpirun -np 4 ./q2
 2983  clear
 2984  mpirun -np 4 ./q2
 2985  mpicc q2.cpp -o q2
 2986  mpirun -np 4 ./q2
 2987  mpicc q2.cpp -o q2
 2988  mpirun -np 4 ./q2
 2989  mpicc q2.cpp -o q2
 2990  mpirun -np 4 ./q2
 2991  mpicc q2.cpp -o q2
 2992  mpirun -np 4 ./q2
 2993  mpicc q2.cpp -o q2
 2994  mpirun -np 4 ./q2
 2995  mpicc q2.cpp -o q2
 2996  mpirun -np 4 ./q2
 2997  mpicc q2.cpp -o q2
 2998  mpirun -np 4 ./q2
 2999  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/" && g++ q2_orig.cpp -o q2_orig && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/"q2_orig
 3000  mpicc q2.cpp -o q2
 3001  mpirun -np 4 ./q2
 3002  mpicc q2.cpp -o q2
 3003  mpirun -np 4 ./q2
 3004  mpicc q2.cpp -o q2
 3005  mpirun -np 4 ./q2
 3006  mpicc q2.cpp -o q2
 3007  mpirun -np 4 ./q2
 3008  mpicc q2.cpp -o q2
 3009  mpirun -np 4 ./q2
 3010  mpirun -np 4 ./q2 > result.txt
 3011  mpicc q2.cpp -o q2
 3012  mpirun -np 4 ./q2 > result.txt
 3013  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/" && g++ q2_orig.cpp -o q2_orig && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/"q2_orig
 3014  mpicc q2.cpp -o q2
 3015  mpirun -np 4 ./q2 > result.txt
 3016  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/" && g++ q2_orig.cpp -o q2_orig && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/"q2_orig
 3017  clear
 3018  mpicc q2.cpp -o q2
 3019  mpirun -np 4 ./q2 > result.txt
 3020  mpicc q2.cpp -o q2
 3021  mpirun -np 4 ./q2 > result.txt
 3022  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/" && g++ q2_orig.cpp -o q2_orig && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/"q2_orig
 3023  mpicc q2.cpp -o q2
 3024  cd q2
 3025  clear
 3026  mpicc q2.cpp -o q2
 3027  mpirun -np 4 ./q2 > result.txt
 3028  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q1/" && g++ q1_orig.cpp -o q1_orig && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q1/"q1_orig
 3029  clear
 3030  mpicc q2.cpp -o q2
 3031  cd ../q2
 3032  mpicc q2.cpp -o q2
 3033  mpirun -np 4 ./q2 > result.txt
 3034  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/" && g++ q2_orig.cpp -o q2_orig && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/"q2_orig
 3035  clear
 3036  mpicc q2.cpp -o q2
 3037  mpirun -np 4 ./q2 > result.txt
 3038  mpicc q2.cpp -o q2
 3039  mpirun -np 4 ./q2 > result.txt
 3040  mpicc q2.cpp -o q2
 3041  mpirun -np 4 ./q2 > result.txt
 3042  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/" && g++ q2_orig.cpp -o q2_orig && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/"q2_orig
 3043  mpirun -np 8 ./q2 > result.txt
 3044  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/" && g++ q2_orig.cpp -o q2_orig && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/"q2_orig
 3045  mpicc q2.cpp -o q2
 3046  mpirun -np 8 ./q2 > result.txt
 3047  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/" && g++ q2_new.cpp -o q2_new && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q2/"q2_new
 3048  mpicc q2_new.cpp -o q2
 3049  mpic++ q2_new.cpp -o q2
 3050  mpirun -np 4 ./q2 > result.txt
 3051  mpic++ q2_new.cpp -o q2
 3052  mpirun -np 4 ./q2 > result.txt
 3053  mpirun -np 4 ./q2 
 3054  clear
 3055  mpic++ q2_new.cpp -o q2
 3056  mpirun -np 4 ./q2
 3057  mpic++ q2_new.cpp -o q2
 3058  mpirun -np 4 ./q2
 3059  mpic++ q2_new.cpp -o q2
 3060  mpirun -np 4 ./q2
 3061  mpic++ q2_new.cpp -o q2
 3062  mpirun -np 4 ./q2
 3063  mpic++ q2_new.cpp -o q2
 3064  mpirun -np 4 ./q2
 3065  mpirun -np 8 ./q2
 3066  mpirun -np 5 ./q2
 3067  mpic++ q2_new.cpp -o q2
 3068  mpirun -np 5 ./q2
 3069  mpic++ q2_new.cpp -o q2
 3070  mpirun -np 5 ./q2
 3071  mpic++ q2_new.cpp -o q2
 3072  mpirun -np 5 ./q2
 3073  mpic++ q2_new.cpp -o q2
 3074  mpirun -np 5 ./q2
 3075  mpic++ q2_new.cpp -o q2
 3076  mpirun -np 5 ./q2
 3077  mpic++ q2_new.cpp -o q2
 3078  mpirun -np 5 ./q2
 3079  mpic++ q2_new.cpp -o q2
 3080  mpirun -np 5 ./q2
 3081  mpic++ q2_new.cpp -o q2
 3082  mpirun -np 5 ./q2
 3083  mpic++ q2_new.cpp -o q2
 3084  mpirun -np 5 ./q2
 3085  mpic++ q2_new.cpp -o q2
 3086  mpirun -np 5 ./q2
 3087  mpic++ q2_new.cpp -o q2
 3088  mpirun -np 5 ./q2
 3089  mpic++ q2_new.cpp -o q2
 3090  mpirun -np 5 ./q2
 3091  mpic++ q2_new.cpp -o q2
 3092  clear
 3093  mpic++ q2_new.cpp -o q2
 3094  mpirun -np 5 ./q2
 3095  mpic++ q2_new.cpp -o q2
 3096  mpirun -np 5 ./q2
 3097  mpic++ q2_new.cpp -o q2
 3098  mpirun -np 5 ./q2
 3099  mpic++ q2_new.cpp -o q2
 3100  mpirun -np 5 ./q2
 3101  mpic++ q2_new.cpp -o q2
 3102  mpirun -np 5 ./q2
 3103  mpic++ q2_new.cpp -o q2
 3104  mpirun -np 5 ./q2
 3105  mpirun -np 4 ./q2
 3106  mpic++ q2_new.cpp -o q2
 3107  mpirun -np 4 ./q2
 3108  mpic++ q2_new.cpp -o q2
 3109  mpirun -np 4 ./q2
 3110  mpic++ q2_new.cpp -o q2
 3111  mpirun -np 4 ./q2
 3112  mpic++ q2_new.cpp -o q2
 3113  mpirun -np 4 ./q2
 3114  mpic++ q2_new.cpp -o q2
 3115  mpirun -np 4 ./q2
 3116  mpic++ q2_new.cpp -o q2
 3117  mpirun -np 4 ./q2
 3118  mpic++ q2_new.cpp -o q2
 3119  mpirun -np 4 ./q2
 3120  mpic++ q2_new.cpp -o q2
 3121  mpirun -np 4 ./q2
 3122  mpic++ q2_new.cpp -o q2
 3123  mpirun -np 4 ./q2
 3124  mpic++ q2_new.cpp -o q2
 3125  mpirun -np 4 ./q2
 3126  mpic++ q2_new.cpp -o q2
 3127  mpirun -np 4 ./q2
 3128  mpic++ q2_new.cpp -o q2
 3129  mpirun -np 4 ./q2
 3130  mpic++ q2_new.cpp -o q2
 3131  mpirun -np 4 ./q2
 3132  mpic++ q2_new.cpp -o q2
 3133  mpirun -np 4 ./q2
 3134  mpic++ q2_new.cpp -o q2
 3135  mpirun -np 4 ./q2
 3136  mpic++ q2_new.cpp -o q2
 3137  mpirun -np 4 ./q2
 3138  mpic++ q2_new.cpp -o q2
 3139  mpirun -np 4 ./q2
 3140  mpirun -np 2 ./q2
 3141  mpirun -np 1 ./q2
 3142  mpirun -np 2 ./q2
 3143  mpirun -np 8 ./q2
 3144  mpirun -np 4 ./q2
 3145  clear
 3146  mpic++ q2_new.cpp -o q2
 3147  mpirun -np 4 ./q2
 3148  mpirun -np 2 ./q2
 3149  mpic++ q2_new.cpp -o q2
 3150  mpirun -np 2 ./q2
 3151  mpirun -np 5 ./q2
 3152  mpirun -np 8 ./q2
 3153  clear
 3154  mpic++ q2_new.cpp -o q2
 3155  mpirun -n 8 ./q2
 3156  mpic++ q2_new.cpp -o q2
 3157  mpirun -n 8 ./q2
 3158  mpirun -n 4 ./q2
 3159  mpirun -n 1 ./q2
 3160  mpirun -n 4 ./q2
 3161  mpirun -n 1 ./q2
 3162  clear
 3163  mpic++ q2_new.cpp -o q2
 3164  mpirun -n 1 ./q2
 3165  mpirun -n 4 ./q2
 3166  mpirun -n 8 ./q2
 3167  mpirun -n 6 ./q2
 3168  mpirun -n 8 ./q2
 3169  mpirun -n 1 ./q2
 3170  mpirun -n 4 ./q2
 3171  mpirun -n 1 ./q2
 3172  clear
 3173  mpic++ q2_new.cpp -o q2
 3174  mpirun -n 1 ./q2
 3175  mpic++ q2_new.cpp -o q2
 3176  mpirun -n 4 ./q2
 3177  mpic++ q2_new.cpp -o q2
 3178  mpirun -n 8 ./q2
 3179  code .
 3180  mpic++ q2_new.cpp -o q2
 3181  cd q2
 3182  clear
 3183  mpic++ q2_new.cpp -o q2
 3184  mpirun -n 1 ./q2
 3185  mpic++ q2_new.cpp -o q2
 3186  mpirun -n 4 ./q2
 3187  mpirun -n 1 ./q2
 3188  mpirun -n 4 ./q2
 3189  mpirun -n 8 ./q2
 3190  mpic++ q2_new.cpp -o q2
 3191  clear
 3192  mpirun -n 1 ./q2
 3193  mpirun -n 4 ./q2
 3194  mpirun -n 8 ./q2
 3195  mpic++ q2_new.cpp -o q2
 3196  mpirun -n 8 ./q2
 3197  mpirun -n 4 ./q2
 3198  clear
 3199  mpic++ q2_new.cpp -o q2
 3200  mpirun -n 4 ./q2
 3201  mpirun -n 1 ./q2
 3202  mpic++ q2_new.cpp -o q2
 3203  mpirun -n 1 ./q2
 3204  mpirun -n 4 ./q2
 3205  mpirun -n 1 ./q2
 3206  mpirun -n 4 ./q2
 3207  code --remote-debugging-port=9222\n
 3208  # Clone this repository\ngit clone https://github.com/electron/electron-quick-start\n# Go into the repository\ncd electron-quick-start\n# Install dependencies\nnpm install\n# Run the app\nnpm start
 3209  code .
 3210  npm start
 3211  python -u "/media/chirag/DATA/CODE_AMA/electron-js/electron-quick-start/t.py"
 3212  cd "/media/chirag/DATA/CODE_AMA/electron-js/electron-quick-start/" && g++ x.cpp -o x && "/media/chirag/DATA/CODE_AMA/electron-js/electron-quick-start/"x
 3213  g++ f1.cpp f2.cpp 
 3214  cd "/media/chirag/DATA/CODE_AMA/electron-js/electron-quick-start/" && g++ f2.cpp -o f2 && "/media/chirag/DATA/CODE_AMA/electron-js/electron-quick-start/"f2
 3215  cd "/media/chirag/DATA/CODE_AMA/electron-js/electron-quick-start/" && g++ x.cpp -o x && "/media/chirag/DATA/CODE_AMA/electron-js/electron-quick-start/"x
 3216  code .
 3217  git init
 3218  git remote add origin https://github.com/chir263/CONLLU-BTP-Task-2.git\ngit branch -M main\ngit push -u origin main
 3219  git add .
 3220  git commit -m "init setup"
 3221  git remote add origin https://github.com/chir263/CONLLU-BTP-Task-2.git\ngit branch -M main\ngit push -u origin main
 3222  code .
 3223  clear
 3224  mpirun -n 1 ./q2
 3225  mpirun -n 4 ./q2
 3226  mpirun -n 1 ./q2
 3227  mpic++ q2_new.cpp -o q2
 3228  mpirun -n 1 ./q2
 3229  mpirun -n 4 ./q2
 3230  mpirun -n 8 ./q2
 3231  mpirun -n 4 ./q2
 3232  mpic++ q2_new.cpp -o q2
 3233  mpirun -n 4 ./q2
 3234  mpic++ q2_new.cpp -o q2
 3235  mpirun -n 4 ./q2
 3236  clear
 3237  mpic++ q2_new.cpp -o q2
 3238  mpirun -n 4 ./q2
 3239  mpic++ q2_new.cpp -o q2
 3240  mpirun -n 4 ./q2
 3241  mpirun -n 1 ./q2
 3242  mpic++ q2_new.cpp -o q2
 3243  mpirun -n 1 ./q2
 3244  mpic++ q2_new.cpp -o q2
 3245  mpirun -n 1 ./q2
 3246  mpirun -n 4 ./q2
 3247  cd ../q1
 3248  mpirun -n 4 ./q1
 3249  mpirun -n 8 ./q1
 3250  mpirun -n 4 ./q1
 3251  ./q1_orig
 3252  code .
 3253  clear
 3254  npm start
 3255  clear
 3256  npm start
 3257  npm init
 3258  code .
 3259  npm i axios
 3260  node "/media/chirag/DATA/VLABS/vlabs-workflow/tets/main.js"
 3261  clear
 3262  node "/media/chirag/DATA/VLABS/vlabs-workflow/tets/main.js"
 3263  npm start
 3264  git status
 3265  git add .
 3266  git commit -m "added github workflow api"
 3267  git push -u origin master
 3268  co
 3269  code .
 3270  cd backend
 3271  npm start
 3272  cd frontend
 3273  npm start
 3274  code .
 3275  cd backend
 3276  cd frontend
 3277  npm start
 3278  git add .
 3279  git commit -m "added update lasb feature in backend"
 3280  git status
 3281  git push -u origin master
 3282  code .
 3283  clear
 3284  npm start
 3285  clear
 3286  npm start
 3287  code .
 3288  clear
 3289  npm start
 3290  clear
 3291  npm start
 3292  gcloud app logs tail -s default
 3293  code .
 3294  python -m venv venv\n
 3295  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 3296  code .
 3297  clear
 3298  npm start
 3299  clear
 3300  npm start
 3301  clear
 3302  git status
 3303  git add .
 3304  git commit -m "resolved default branch issue"
 3305  git push -u origin master
 3306  npm start
 3307  code .
 3308  clear
 3309  git add .
 3310  git status
 3311  git commit -m "added changes"
 3312  git push -u origin main
 3313  code .
 3314  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 3315  code .
 3316  clear
 3317  git add .
 3318  git commit -m "resolved png bug"
 3319  git push -u origin main
 3320  code .
 3321  htop
 3322  code .
 3323  clear
 3324  npm start
 3325  clear
 3326  npm start
 3327  clear
 3328  git status
 3329  git add .
 3330  git commit -m "added tags and analytics"
 3331  git push -u origin main
 3332  git push -u origin master
 3333  code .
 3334  cd ../q3
 3335  clear
 3336  mpic++ q.cpp -o q
 3337  mpirun -n 4 ./q
 3338  git init
 3339  mpic++ q.cpp -o q
 3340  clear
 3341  mpirun -n 4 ./q
 3342  mpic++ q.cpp -o q
 3343  mpirun -n 4 ./q
 3344  clear
 3345  mpic++ q.cpp -o q
 3346  mpirun -n 4 ./q
 3347  mpic++ q.cpp -o q
 3348  mpirun -n 4 ./q
 3349  clear
 3350  mpirun -n 4 ./q
 3351  clear
 3352  mpic++ q.cpp -o q
 3353  mpirun -n 4 ./q
 3354  clear
 3355  mpic++ q.cpp -o q
 3356  mpirun -n 4 ./q
 3357  clear
 3358  mpic++ q.cpp -o q
 3359  mpirun -n 4 ./q
 3360  clear
 3361  mpic++ q.cpp -o q
 3362  mpirun -n 4 ./q
 3363  mpic++ q.cpp -o q
 3364  mpirun -n 4 ./q
 3365  mpic++ q.cpp -o q
 3366  mpirun -n 4 ./q
 3367  mpic++ q.cpp -o q
 3368  mpirun -n 4 ./q
 3369  mpic++ q.cpp -o q
 3370  mpirun -n 4 ./q
 3371  mpic++ q.cpp -o q
 3372  mpirun -n 4 ./q
 3373  clear
 3374  mpic++ q.cpp -o q
 3375  clear
 3376  mpirun -n 4 ./q
 3377  mpic++ q.cpp -o q
 3378  mpirun -n 4 ./q
 3379  clear
 3380  mpic++ q.cpp -o q
 3381  mpirun -n 4 ./q
 3382  clear
 3383  mpic++ q.cpp -o q
 3384  mpirun -n 4 ./q
 3385  mpic++ q.cpp -o q
 3386  mpirun -n 4 ./q
 3387  code .
 3388  clear
 3389  mpic++ q.cpp -o q
 3390  mpirun -n 4 ./q
 3391  clear
 3392  mpic++ q.cpp -o q
 3393  mpirun -n 4 ./q
 3394  mpirun -n 2 ./q
 3395  mpic++ q.cpp -o q
 3396  mpirun -n 2 ./q
 3397  code .
 3398  python -m venv venv\n
 3399  source venv/bin/activate
 3400  pip install numpy pandas
 3401  code .
 3402  source venv/bin/activate
 3403  pip install sklearn
 3404  pip install pip install scikit-learn\n
 3405  code .
 3406  mpic++ q.cpp -o q
 3407  mpirun -n 4 ./q
 3408  mpirun -n 1 ./q
 3409  mpic++ q.cpp -o q
 3410  mpirun -n 4 ./q
 3411  clear
 3412  mpic++ q.cpp -o q
 3413  clear
 3414  g++ testmatrix.cpp
 3415  ./a.out > input.txt
 3416  mpic++ q.cpp -o q
 3417  mpirun -n 4 ./q
 3418  g++ testmatrix.cpp
 3419  ./a.out > input.txt
 3420  mpirun -n 4 ./q
 3421  mpirun -n 1 ./q
 3422  g++ testmatrix.cpp
 3423  ./a.out > input.txt
 3424  mpirun -n 4 ./q
 3425  mpic++ q.cpp -o q
 3426  mpirun -n 4 ./q
 3427  mpic++ q.cpp -o q
 3428  mpirun -n 4 ./q
 3429  mpic++ q.cpp -o q
 3430  mpirun -n 4 ./q
 3431  mpic++ q.cpp -o q
 3432  mpirun -n 4 ./q
 3433  mpic++ q.cpp -o q
 3434  mpirun -n 4 ./q
 3435  mpic++ q.cpp -o q
 3436  mpirun -n 4 ./q
 3437  mpic++ q.cpp -o q
 3438  mpirun -n 4 ./q
 3439  mpic++ q.cpp -o q
 3440  mpirun -n 4 ./q
 3441  mpic++ q.cpp -o q
 3442  mpirun -n 4 ./q
 3443  mpic++ q.cpp -o q
 3444  mpirun -n 4 ./q
 3445  mpic++ q.cpp -o q
 3446  mpirun -n 4 ./q
 3447  mpic++ q.cpp -o q
 3448  mpirun -n 4 ./q
 3449  clear
 3450  mpic++ q.cpp -o q
 3451  mpirun -n 4 ./q
 3452  mpic++ q.cpp -o q
 3453  mpirun -n 4 ./q
 3454  mpic++ q.cpp -o q
 3455  mpirun -n 4 ./q
 3456  mpirun -n 4 ./q > output.txt
 3457  mpirun -n 4 ./q
 3458  mpic++ q.cpp -o q
 3459  mpirun -n 4 ./q
 3460  clear
 3461  mpic++ q.cpp -o q
 3462  mpirun -n 4 ./q
 3463  clear
 3464  mpic++ q.cpp -o q
 3465  mpirun -n 4 ./q
 3466  mpic++ q.cpp -o q
 3467  mpirun -n 4 ./q
 3468  mpic++ q.cpp -o q
 3469  mpirun -n 4 ./q
 3470  mpic++ q.cpp -o q
 3471  mpirun -n 4 ./q
 3472  mpic++ q.cpp -o q
 3473  mpirun -n 4 ./q
 3474  mpic++ q.cpp -o q
 3475  mpirun -n 4 ./q
 3476  mpic++ q.cpp -o q
 3477  mpirun -n 4 ./q
 3478  mpic++ q.cpp -o q
 3479  mpirun -n 4 ./q
 3480  mpic++ q.cpp -o q
 3481  mpirun -n 4 ./q
 3482  mpic++ q.cpp -o q
 3483  mpirun -n 4 ./q
 3484  mpic++ q.cpp -o q
 3485  mpirun -n 4 ./q
 3486  mpic++ q.cpp -o q
 3487  mpirun -n 4 ./q
 3488  mpirun -n 1 ./q
 3489  mpirun -n 4 ./q
 3490  mpirun -n 8 ./q
 3491  mpirun -n 1 ./q
 3492  mpic++ q.cpp -o q
 3493  mpirun -n 1 ./q
 3494  mpirun -n 4 ./q
 3495  mpic++ q.cpp -o q
 3496  mpirun -n 4 ./q
 3497  mpic++ q.cpp -o q
 3498  mpirun -n 4 ./q
 3499  mpic++ q.cpp -o q
 3500  mpirun -n 4 ./q > output.txt
 3501  mpirun -n 1 ./q > output.txt
 3502  mpic++ q.cpp -o q
 3503  mpirun -n 1 ./q > output.txt
 3504  mpirun -n 4 ./q > output.txt
 3505  mpirun -n 1 ./q > output.txt
 3506  mpirun -n 4 ./q > output.txt
 3507  mpirun -n 1 ./q > output.txt
 3508  mpirun -n 4 ./q > output.txt
 3509  mpirun -n 1 ./q > output.txt
 3510  g++ testmatrix.cpp
 3511  ./a.out > input.txt
 3512  mpirun -n 1 ./q > output.txt
 3513  mpirun -n 4 ./q > output.txt
 3514  mpirun -n 1 ./q > output.txt
 3515  mpirun -n 4 ./q > output.txt
 3516  mpic++ kawde.cpp -o q
 3517  mpirun -n 4 ./q > output.txt
 3518  mpirun -n 4 ./q < input.txt > output.txt
 3519  mpirun -n 1 ./q < input.txt > output.txt
 3520  mpirun -n 4 ./q < input.txt > output.txt
 3521  mpic++ q.cpp -o q
 3522  mpirun -n 4 ./q < input.txt > output.txt
 3523  mpirun -n 1 ./q < input.txt > output.txt
 3524  mpirun -n 4 ./q < input.txt > output.txt
 3525  mpirun -n 1 ./q < input.txt > output.txt
 3526  mpirun -n 2 ./q < input.txt > output.txt
 3527  mpirun -n 3 ./q < input.txt > output.txt
 3528  mpirun -n 5 ./q < input.txt > output.txt
 3529  mpirun -n 1 ./q < input.txt > output.txt
 3530  mpirun -n 6 ./q < input.txt > output.txt
 3531  mpirun -n 8 ./q < input.txt > output.txt
 3532  mpirun -n 4 ./q < input.txt > output.txt
 3533  mpirun -n 1 ./q < input.txt > output.txt
 3534  mpic++ q.cpp -o q
 3535  mpirun -n 1 ./q < input.txt > output.txt
 3536  clear
 3537  git status
 3538  git add .
 3539  git commit -m "init"
 3540  git remote add origin https://github.com/chir263/ds-assign-1.git\ngit push -u origin main\n
 3541  git push -u origin master
 3542  cd q1
 3543  clear
 3544  mpirun -n 1 ./q1
 3545  mpirun -n 4 ./q1
 3546  mpirun -n 1 ./q1
 3547  mpirun -n 5 ./q1
 3548  mpirun -n 4 ./q1
 3549  cd "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q1/" && g++ q1_orig.cpp -o q1_orig && "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_1/q1/"q1_orig
 3550  code .
 3551  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 3552  source venv/bin/activate
 3553  pip install matplotlib
 3554  htop
 3555  code .
 3556  1.csv
 3557  touch 1.csv
 3558  code .
 3559  pip install matplotlib pandas numpy
 3560  pip install seaborn
 3561  pip install matplotlib_venn\n\n\n\n\n\n
 3562  statsmodels
 3563  pip install statsmodels
 3564  code .
 3565  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2023.22.1/pythonFiles/deactivate/zsh/envVars.txt
 3566  code .
 3567  pip install sklearn
 3568  code .
 3569  pip install --upgrade seaborn matplotlib\n
 3570  code .
 3571  clear
 3572  npm start
 3573  clear
 3574  npm start
 3575  code .
 3576  clear
 3577  npm start
 3578  clear
 3579  npm start
 3580  clear
 3581  cd frontend
 3582  npm install react-table\n
 3583  npm install @table-library/react-table-library @emotion/react
 3584  npm start
 3585  npm i react-data-table-component
 3586  code .
 3587  clear
 3588  mpirun -n 4 ./q1
 3589  ./q1_orig
 3590  mpirun -n 4 ./q1
 3591  ./q1_orig
 3592  mpirun -n 4 ./q1
 3593  mpirun -n 1 ./q1
 3594  mpirun -n 4 ./q1
 3595  mpirun -n 7 ./q1
 3596  mpirun -n 1 ./q1
 3597  mpic++ q.cpp -o q
 3598  mpic++ q1.cpp -o q
 3599  mpirun -n 1 ./q
 3600  mpirun -n 4 ./q
 3601  mpic++ q1.cpp -o q
 3602  mpirun -n 4 ./q
 3603  mpic++ q1.cpp -o q
 3604  mpirun -n 4 ./q
 3605  cd ../q2
 3606  clear
 3607  mpic++ q2_new.cpp -o q2
 3608  mpirun -n 4 ./q2
 3609  mpic++ q2_new.cpp -o q2
 3610  mpirun -n 4 ./q2
 3611  mpic++ q2_new.cpp -o q2
 3612  mpirun -n 4 ./q2
 3613  mpic++ q2_new.cpp -o q2
 3614  mpirun -n 4 ./q2
 3615  mpic++ q2_new.cpp -o q2
 3616  mpirun -n 4 ./q2
 3617  cd ../q3
 3618  clear
 3619  mpic++ q2_new.cpp -o q2
 3620  mpic++ q.cpp -o q
 3621  mpirun -n 4 ./q
 3622  mpirun -n 4 ./q < input.txt > output.txt
 3623  ./a.out > input.txt
 3624  mpirun -n 4 ./q < input.txt > output.txt
 3625  mpirun -n 1 ./q < input.txt > output.txt
 3626  mpirun -n 2 ./q < input.txt > output.txt
 3627  mpirun -n 3 ./q < input.txt > output.txt
 3628  mpirun -n 4 ./q < input.txt > output.txt
 3629  mpirun -n 5 ./q < input.txt > output.txt
 3630  cd ../q1
 3631  clear
 3632  mpirun -n 1 ./q
 3633  mpic++ q.cpp -o q
 3634  mpic++ q1.cpp -o q
 3635  mpirun -n 1 ./q
 3636  mpirun -n 2 ./q
 3637  mpirun -n 3 ./q
 3638  mpirun -n 4 ./q
 3639  mpirun -n 5 ./q
 3640  mpirun -n 6 ./q
 3641  mpirun -n 7 ./q
 3642  mpirun -n 8 ./q
 3643  mpirun -n 9 ./q
 3644  mpirun -n 10 ./q
 3645  mpirun -n 1 ./q
 3646  mpirun -n 2 ./q
 3647  mpirun -n 3 ./q
 3648  mpirun -n 4 ./q
 3649  mpirun -n 5 ./q
 3650  2 469077255466389
 3651  mpirun -n 5 ./q
 3652  mpirun -n 6 ./q
 3653  mpirun -n 7 ./q
 3654  code .
 3655  cd ../q1
 3656  cd ../q2
 3657  clear
 3658  mpic++ q1.cpp -o q
 3659  mpic++ q2.cpp -o q
 3660  mpic++ q2_new.cpp -o q
 3661  mpirun -n 7 ./q
 3662  mpirun -n 1 ./q
 3663  mpirun -n 1 ./q < input.txt
 3664  g++ testmatrix.cpp
 3665  ./a.out > input.txt
 3666  mpirun -n 1 ./q < input.txt
 3667  mpic++ q2_new.cpp -o q
 3668  mpirun -n 1 ./q < input.txt
 3669  mpic++ q2_new.cpp -o q
 3670  mpirun -n 1 ./q < input.txt
 3671  mpic++ q2_new.cpp -o q
 3672  mpirun -n 1 ./q < input.txt
 3673  mpirun -n 1 ./q
 3674  mpirun -n 1 ./q < input.txt
 3675  mpic++ q2_new.cpp -o q
 3676  mpirun -n 1 ./q < input.txt
 3677  g++ testmatrix.cpp
 3678  ./a.out > input.txt
 3679  mpirun -n 1 ./q < input.txt
 3680  mpirun -n 2 ./q < input.txt
 3681  mpirun -n 3 ./q < input.txt
 3682  mpirun -n 4 ./q < input.txt
 3683  mpirun -n 5 ./q < input.txt
 3684  mpirun -n 6 ./q < input.txt
 3685  mpirun -n 7 ./q < input.txt
 3686  mpirun -n 8 ./q < input.txt
 3687  mpirun -n 9 ./q < input.txt
 3688  mpic++ q2_new.cpp -o q
 3689  mpirun -n 9 ./q < input.txt
 3690  mpirun -n 10 ./q < input.txt
 3691  mpirun -n 11 ./q < input.txt
 3692  cd ../q3
 3693  clear
 3694  g++ testmatrix.cpp
 3695  ./a.out > input.txt
 3696  g++ testmatrix.cpp
 3697  ./a.out > input.txt
 3698  g++ testmatrix.cpp
 3699  ./a.out > input.txt
 3700  mpic++ q.cpp -o q
 3701  mpirun -n 1 ./q < input.txt
 3702  g++ testmatrix.cpp
 3703  ./a.out > input.txt
 3704  mpirun -n 1 ./q < input.txt
 3705  mpirun -n 2 ./q < input.txt
 3706  mpirun -n 1 ./q < input.txt
 3707  mpirun -n 3 ./q < input.txt
 3708  mpirun -n 4 ./q < input.txt
 3709  mpirun -n 5 ./q < input.txt
 3710  mpirun -n 6 ./q < input.txt
 3711  mpirun -n 7 ./q < input.txt
 3712  mpirun -n 8 ./q < input.txt
 3713  mpirun -n 9 ./q < input.txt
 3714  mpirun -n 10 ./q < input.txt
 3715  mpirun -n 1 ./q < input.txt
 3716  mpirun -n 9 ./q < input.txt
 3717  mpirun -n 10 ./q < input.txt
 3718  mpirun -n 10 ./q < input.txt > output.txt
 3719  mpirun -n 1 ./q < input.txt > output.txt
 3720  code .
 3721  ipython
 3722  code .
 3723  mpic++ q2_new.cpp -o q
 3724  mpirun -n 1 ./q
 3725  mpic++ q2_new.cpp -o q
 3726  mpirun -n 1 ./q
 3727  mpic++ q2_new.cpp -o q
 3728  mpirun -n 1 ./q
 3729  mpic++ q2_new.cpp -o q
 3730  mpirun -n 1 ./q
 3731  mpic++ q2_new.cpp -o q
 3732  mpirun -n 1 ./q
 3733  mpirun -n 2 ./q
 3734  mpirun -n 3 ./q
 3735  mpirun -n 4 ./q
 3736  mpirun -n 5 ./q
 3737  mpirun -n 6 ./q
 3738  mpirun -n 7 ./q
 3739  mpirun -n 8 ./q
 3740  mpirun -n 9 ./q
 3741  mpirun -n 10 ./q
 3742  mpic++ q2_new.cpp -o q
 3743  mpirun -n 3 ./q
 3744  g++ testmatrix.cpp
 3745  ./a.out > input.txt
 3746  mpic++ q.cpp -o q
 3747  mpirun -n 1 ./q
 3748  mpirun -n 2 ./q
 3749  mpirun -n 3 ./q
 3750  mpirun -n 4 ./q
 3751  mpirun -n 5 ./q
 3752  mpirun -n 6 ./q
 3753  mpirun -n 7 ./q
 3754  mpirun -n 8 ./q
 3755  tar -zcvf file.tar.gz 2021101100
 3756  code .
 3757  cd 3
 3758  clear
 3759  mpic++ 3.cpp -o q
 3760  mpirun -n 1 ./q
 3761  mpirun -n 8 ./q
 3762  mpirun -n 4 ./q
 3763  rm q
 3764  tar -zcvf file.tar.gz 2021101100
 3765  code .
 3766  clear
 3767  npm start
 3768  clear
 3769  npm start
 3770  code .
 3771  npm start
 3772  clear
 3773  code .
 3774  git init
 3775  git add .
 3776  git commit -m "first commit"
 3777  git checkout tags/v1.0.0\n
 3778  git tag v1.0.0\n
 3779  git log
 3780  git tag
 3781  git show <tag-name>\n
 3782  git show v1.0.0\n
 3783  git add .
 3784  git commit -m "second commit"
 3785  git tag v1.0.1\n
 3786  git tag
 3787  git checkout tags/v1.0.0\n
 3788  git show v1.0.0\n
 3789  git checkout tags/v1.0.1\n
 3790  git show v1.0.0\n
 3791  git log
 3792  git checkout tags/v1.0.0\n
 3793  git log
 3794  cd ..
 3795  clear
 3796  git show v1.0.0\n
 3797  git status
 3798  git add .
 3799  git commit -m "added revert functionality and analytics table"
 3800  git push -u origin master
 3801  git clone https://github.com/PramodRaoB/docker-hadoop.git
 3802  docker
 3803  sudo  docker-compose up -d
 3804  sudo  make wordcount\n
 3805  java
 3806  jdk
 3807  htop
 3808  history
 3809  history > his.txt
 3810  code .
 3811  clear
 3812  npm start
 3813  clear
 3814  npm start
 3815  code .
 3816  clear
 3817  npm start
 3818  clear
 3819  npm start
 3820  code .
 3821  npm start
 3822  lsof -n -i :'5005' | grep LISTEN\n
 3823  npm start
 3824  sudo kill -9 $(sudo lsof -t -i:5005)\n
 3825  sudo kill -9 $(sudo lsof -t -i:3000)\n
 3826  npm start
 3827  clear
 3828  npm start
 3829  clear
 3830  git s
 3831  git status
 3832  clear
 3833  git status
 3834  git add .
 3835  git commit -m "added filters and experiment table"
 3836  git push -u origin master
 3837  clear
 3838  npm start
 3839  code .
 3840  clear
 3841  npm start
 3842  clear
 3843  npm start
 3844  npm i; npm start
 3845  code .
 3846  clear
 3847  npm start
 3848  clear
 3849  npm start
 3850  sudo kill -9 $(sudo lsof -t -i:5005)\n
 3851  npm start
 3852  git branch -b dev
 3853  git branch dev
 3854  git checkout dev
 3855  git log
 3856  git add .
 3857  git commit -m "added docs"
 3858  git remote -v\n
 3859  git remote set-url origin https://github.com/virtual-labs/app-lab-deployment-web.git
 3860  git remote -v\n
 3861  git push -u origin dev
 3862  htop
 3863  code .
 3864  npm start
 3865  clear
 3866  npm start
 3867  npm run build
 3868  code .
 3869  npm start
 3870  gcloud components list
 3871  cd ..
 3872  ls
 3873  gsutil cp -r build/* gs://workflow-app\n
 3874  code .
 3875  npm start
 3876  npm i react-router-dom@^6.6.1
 3877  npm start
 3878  code .
 3879  npm run build
 3880  code .
 3881  npm start
 3882  npm run build
 3883  npm i react-router-dom@6.6.1
 3884  npm start
 3885  npm run build
 3886  gsutil cp -r build/* gs://workflow-app\n
 3887  code .
 3888  npm start
 3889  code .
 3890  cd frontend
 3891  cd backend
 3892  npm start
 3893  npm run build
 3894  code .
 3895  npm start
 3896  npm uninstall react-table
 3897  npm start
 3898  clear
 3899  npm i
 3900  npm start
 3901  npm run build
 3902  npm start
 3903  sudo apt update\n
 3904  sudo apt-get --only-upgrade install google-chrome-stable\n
 3905  npm uninstall -g create-react-app\n
 3906  npx create-react-app my-app\n
 3907  ls
 3908  rm -rf my-app
 3909  ls
 3910  npm install react-scripts@latest\n
 3911  npm run build
 3912  npm start
 3913  cd ..
 3914  ls
 3915  git status
 3916  git add .
 3917  git status
 3918  git commit -m "version 1"
 3919  git push -u origin dev
 3920  npx create-react-app test-app\n
 3921  code .
 3922  npm start
 3923  react-router-dom
 3924  npm i react-router-dom
 3925  react-router-dom
 3926  npm start
 3927  npm run build
 3928  code .
 3929  npm i
 3930  npm start
 3931  npm run build
 3932  code .
 3933  npm run build
 3934  code .
 3935  gcloud auth login
 3936  gcloud config set project lab-deployment-414310
 3937  ls
 3938  cat .gcloudignore
 3939  node -v
 3940  npm start
 3941  ls
 3942  ls -a
 3943  gcloud app deploy
 3944  gcloud app browse
 3945  gcloud app logs tail -s default
 3946  gcloud app deploy
 3947  gcloud app browse
 3948  gcloud app deploy
 3949  node server.js
 3950  code .
 3951  cd frontend
 3952  npm start
 3953  cd backend
 3954  npm start
 3955  code .
 3956  npm start
 3957  npm run build
 3958  cd frontend
 3959  npm run build
 3960  code .
 3961  ht
 3962  odsk\\ndf
 3963  htop
 3964  npm start
 3965  code .
 3966  npm start
 3967  npm run build
 3968  npm start
 3969  git status
 3970  git add .
 3971  git commit -m "updated doc and app.yaml"
 3972  git push -u origin dev
 3973  code .
 3974  htop
 3975  pip install h5py
 3976  git clone https://github.com/PramodRaoB/hadoop-playground.git
 3977  code .
 3978  make wordcount
 3979  sudo make wordcount
 3980  docker-compose up -d\n\n
 3981  sudo docker-compose up -d\n\n
 3982  docker exec -it namenode bash\n\n
 3983  sudo docker exec -it namenode bash\n\n
 3984  nano ~/.zshrc
 3985  cd /usr/lib/jvm/
 3986  ls
 3987  nano ~/.zshrc
 3988  code ~/.zshrc
 3989  nano ~/.zshrc
 3990  sudo apt-get install ssh\n
 3991  tar -zxvf hadoop-3.3.6.tar.gz \n
 3992  code hadoop-env.sh
 3993  ssh localhost
 3994  ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa \ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys 
 3995  chmod 0600 ~/.ssh/authorized_keys 
 3996  hadoop-3.3.6/bin/hdfs namenode -format\n
 3997  hadoop-3.2.3/bin/hdfs namenode -format\n
 3998  hadoop-3.2.3/bin/hdfs namenode -format
 3999  ./hdfs namenode -format\n
 4000  hadoop-3.2.3/bin/hdfs namenode -format\n
 4001  hadoop-3.3.6/bin/hdfs namenode -format\n
 4002  pwd
 4003  hadoop-3.3.6/bin/hdfs namenode -format\n
 4004  source ~/.zshrc 
 4005  hadoop-3.3.6/bin/hdfs namenode -format\n
 4006  export PDSH_RCMD_TYPE=ssh\n
 4007  start-all.sh
 4008  docker-compose down\n\n
 4009  sudo docker-compose down\n\n
 4010  start-all.sh
 4011  source ~/.zshrc 
 4012  start-all.sh
 4013  sudo kill -9 $(sudo lsof -t -i:9870)\n
 4014  start-all.sh
 4015  code ~
 4016  code ~/.zshrc
 4017  source ~/.zshrc 
 4018  start-all.sh
 4019  pwd
 4020  source ~/.zshrc 
 4021  start-all.sh
 4022  cd /usr/lib/jvm/java-11-openjdk-amd64
 4023  ls
 4024  sudo apt install openjdk-8-jdk\n
 4025  cd /usr/lib/jvm/java-11-openjdk-amd64
 4026  cd /usr/lib/jvm/java-8-openjdk-amd64
 4027  source ~/.zshrc 
 4028  cd -
 4029  start-all.sh
 4030  $HADOOP_HOME
 4031  code ~/.zshrc
 4032  jps
 4033  hadoop -v
 4034  hadoop -vview hadoop version
 4035  hadoop version
 4036  netstat -tulpn\n
 4037  code .
 4038  ls 
 4039  ls -al .git/index
 4040  code .
 4041  code hadoop-env.sh
 4042  code hadoop-env.h
 4043  code ~
 4044  code ~/
 4045  code ~/z
 4046  code ~/.zshrc
 4047  cd /home/chirag/hadoop-3.3.6
 4048  cd -
 4049  ssh localhost \nssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa \ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys \nchmod 0600 ~/.ssh/authorized_keys \nhadoop-3.2.3/bin/hdfs namenode -format
 4050  ssh localhost \nssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa \ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys \nchmod 0600 ~/.ssh/authorized_keys \nhadoop-3.3.6/bin/hdfs namenode -format
 4051  ssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa \n
 4052  cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
 4053  chmod 0600 ~/.ssh/authorized_keys
 4054  hadoop-3.3.6/bin/hdfs namenode -format
 4055  start-all.sh
 4056  hdfs fs -ls
 4057  hdfs -ls
 4058  hadoop -ls
 4059  code .
 4060  cd frontend
 4061  cd backend
 4062  npm start
 4063  code .
 4064  git clone https://github.com/harveyslash/Facial-Similarity-with-Siamese-Networks-in-Pytorch.git
 4065  python -m venv venv\n
 4066  code .
 4067  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/deactivate/zsh/envVars.txt
 4068  python -u "/media/chirag/DATA/VLABS/vertexai/main.py"
 4069  source venv/bin/activate
 4070  clear
 4071  python -u "/media/chirag/DATA/VLABS/vertexai/main.py"
 4072  pip install vertexai
 4073  python -u "/media/chirag/DATA/VLABS/vertexai/main.py"
 4074  python main.py
 4075  pip install --upgrade google-cloud-aiplatform\n
 4076  python main.py
 4077  code .
 4078  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/deactivate/zsh/envVars.txt
 4079  python -u "/media/chirag/DATA/VLABS/vertexai/main.py"
 4080  from google.oauth2 import service_account\n
 4081  pip install google-auth\n
 4082  python -u "/media/chirag/DATA/VLABS/vertexai/main.py"
 4083  code .
 4084  /usr/bin/env python "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_2/q3/runner_script.py"
 4085  python mapper.py < inp.txt626560933.tmp > om.txt
 4086  python reducer.py < om.txt > final.txt
 4087  python mapper.py < inp.txt626560933.tmp > om.txt
 4088  python reducer.py < om.txt > final.txt
 4089  python mapper.py < inp.txt626560933.tmp > om.txt
 4090  python reducer.py < om.txt > final.txt
 4091  python mapper.py < inp.txt626560933.tmp > om.txt
 4092  python reducer.py < om.txt > final.txt
 4093  python mapper.py < inp.txt626560933.tmp > om.txt
 4094  python reducer.py < om.txt > final.txt
 4095  hadoop fs -put mapper.py /
 4096  code .
 4097  git clone https://github.com/jonorthwash/ud-annotatrix
 4098  code .
 4099  npm i
 4100  npm start
 4101  pip install imageio
 4102  code .
 4103  start-all.sh
 4104  hadoop fs -put ./mapper.py ./
 4105  start-all.sh
 4106  hadoop fs -put ./mapper.py ./
 4107  hadoop fs -put ./mapper.py /
 4108  code .
 4109  pwd
 4110  hadoop fs -put ./reducer.py /
 4111  hadoop fs -mkdir /input\n\n
 4112  ls
 4113  start-all.sh
 4114  hdfs dfs -chmod 777 /\n
 4115  hdfs dfs -chmod 777 /input\n
 4116  hdfs dfs -chmod 777 /mapper.py\n
 4117  hdfs dfs -chmod 777 /reducer.py\n
 4118  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt input/ output/ ./
 4119  chmod 777 runner_script.py
 4120  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt input/ output/ ./
 4121  hadoop fs -mkdir /input/in\n\n
 4122  hdfs dfs -chmod 777 /input/in\n
 4123  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt input/ output/ ./
 4124  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ output/ ./
 4125  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt // / ./
 4126  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt / / ./
 4127  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt / /output/ ./
 4128  hadoop fs -rmdir /user/chirag/output
 4129  hadoop fs -rm -r /user/chirag/output
 4130  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt / /output/ ./
 4131  hadoop fs -rm -r /user/chirag/output
 4132  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4133  hadoop fs -rm -r /output
 4134  code .
 4135  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4136  hadoop fs -rm -r /output
 4137  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4138  hadoop fs -rm -r /output
 4139  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4140  hadoop fs -rm -r /output
 4141  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4142  hadoop fs -rm -r /output
 4143  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4144  hadoop fs -rm -r /output
 4145  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4146  hadoop fs -rm -r /output
 4147  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4148  hadoop fs -rm -r /output
 4149  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4150  hadoop fs -rm -r /output
 4151  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4152  hadoop fs -rm -r /output
 4153  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4154  hadoop fs -rm -r /output
 4155  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4156  /usr/bin/env python "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_2/q3/reducer.py"
 4157  hadoop fs -rm -r /output
 4158  /usr/bin/env python "/media/chirag/DATA/CODE_AMA/distributed-systems/assign_2/q3/reducer.py"
 4159  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4160  python reducer.py < om.txt > final.txt
 4161  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4162  python mapper.py < inp.txt718140999.tmp > om.txt
 4163  python reducer.py < om.txt > final.txt
 4164  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4165  hadoop fs -rm -r /output
 4166  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ /output/ ./
 4167  code .
 4168  python runner_script_temp.py < inp.txt
 4169  python mapper.py < inp.txt.tmp
 4170  python mapper.py < inp.txt.tmp > o.txt
 4171  python mapper.py < o.txt > inp.txt.tmp
 4172  python reducer.py < o.txt > inp.txt.tmp
 4173  python mapper.py < inp.txt.tmp > o.txt
 4174  python reducer.py < o.txt > inp.txt.tmp
 4175  python mapper.py < inp.txt.tmp > o.txt
 4176  python reducer.py < o.txt > inp.txt.tmp
 4177  python mapper.py < inp.txt.tmp > o.txt
 4178  python reducer.py < o.txt > inp.txt.tmp
 4179  python runner_script_temp.py < inp.txt
 4180  python mapper.py < inp.txt.tmp > o.txt
 4181  python reducer.py < o.txt > inp.txt.tmp
 4182  python mapper.py < inp.txt.tmp > o.txt
 4183  python reducer.py < o.txt > inp.txt.tmp
 4184  code .
 4185  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/deactivate/zsh/envVars.txt
 4186  source venv/bin/activate
 4187  python main.py
 4188  htop
 4189  python main.py
 4190  code .
 4191  pip freeze | grep pandas
 4192  pip install xlrd
 4193  pip install --update xlrd
 4194  pip install --upgrade xlrd
 4195  npm start
 4196  cat package.json
 4197  source venv/bin/activate
 4198  python main.py
 4199  cd search-page-react
 4200  npm start
 4201  python main.py
 4202  code .
 4203  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/deactivate/zsh/envVars.txt
 4204  python main.py
 4205  source venv/bin/activate
 4206  python main.py
 4207  code .
 4208  source venv/bin/activate
 4209  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/deactivate/zsh/envVars.txt
 4210  py
 4211  python main.py
 4212  python tem.py
 4213  python main.py
 4214  source venv/bin/activate
 4215  python main.py
 4216  code .
 4217  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/deactivate/zsh/envVars.txt
 4218  python main.py
 4219  source venv/bin/activate
 4220  python main.py
 4221  code .
 4222  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/deactivate/zsh/envVars.txt
 4223  source venv/bin/activate
 4224  python main.py
 4225  code .
 4226  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/deactivate/zsh/envVars.txt
 4227  cd search-page-react
 4228  npm start
 4229  source venv/bin/activate
 4230  pip install vertexai
 4231  source venv/bin/activate
 4232  python main.py
 4233  pip freeze > requirements.txt
 4234  history > his.txt
 4235  pip install --upgrade google-cloud-aiplatform
 4236  python main.py
 4237  clear
 4238  code .
 4239  python main.py
 4240  source venv/bin/activate
 4241  python main.py
 4242  code .
 4243  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/deactivate/zsh/envVars.txt
 4244  python -m venv venv\n
 4245  clear
 4246  git status
 4247  clear
 4248  source venv/bin/activate
 4249  python main.py
 4250  pip install flask_cors uuid python-dotenv flask requests google-auth google-auth-oauthlib\n
 4251  python main.py
 4252  pip install qdrant-client\n
 4253  python main.py
 4254  pip install gspread
 4255  python main.py
 4256  pip install llmsherpa
 4257  python main.py
 4258  history > his.txt
 4259  pip install --upgrade google-cloud-aiplatform
 4260  python main.py
 4261  source venv/bin/activate
 4262  python -m venv venv\n
 4263  source venv/bin/activate
 4264  clear
 4265  python main.py
 4266  history > his.txt
 4267  code .
 4268  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.0.1/pythonFiles/deactivate/zsh/envVars.txt
 4269  source venv/bin/activate
 4270  pip freeze > requirements.txt
 4271  pip install flask_cors uuid python-dotenv flask requests google-auth google-auth-oauthlib
 4272  pip install qdrant-client
 4273  python main.py
 4274  pip install gspread
 4275  pip install llmsherpa
 4276  pip install --upgrade google-cloud-aiplatform
 4277  python main.py
 4278  pip install bs4
 4279  python main.py
 4280  pip install google-api-python-client PyPDF2\n
 4281  python main.py
 4282  source venv/bin/activate
 4283  pip freeze > requirements.txt
 4284  pip install flask==2.3.3
 4285  python main.py
 4286  source venv/bin/activate
 4287  clear
 4288  pip install -r requirements.txt
 4289  python main.py
 4290  python -m venv venv\n
 4291  source venv/bin/activate
 4292  python main.py
 4293  pip install -r requirements.txt
 4294  python main.py
 4295  source venv/bin/activate
 4296  pip install -r requirements.txt
 4297  cd search-page-react
 4298  npm start
 4299  python main.py
 4300  clear
 4301  git status
 4302  git add .
 4303  git commit -m "replaced embedding sentence-transformer with vertexai api and updated requirements.txt"
 4304  git push -u origin dev
 4305  code .
 4306  pip install pingouin\n
 4307  code .
 4308  git clone https://github.com/subtlai/subtl_bot.git
 4309  code .
 4310  cd subtl-react
 4311  npm i; npm start
 4312  cp .env.example .env
 4313  code .
 4314  cd subtl-react
 4315  npm start
 4316  clear
 4317  git clone https://github.com/subtlai/subtl_bot.git
 4318  code .
 4319  git clone https://github.com/subtlai/subtl_bot.git
 4320  code .
 4321  python -m venv venv\n
 4322  source venv/bin/activate
 4323  pip install pandas, bs4, pdfkit
 4324  pip install pandas bs4 pdfkit
 4325  source venv/bin/activate
 4326  pip install pandas bs4 pdfkit
 4327  code .
 4328  cd backend
 4329  npm start
 4330  cd frontend
 4331  npm run build
 4332  gcloud
 4333  gcloud auth login
 4334  gcloud config set project lab-deployment-414310
 4335  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 4336  npm start:dev
 4337  npm run start:dev
 4338  npm run start:prod
 4339  npm run start:dev
 4340  npm run start:prod
 4341  cd frontend
 4342  npm ls react-scripts\n
 4343  npm cache clean --force\n
 4344  npm run start:prod
 4345  npm cache clean --force\n
 4346  npm run start:prod
 4347  npm cache clean --force\n
 4348  npm run start:prod
 4349  npm start:prod
 4350  npm run start:prod
 4351  dig deploy.vlabs.ac.in
 4352  npm run build:prod
 4353  code .
 4354  dig deploy.vlabs.ac.in
 4355  cd /etc
 4356  ls
 4357  code hosts
 4358  cat hosts
 4359  code hosts
 4360  code /etc/hosts
 4361  code .
 4362  dig deploy.vlabs.ac.in
 4363  code .
 4364  clear
 4365  cd 2
 4366  cd ..
 4367  cd 3
 4368  cd ../2
 4369  clear
 4370  mpic++ 2.cpp -o q
 4371  mpirun -n 4 ./q < 1.in
 4372  mpirun -n 4 ./q < 2.in
 4373  mpirun -n 4 ./q < 3.in
 4374  cd ../3
 4375  clear
 4376  mpic++ 3.cpp -o q
 4377  mpirun -n 4 ./q < 1.in
 4378  mpirun -n 4 ./q < 2.in
 4379  mpirun -n 4 ./q < 3.in
 4380  mpirun -n 4 ./q < 3.in > 3.o
 4381  python test.py 3.o 3.out
 4382  /bin/python
 4383  clear
 4384  python test.py 3.o 3.out
 4385  def compare_files(file1, file2):
 4386  python test.py 3.o 3.out
 4387  mpirun -n 4 ./q < 4.in > 4.o
 4388  python test.py 4.o 4.out
 4389  mpirun -n 5 ./q < 5.in > 5.o
 4390  python test.py 5.o 5.out
 4391  mpirun -n 6 ./q < 6.in > 6.o
 4392  python test.py 6.o 6.out
 4393  python test.py 3.o 3.out
 4394  python test.py 4.o 4.out
 4395  python test.py 5.o 5.out
 4396  python test.py 6.o 6.out
 4397  mpirun -n 2 ./q < 6.in > 6.o
 4398  python test.py 6.o 6.out
 4399  mpirun -n 2 ./q < 6.in > 6.o
 4400  mpirun -n 2 ./q < 5.in > 5.o
 4401  mpirun -n 2 ./q < 4.in > 4.o
 4402  mpirun -n 2 ./q < 3.in > 3.o
 4403  mpirun -n 2 ./q < 2.in > 2.o
 4404  mpirun -n 2 ./q < 1.in > 1.o
 4405  python test.py 6.o 6.out
 4406  python test.py 5.o 5.out
 4407  python test.py 4.o 4.out
 4408  python test.py 2.o 2.out
 4409  python test.py 1.o 1.out
 4410  mpirun -n 2 ./q < 6.in > 6.o
 4411  mpirun -n 2 ./q < 5.in > 5.o
 4412  mpirun -n 2 ./q < 4.in > 4.o
 4413  mpirun -n 2 ./q < 3.in > 3.o
 4414  mpirun -n 2 ./q < 2.in > 2.o
 4415  mpirun -n 2 ./q < 1.in > 1.o
 4416  mpirun -n 2 ./q < 7.in > 7.o
 4417  cd ../2
 4418  mpirun -n 2 ./q < 7.in > 7.o
 4419  mpirun -n 2 ./q < 1.in > 1.o
 4420  mpirun -n 2 ./q < 2.in > 2.o
 4421  mpirun -n 2 ./q < 3.in > 3.o
 4422  mpirun -n 2 ./q < 4.in > 4.o
 4423  mpirun -n 2 ./q < 5.in > 5.o
 4424  mpirun -n 2 ./q < 6.in > 6.o
 4425  python test.py 1.o 1.out
 4426  python test.py 2.o 2.out
 4427  python test.py 3.o 3.out
 4428  python test.py 4.o 4.out
 4429  python test.py 5.o 5.out
 4430  python test.py 6.o 6.out
 4431  python test.py 7.o 7.out
 4432  code .
 4433  npm run build:dev
 4434  cd frontend
 4435  clear
 4436  npm run build:dev
 4437  cd backend
 4438  npm start:prod
 4439  npm start
 4440  npm run start:prod
 4441  gcloud config set project lab-deployment-414310
 4442  gcloud app deploy
 4443  npm run build:prod
 4444  gcloud app browse
 4445  npm run start:prod
 4446  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 4447  code .
 4448  npm run build:prod
 4449  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 4450  code .
 4451  pip install cv2
 4452  pip install cv
 4453  pip install opencv-python\n
 4454  code .
 4455  start-all.sh
 4456  code .
 4457  start-all.sh
 4458  code .
 4459  start-all.sh
 4460  cd q2
 4461  ls
 4462  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt input/ output ./
 4463  chmod 777 runner_script.py
 4464  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt input/ output ./
 4465  ssh localhost \nssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa \ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys \nchmod 0600 ~/.ssh/authorized_keys 
 4466  hadoop-3.3.6/bin/hdfs namenode -format\n
 4467  start-all.sh
 4468  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt input/ output ./
 4469  hadoop fs mkdir input
 4470  hadoop fs -mkdir /input
 4471  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt input/ output ./
 4472  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ output ./
 4473  hadoop fs -rm -r /output0
 4474  hadoop fs -rm -r /user/chirag/output[0..9]
 4475  hadoop fs -rm -r /user/chirag/output{0..9}
 4476  ./mapper.py < inp.txt.tmp > out.o
 4477  ./reducer.py < out.o > inp.txt.tmp
 4478  ./mapper.py < inp.txt.tmp > out.o
 4479  ./reducer.py < out.o > inp.txt.tmp
 4480  ./mapper.py < inp.txt.tmp > out.o
 4481  ./reducer.py < out.o > inp.txt.tmp
 4482  ./mapper.py < inp.txt.tmp > out.o
 4483  ./reducer.py < out.o > inp.txt.tmp
 4484  ./mapper.py < inp.txt.tmp > out.o
 4485  ./reducer.py < out.o > inp.txt.tmp
 4486  ./mapper.py < inp.txt.tmp > out.o
 4487  ./reducer.py < out.o > inp.txt.tmp
 4488  ./mapper.py < inp.txt.tmp > out.o
 4489  ./reducer.py < out.o > inp.txt.tmp
 4490  ./mapper.py < inp.txt.tmp > out.o
 4491  ./reducer.py < out.o > inp.txt.tmp
 4492  ./mapper.py < inp.txt.tmp > out.o
 4493  ./reducer.py < out.o > inp.txt.tmp
 4494  ./mapper.py < inp.txt.tmp > out.o
 4495  ./reducer.py < out.o > inp.txt.tmp
 4496  ./mapper.py < inp.txt.tmp > out.o
 4497  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ output ./
 4498  clear
 4499  hadoop fs -rm -r /user/chirag/output{0..9}
 4500  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ output ./
 4501  hadoop fs -rm -r /user/chirag/output{0..9}
 4502  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ output ./
 4503  hadoop fs -rm -r /user/chirag/output{0..9}
 4504  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ output ./
 4505  hadoop fs -rm -r /user/chirag/output{0..9}
 4506  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ output ./
 4507  hadoop fs -rm -r /user/chirag/output{0..9}
 4508  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ output ./
 4509  hadoop fs -rm -r /user/chirag/output{0..9}
 4510  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ output ./
 4511  hadoop fs -rm -r /user/chirag/output{0..9}
 4512  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ output ./
 4513  ./mapper.py < inp.txt.tmp | sort > out.o
 4514  ./reducer.py < out.o > inp.txt.tmp
 4515  ./mapper.py < inp.txt.tmp | sort > out.o
 4516  ./reducer.py < out.o > inp.txt.tmp
 4517  ./mapper.py < inp.txt.tmp | sort > out.o
 4518  ./reducer.py < out.o > inp.txt.tmp
 4519  ./mapper.py < inp.txt.tmp | sort > out.o
 4520  ./reducer.py < out.o > inp.txt.tmp
 4521  ./mapper.py < inp.txt.tmp | sort > out.o
 4522  ./reducer.py < out.o > inp.txt.tmp
 4523  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ output ./
 4524  hadoop fs -rm -r /user/chirag/output{0..9}
 4525  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt /input/ output ./
 4526  hadoop fs -rm -r /user/chirag/output{0..9}
 4527  hadoop fs -rm -r input/
 4528  hadoop fs -rm -r /input/
 4529  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4530  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt input/ output/ ./
 4531  hadoop fs mkdir /input
 4532  hadoop fs -mkdir /input
 4533  hadoop fs -mkdir input/
 4534  hadoop fs -rm -r /input
 4535  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./inp.txt input/ output/ ./
 4536  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4537  hadoop fs -mkdir input/
 4538  hadoop fs -rm rmdir input/
 4539  hadoop fs -rmdir input/
 4540  hadoop fs -rmdir rm input/
 4541  hadoop fs -rm -r input/
 4542  hadoop fs -rm -r output/
 4543  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4544  hadoop fs -mkdir input/
 4545  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4546  hadoop fs -mkdir input/temp
 4547  hadoop fs -rm -r input/temp
 4548  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4549  code .
 4550  hadoop fs -rm -r input/
 4551  hadoop fs -rm -r output/
 4552  hadoop fs -mkdir input/
 4553  cd ../q2
 4554  clear
 4555  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4556  hadoop fs -rm -r tem0/
 4557  hadoop fs -mkdir input/inp.txt
 4558  hadoop fs -rm input/inp.txt
 4559  cd ../q3
 4560  clear
 4561  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4562  chmod 777 runner_script.py
 4563  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4564  hadoop fs -rm output/
 4565  hadoop fs -rm -r output/
 4566  hadoop fs -rm -r input/inp.txt
 4567  hadoop fs -rm -r input/input.txt
 4568  cd q2
 4569  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4570  hadoop fs -rm -r input/input.txt
 4571  hadoop fs -rm -r output/
 4572  cd ../q3
 4573  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4574  hadoop fs -rm -r output/
 4575  hadoop fs -rm -r input/input.txt
 4576  code .
 4577  cd q2
 4578  clear
 4579  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4580  hadoop fs -rm -r input/input.txt
 4581  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4582  hadoop fs -rm -r input/input.txt
 4583  hadoop fs -rm -r output/
 4584  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4585  hadoop fs -rm -r input/input.txt
 4586  hadoop fs -rm -r output/
 4587  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ /
 4588  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4589  hadoop fs -rm -r input/input.txt
 4590  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4591  cd q2
 4592  ./mapper0.py < ./input/input.txt | sort > o.out
 4593  chmod 777 mapper0.py
 4594  ./mapper0.py < ./input/input.txt | sort > o.out
 4595  ./mapper0.py < ./input/input.txt > o.out
 4596  ./mapper0.py < ./input/input.txt | sort > o.out
 4597  chmod 777 reducer0.py
 4598  ./reducer0.py < o.out > final
 4599  ./mapper0.py < ./input/input.txt | sort > o.out
 4600  ./reducer0.py < o.out > final
 4601  ./mapper0.py < ./input/input.txt | sort > o.out
 4602  ./reducer0.py < o.out > final
 4603  ./mapper0.py < ./input/input.txt | sort > o.out
 4604  ./reducer0.py < o.out > final
 4605  ./mapper0.py < ./input/input.txt | sort > o.out
 4606  ./reducer0.py < o.out > final
 4607  ./mapper.py < ./final | sort > p.out
 4608  chmod 777 mapper.py
 4609  ./mapper.py < ./final | sort > p.out
 4610  chmod 777 reducer.py
 4611  ./reducer.py < ./p.out > ff
 4612  hadoop fs -rm -r input/input.txt
 4613  hadoop fs -rm -r input/
 4614  hadoop fs -rm -r output/
 4615  hadoop fs -rm -r temp/
 4616  hadoop fs -mkdir input/
 4617  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4618  hadoop fs -rm -r temp/
 4619  hadoop fs -rm -r output/
 4620  hadoop fs -rm -r input/input.txt
 4621  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4622  hadoop fs -rm -r input/input.txt
 4623  hadoop fs -rm -r output/
 4624  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4625  hadoop fs -rm -r output/
 4626  hadoop fs -rm -r input/input.txt
 4627  hadoop fs -rm -r input/input1.txt
 4628  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4629  hadoop fs -rm -r output/
 4630  hadoop fs -rm -r input/input1.txt
 4631  hadoop fs -rm -r input/input.txt
 4632  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4633  hadoop fs -rm -r input/input.txt
 4634  hadoop fs -rm -r input/input1.txt
 4635  hadoop fs -rm -r output/
 4636  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4637  hadoop fs -rm -r output/
 4638  hadoop fs -rm -r input/input1.txt
 4639  hadoop fs -rm -r input/input.txt
 4640  hadoop fs -rm -r temp/
 4641  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4642  hadoop fs -rm -r temp/
 4643  hadoop fs -rm -r input/input.txt
 4644  hadoop fs -rm -r input/input1.txt
 4645  hadoop fs -rm -r output/
 4646  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4647  hadoop fs -rm -r output/
 4648  hadoop fs -rm -r input/input1.txt
 4649  hadoop fs -rm -r input/input.txt
 4650  hadoop fs -rm -r temp/
 4651  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4652  cd ../q3
 4653  hadoop fs -rm -r input/input.txt
 4654  hadoop fs -rm -r input/input1.txt
 4655  hadoop fs -rm -r output/
 4656  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4657  clear
 4658  hadoop fs -rm -r tem4/
 4659  hadoop fs -rm -r input/input.txt
 4660  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4661  hadoop fs -rm -r input/input.txt
 4662  hadoop fs -rm -r tem5/
 4663  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4664  hadoop fs -rm -r tem1/
 4665  hadoop fs -rm -r tem2/
 4666  hadoop fs -rm -r input/input.txt
 4667  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4668  chmod 777 reducer.py
 4669  chmod 777 mapper.py
 4670  ./mapper.py < temp/input.txt | sort > p.out
 4671  0
 4672  ./mapper.py < temp/input.txt | sort > o.out
 4673  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4674  hadoop fs -rm -r input/input.txt
 4675  ./mapper.py < temp/input.txt | sort > o.out
 4676  ./reducer.py < ./o.out > ff
 4677  ./mapper.py < ff | sort > o.out
 4678  ./reducer.py < ./o.out > ff
 4679  ./mapper.py < ff | sort > o.out
 4680  ./reducer.py < ./o.out > ff
 4681  ./mapper.py < ff | sort > o.out
 4682  ./reducer.py < ./o.out > ff
 4683  ./mapper.py < ff | sort > o.out
 4684  ./reducer.py < ./o.out > ff
 4685  ./mapper.py < ff | sort > o.out
 4686  ./reducer.py < ./o.out > ff
 4687  ./mapper.py < ff | sort > o.out
 4688  ./reducer.py < ./o.out > ff
 4689  ./mapper.py < ff | sort > o.out
 4690  ./reducer.py < ./o.out > ff
 4691  ./mapper.py < ff | sort > o.out
 4692  ./reducer.py < ./o.out > ff
 4693  ./mapper.py < ff | sort > o.out
 4694  ./reducer.py < ./o.out > ff
 4695  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4696  hadoop fs -rm -r input/input.txt
 4697  hadoop fs -rm -r output/
 4698  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4699  hadoop fs -rm -r tem0/
 4700  hadoop fs -rm -r tem1/
 4701  hadoop fs -rm -r input/input.txt
 4702  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4703  python
 4704  hadoop fs -rm -r input/input.txt
 4705  hadoop fs -rm -r output/
 4706  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4707  chmod 777 mapper0.py
 4708  chmod 777 reducer0.py
 4709  ./mapper0.py < input/input.txt | sort > o.out
 4710  ./reducer0.py < ./o.out > ff
 4711  hadoop fs -rm -r tem0/
 4712  hadoop fs -rm -r input/input.txt
 4713  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4714  hadoop fs -rm -r input/
 4715  hadoop fs -rm -r output/
 4716  cd ../q2
 4717  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4718  hadoop fs -rm -r input/
 4719  hadoop fs -rm -r output/
 4720  cd ../q3
 4721  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4722  hadoop fs -rm -r input/
 4723  hadoop fs -rm -r tem0/
 4724  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4725  hadoop fs -rm -r input/
 4726  hadoop fs -rm -r output/
 4727  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4728  hadoop fs -rm -r output/
 4729  hadoop fs -rm -r input/
 4730  ./runner_script.py /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4731  touch makefile
 4732  make
 4733  code .
 4734  chmod 777 runnerscript.sh
 4735  ./runnerscript.sh /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ in/ out/
 4736  hadoop dfs -cat out/*
 4737  hadoop dfs -cat /user/chiragout/*
 4738  hadoop dfs -cat /user/chirag/out/*
 4739  hadoop fs -cat /user/chirag/out/*
 4740  hadoop fs -cat /user/chirag/out/
 4741  hadoop fs -ls out/
 4742  hadoop fs -ls
 4743  hadoop dfs -cat out/*
 4744  hadoop fs -cat out/*
 4745  hadoop fs -cat out/part-0000{0..2}
 4746  hadoop fs -cat out/part-0000{0..2} | sort
 4747  hadoop fs -rm -r input/
 4748  hadoop fs -rm -r output/
 4749  hadoop fs -rm -r in/
 4750  hadoop fs -rm -r out/
 4751  code .
 4752  cd q2
 4753  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ in/ out/
 4754  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4755  hadoop fs -rm -r out/
 4756  hadoop fs -rm -r input/
 4757  hadoop fs -rm -r temp/
 4758  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4759  hadoop fs -rm -r input/
 4760  hadoop fs -rm -r output/
 4761  cd ../q3
 4762  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/ ./
 4763  code .
 4764  cd frontend
 4765  npm start:dev
 4766  npm run start:dev
 4767  cd backend
 4768  npm start
 4769  node "/media/chirag/DATA/VLABS/vlabs-workflow/frontend/src/components/search-box-component/test.js"
 4770  nodemon app.js
 4771  nodemon server.js
 4772  gcloud app deploy
 4773  npm run build:prod
 4774  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 4775  code .
 4776  gcloud app browse
 4777  clear
 4778  git status
 4779  git add .
 4780  git commit -m "fixed sorting and validation issues, added workflow list in deployment table"
 4781  code .
 4782  npm install react-datepicker\n
 4783  npm install react-datepicker -f\n
 4784  npm run start:dev
 4785  npm start
 4786  code .
 4787  npm start
 4788  git status
 4789  git add .
 4790  git commit -m "added hosting request form modal"
 4791  git push -u origin dev
 4792  npm run build:prod
 4793  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 4794  cd frontend
 4795  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 4796  htop
 4797  code .
 4798  cd ..
 4799  git add .
 4800  git commit -m "added worklflow config file"
 4801  git push -u origin dev
 4802  clear
 4803  npm start
 4804  clear
 4805  npm start
 4806  cd frontend
 4807  npm i npm install ini\n
 4808  npm install ini\n
 4809  npm install ini -f\n
 4810  cd ..
 4811  git status
 4812  git add .
 4813  git commit -m "added workflow map to select box"
 4814  git push -u origin dev
 4815  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 4816  cd frontend
 4817  npm run build:prod
 4818  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 4819  code .
 4820  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 4821  gcloud auth login
 4822  gcloud config set project document-search-398511
 4823  gcloud app deploy
 4824  source venv/bin/activate
 4825  python main.py
 4826  clear
 4827  gcloud app deploy
 4828  clear
 4829  python -m venv venv\n
 4830  source venv/bin/activate
 4831  pip install -r requirements.txt
 4832  python main.py
 4833  gcloud app deploy
 4834  gcloud app browse
 4835  code .
 4836  gcloud app deploy
 4837  htop
 4838  gcloud app browse
 4839  gcloud app deploy
 4840  gcloud app browse
 4841  htop
 4842  sudo chmod +r /media/chirag/DATA/Downloads/docker-desktop-4.28.0-amd64.deb\n
 4843  sudo apt-get install ./docker-desktop-4.28.0-amd64.deb\n
 4844  systemctl --user start docker-desktop
 4845  sudo  modprobe kvm\n
 4846  sudo modprobe kvm_intel
 4847  sudo usermod -aG kvm $USER
 4848  modprobe kvm\n
 4849  kvm-ok\n
 4850  sudo /usr/sbin/kvm-ok
 4851  lsmod | grep kvm
 4852  ls -al /dev/kvm
 4853  egrep -c '(vmx|svm)' /proc/cpuinfo
 4854  sudo apt install qemu-kvm libvirt-daemon-system libvirt-clients bridge-utils
 4855  systemctl --user start docker-desktop
 4856  docker
 4857  git checkout llm_api
 4858  git branch
 4859  code .
 4860  git clone https://github.com/subtlai/subtl_bot.git
 4861  git checkout llm_api
 4862  cd subtl_bot
 4863  git checkout llm_api
 4864  code .
 4865  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 4866  gcloud app deploy
 4867  gcloud app browse
 4868  egrep -c '(vmx|svm)' /proc/cpuinfo
 4869  ls -al /dev/kvm
 4870  egrep '(vmx|svm)' --color=always /proc/cpuinfo
 4871  sudo insmod kvm-intel\n\n
 4872  sudo insmod kvm\n\n
 4873  gpg --generate-key\n
 4874  pass init 5E715038955F848D7BF74C9C8A91521CDA184000
 4875  egrep '(vmx|svm)' --color=always /proc/cpuinfo
 4876  lsmod | grep kvm
 4877  docker version
 4878  sudo docker run docker/whalesay cowsay helloWorld
 4879  docker run docker/whalesay cowsay boo\n
 4880  code .
 4881  docker ps
 4882  docker-desktop ps
 4883  docker run docker/whalesay cowsay boo\n
 4884  docker/whalesay cowsay boo\n
 4885  cowsay boo\n
 4886  npm i fastapi
 4887  pip install fastapi
 4888  cd subtl_llm/llm_api
 4889  python main.py
 4890  uvicorn main:app --reload
 4891  sudo install uvicorn
 4892  \n
 4893  \nsudo apt-get -y install uvicorn\n
 4894  uvicorn main:app --reload
 4895  pip install uvloop>=0.14.0\n
 4896  pip install uvloop==0.14.0\n
 4897  uvicorn main:app --reload
 4898  pip install httptools==0.1.*
 4899  pip install httptools==0.1.0
 4900  uvicorn main:app --reload
 4901  cp .env.example .env
 4902  sudo docker-compose --env-file dotenv up --build -d
 4903  sudo docker-compose --env-file .env up --build -d
 4904  sudo service docker start\n\n
 4905  sudo systemctl unmask docker.service\n
 4906  sudo systemctl daemon-reload\n
 4907  sudo systemctl start docker.service\n
 4908  sudo systemctl enable docker.service\n
 4909  docker
 4910  docker-compose --env-file .env up --build -d
 4911  sudo docker-compose --env-file .env up --build -d
 4912  sudo systemctl status docker\n
 4913  systemctl status docker\n
 4914  sudo apt-get update\nsudo apt-get install docker.io\n
 4915  systemctl status docker\n
 4916  sudo docker-compose --env-file .env up --build -d
 4917  docker version
 4918  systemctl --user start docker-desktop
 4919  sudo systemctl --user start docker-desktop
 4920  systemctl status docker\n
 4921  docker-compose --env-file .env up --build -d
 4922  systemctl status docker\n
 4923  docker-compose --env-file .env up --build -d
 4924  sudo REACT_APP_DEPLOYMENT_FLAG
 4925  sudo docker-compose --env-file .env up --build -d
 4926  docker ps
 4927  sudo docker ps
 4928  docker stop 2021101100_nginx_1
 4929  sudo docker stop 2021101100_nginx_1
 4930  sudo docker ps
 4931  docker rm -f $(docker ps -qa)\n
 4932  sudo docker rm -f $(docker ps -qa)\n
 4933  sudo docker rm -f subtl_bot_api_1\n
 4934  sudo docker rm -f $(sudo docker ps -qa)\n
 4935  sudo docker ps
 4936  sudo docker rmi -f $(sudo docker images -aq)\n
 4937  sudo docker ps
 4938  docker build -t myimage .
 4939  sudo docker build -t myimage .
 4940  python -m venv venv\n
 4941  source venv/bin/activate
 4942  uvicorn main:app --reload
 4943  pip freeze > requirements.txt
 4944  code .
 4945  source venv/bin/activate
 4946  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 4947  pip freeze > requirements.txt
 4948  uvicorn main:app --reload
 4949  sudo docker build -t myimage .
 4950  source venv/bin/activate
 4951  pip freeze
 4952  pip install fastapi
 4953  pip freeze > requirements.txt
 4954  code .
 4955  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 4956  docker run -d --name mycontainer -p 80:80 myimage
 4957  sudo docker run -d --name mycontainer -p 80:80 myimage
 4958  sudo docker build -t myimage .
 4959  sudo docker run -d --name mycontainer -p 80:80 myimage
 4960  sudo docker rm -f $(sudo docker ps -qa)\n
 4961  sudo docker run -d --name mycontainer -p 80:80 myimage
 4962  sudo lsof -i :80\n
 4963  sudo docker run -d --name mycontainer -p 8080:80 myimage
 4964  sudo docker rm -f $(sudo docker ps -qa)\n
 4965  sudo docker run -d --name mycontainer -p 8080:80 myimage
 4966  pip install uvicorn
 4967  python main.py
 4968  pip install requests
 4969  python main.py
 4970  pip install yaml
 4971  pip install PyYAML
 4972  python main.py
 4973  pip freeze > requirements.txt
 4974  uvicorn main:app --reload
 4975  sudo docker run -d --name mycontainer -p 8080:80 myimage
 4976  sudo docker rm -f $(sudo docker ps -qa)\n
 4977  sudo docker run -d --name mycontainer -p 8080:80 myimage
 4978  sudo docker rm -f $(sudo docker ps -qa)\n
 4979  sudo docker build -t myimage .
 4980  sudo docker rm -f $(sudo docker ps -qa)\n
 4981  sudo docker run -d --name mycontainer -p 8080:80 myimage
 4982  sudo docker compose up --build
 4983  git status
 4984  code .
 4985  git add .
 4986  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 4987  git commit -m "dockerized subtl_llm/llm_api"
 4988  git push -u origin llm_api
 4989  git status
 4990  cd ../..
 4991  git status
 4992  git log
 4993  git reset --hard HEAD^
 4994  code .
 4995  git clone https://github.com/subtlai/subtl_bot.git
 4996  cd subtl_bot
 4997  git checkout llm_api
 4998  cd subtl_llm/llm_api
 4999  python -m venv venv\n
 5000  source venv/bin/activate
 5001  uvicorn main:app --reload
 5002  source venv/bin/activate
 5003  pip install fastapi, requests, pyaml, uvicorn
 5004  pip install fastapi requests pyaml uvicorn
 5005  pip freeze > requirements.txt
 5006  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5007  sudo docker compose up --build
 5008  git status
 5009  cd subtl_bot
 5010  git status
 5011  git add .
 5012  git commit -m "added dockerfile and docker-compose.yaml in subtl_llm/llm_api"
 5013  git push -u origin llm_api
 5014  git status
 5015  git log
 5016  code .
 5017  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5018  clear
 5019  git log
 5020  git push -u origin llm_api
 5021  npx create-react-app frontend
 5022  cd backend
 5023  mkdir backend
 5024  cd backend
 5025  npm init
 5026  code .
 5027  cd backend
 5028  npm i
 5029  npm i express body-parser
 5030  npm i cors
 5031  npm i nodemon
 5032  npm install express passport passport-google-oauth20 express-session\n
 5033  npm start
 5034  code .
 5035  git init
 5036  cd backend
 5037  npm i dotenv
 5038  npm i http-status-codes
 5039  npm start
 5040  npm i googleapis
 5041  npm start
 5042  code .
 5043  npm start
 5044  cd frontend
 5045  npm start
 5046  npm i axios
 5047  npm start
 5048  git clone https://github.com/sitepoint-editors/connect-and-use-new-google-auth-client.git
 5049  git clone https://github.com/sitepoint-editors/connect-and-use-new-google-auth-server.git
 5050  code .
 5051  cd connect-and-use-new-google-auth-client
 5052  cd connect-and-use-new-google-auth-server
 5053  npm i; npm start
 5054  cat .env
 5055  npm i; npm start
 5056  npm start
 5057  npm i; npm start
 5058  code .
 5059  cd backend
 5060  npm i google-auth-library
 5061  npm start
 5062  cd frontend
 5063  npm start
 5064  npm i react-router-dom
 5065  npm start
 5066  npm i jwt
 5067  npm i jsonwebtoken
 5068  npm start
 5069  npm i jsonwebtoken
 5070  npm start
 5071  code .
 5072  cd frontend
 5073  rm -rf .git
 5074  cd ..
 5075  git status
 5076  npm install -D tailwindcss\nnpx tailwindcss init
 5077  npm start
 5078  npm i react-datepicker
 5079  npm i react-loading
 5080  npm i react-data-table-component
 5081  npm start
 5082  clear
 5083  ls
 5084  git status
 5085  git add .
 5086  git commit -m "init setup"
 5087  git remote add origin https://github.com/chir263/outreach-vlabs.git\ngit push -u origin master
 5088  code .
 5089  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5090  cd subtl_llm/llm_api
 5091  ls
 5092  source venv/bin/activate
 5093  uvicorn main:app --reload
 5094  code .
 5095  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5096  source venv/bin/activate
 5097  uvicorn main:app --reload
 5098  clear
 5099  uvicorn main:app --reload
 5100  code .
 5101  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5102  uvicorn main:app --reload
 5103  clear
 5104  uvicorn main:app --reload
 5105  code .
 5106  clear
 5107  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5108  git status
 5109  git add .
 5110  git commit -m "setup config for ease in backend addn, optional prompt to qa.py"
 5111  git push -u origin llm_api
 5112  code .
 5113  cd frontend
 5114  cd backend
 5115  npm start
 5116  code .
 5117  git add .
 5118  git commit -m "added workshop table"
 5119  cd ..
 5120  git add .
 5121  git commit -m "added workshop table"
 5122  git push -u origin master
 5123  code .
 5124  source venv/bin/activate
 5125  uvicorn main:app --reload
 5126  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5127  code ~/.ssh/gcloud.pem
 5128  chmod 777 ~/.ssh/gcloud.pem
 5129  chmod 400 ~/.ssh/gcloud.pem
 5130  chmod 600 ~/.ssh/gcloud.pem
 5131  code .
 5132  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5133  git status
 5134  git add .
 5135  git commit -m "updated docker conf for subtl_llm"
 5136  git push -u origin llm_api
 5137  git pull
 5138  git log
 5139  code .
 5140  git log
 5141  git pull
 5142  git status
 5143  git pull
 5144  git status
 5145  git add .
 5146  git commit -m "resolved merge conflicts"
 5147  git push -u origin llm_api
 5148  git status
 5149  git add .
 5150  git commit -m "resolved merge conflicts 2"
 5151  git push -u origin llm_api
 5152  code .
 5153  cd frontend
 5154  npm start
 5155  cd backend
 5156  npm start
 5157  cd ..
 5158  git status
 5159  git add .
 5160  git commit -m "resolved invalid descriptor issue #3"
 5161  git push -u origin dev
 5162  git pull
 5163  git status
 5164  git log
 5165  git push -u origin dev
 5166  npm run build:prod
 5167  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 5168  code .
 5169  git pull
 5170  ./run.sh -d -- up --build -d llm_api nginx
 5171  sudo ./run.sh -d -- up --build -d llm_api nginx
 5172  sudo lsof -i :80\n
 5173  The error message indicates that port 80 is already in use, and Docker is unable to bind to it for the specified container. To free up the port on Ubuntu, you can follow these steps:\n\n1. Identify the process using port 80:\n\n   ```bash\n   sudo lsof -i :80\n   ```\n\n   This will show you the process ID (PID) using port 80. Make note of the PID.\n\n2. Stop the process using the port (replace [PID] with the actual PID):\n\n   ```bash\n   sudo kill -9 [PID]\n   ```\n\n   Make sure to replace [PID] with the actual process ID you obtained from the previous step.\n\n3. After stopping the process, try running your Docker container again.\n\n   ```bash\n   docker run [your_docker_options]\n   ```\n\nIf you encounter any issues or if the port is still in use, you may need to investigate further or consider changing the port that your Docker container is trying to use. Additionally, you can check for any other applications or services that might be using port 80 on your system.
 5174  sudo kill -9 $(sudo lsof -t -i:80)\n
 5175  sudo ./run.sh -d -- up --build -d llm_api nginx
 5176  sudo docker ps
 5177  sudo kill -9 $(sudo lsof -t -i:80)\n
 5178  sudo ./run.sh -d -- up --build -d llm_api nginx
 5179  sudo docker ps
 5180  git status
 5181  git pull
 5182  sudo ./run.sh -d -- up --build -d llm_api nginx
 5183  sudo docker ps
 5184  sudo kill -9 $(sudo lsof -t -i:80)\n
 5185  sudo docker ps
 5186  sudo docker rm -f $(sudo docker ps -qa)\n
 5187  sudo docker ps
 5188  sudo ./run.sh -d -- up --build -d llm_api nginx
 5189  sudo docker ps
 5190  hostname -I
 5191  pconfig
 5192  ipconfig
 5193  hostname -I
 5194  ip a\n
 5195  ip addr show\n
 5196  sudo ./run.sh -d -- up --build -d llm_api nginx
 5197  code .
 5198  git clone https://github.com/Mitanshk01/BTP-Task3.git
 5199  code .
 5200  git clone https://github.com/Mitanshk01/BTP-Task3.git
 5201  code .
 5202  9
 5203  npm i; npm start
 5204  sudo docker ps
 5205  sudo ./run.sh logs -f --tail 100 llm_api
 5206  sudo ./run.sh logs -f --tail 100 nginx
 5207  sudo ./run.sh -d -- up --build -d nginx
 5208  docker network create traefik-public
 5209  sudo docker network create traefik-public
 5210  sudo ./run.sh -d -- up --build -d nginx
 5211  sudo ./run.sh -d -- up --build -d --force-recreate nginx
 5212  sudo ./run.sh logs -f --tail 100 nginx
 5213  sudo ./run.sh -d -- up --build -d --force-recreate nginx llm_api
 5214  sudo ./run.sh logs -f --tail 100 nginx api
 5215  sudo ./run.sh logs -f --tail 100 nginx llm_api
 5216  sudo ./run.sh -d -- up --build -d --force-recreate nginx llm_api
 5217  sudo ./run.sh logs -f --tail 100 nginx llm_api
 5218  sudo ./run.sh -d -- up --build -d --force-recreate nginx llm_api
 5219  sudo ./run.sh -d -- up --build -d --force-recreate nginx 
 5220  sudo ./run.sh logs -f --tail 100 nginx llm_api
 5221  sudo ./run.sh -d -- up --build -d --force-recreate nginx 
 5222  sudo ./run.sh logs -f --tail 100 nginx llm_api
 5223  code .
 5224  pip3 install yapf\n
 5225  cd ~/.config/yapf
 5226  cd ~/.config
 5227  ls
 5228  mkdir yapf
 5229  cd yapf
 5230  cd style
 5231  mkdir style; cd style
 5232  cod
 5233  code .
 5234  git status
 5235  cd ..
 5236  history --tail 100 > his.txt
 5237  code his.txt
 5238  cd subtl_bot
 5239  sudo ./run.sh -d -- up --build -d --force-recreate nginx llm_api
 5240  sudo ./run.sh logs -f --tail 100 nginx llm_api
 5241  sudo ./run.sh -d -- up --build -d --force-recreate nginx llm_api
 5242  sudo ./run.sh logs -f --tail 100 nginx llm_api
 5243  sudo ./run.sh -d -- up --build -d --force-recreate nginx llm_api
 5244  sudo ./run.sh logs -f --tail 100 llm_api
 5245  sudo ./run.sh -d -- up --build -d --force-recreate nginx llm_api
 5246  sudo ./run.sh logs -f --tail 100 llm_api
 5247  git status
 5248  git add .
 5249  git commit -m "updated development.conf and docker conf"
 5250  git push -u origin llm_api
 5251  code his.txt
 5252  code .
 5253  cd backend; npm start
 5254  cd frontend; npm start
 5255  code .
 5256  python -u "/media/chirag/DATA/advance-python/main.py"
 5257  code .
 5258  sudo ./run.sh -d -- up --build -d --force-recreate nginx llm_api
 5259  sudo docker ps
 5260  sudo ./run.sh logs -f --tail 100 llm_api
 5261  htop
 5262  wget https://repo.protonvpn.com/debian/dists/stable/main/binary-all/protonvpn-stable-release_1.0.3-2_all.deb
 5263  sudo dpkg -i ./protonvpn-stable-release_1.0.3-2_all.deb && sudo apt update\n
 5264  sudo ./run.sh -d -- up --build -d --force-recreate nginx llm_api
 5265  sudo ./run.sh logs -f --tail 100 llm_api
 5266  code .
 5267  ls
 5268  npm start
 5269  git pull
 5270  npm install react-resizable\n
 5271  npm install @mui/icons-material\n
 5272  code .
 5273  git add .
 5274  cd conllu-backend
 5275  rm -rf .git
 5276  git add .
 5277  git status
 5278  cd frontend; npm start
 5279  cd ../frontend
 5280  npm start
 5281  cd conllu-backend
 5282  npm start
 5283  npm run start:dev
 5284  npm run start:prod
 5285  npm start
 5286  git status
 5287  git add .
 5288  git commit -m "added redent updated"
 5289  git push -u origin main
 5290  git rm -r --cached
 5291  git status
 5292  git add .
 5293  git commit -m "added recent updates"
 5294  git push -u origin main
 5295  code .
 5296  git pull
 5297  git status
 5298  git add .
 5299  sudo ./run.sh logs -f --tail 100 llm_api
 5300  sudo ./run.sh -d -- up --build -d --force-recreate nginx llm_api
 5301  sudo ./run.sh logs -f --tail 100 llm_api
 5302  sudo ./run.sh logs -f --tail 100 llm_api nginx
 5303  cd subtl_llm
 5304  ls
 5305  cd app
 5306  uvicorn main:app --reload
 5307  code .
 5308  cd /media/chirag
 5309  ls
 5310  ls -al
 5311  cd DATA
 5312  ls
 5313  cd DATA1
 5314  cd ../DATA1
 5315  ls
 5316  cd ../DATA2
 5317  ls
 5318  code .
 5319  cd ../DATA2
 5320  cd ..
 5321  ls
 5322  cd ..
 5323  ls
 5324  cd DATA1
 5325  ls
 5326  cd subtl.ai
 5327  ls
 5328  cd subtl_bot
 5329  ls
 5330  cd subtl_llm
 5331  cd app
 5332  uvicorn main:app --reload
 5333  ls
 5334  cd subtl_llm
 5335  clear
 5336  cd app
 5337  uvicorn main:app --reload
 5338  code .
 5339  python -u "/media/chirag/DATA2/advance-python/main.py"
 5340  pip install httpx
 5341  cd subtl_llm
 5342  cd ..
 5343  git add .
 5344  git status
 5345  git commit -m "added map_reduce to llm_api"
 5346  git log
 5347  git pull origin dev
 5348  git status
 5349  git pull
 5350  uvicorn main:app --reload
 5351  clear
 5352  uvicorn main:app --reload
 5353  git status
 5354  git add .
 5355  git commit -m "resolved merge conflicts"
 5356  git status
 5357  git log
 5358  git push -u origin llm_api
 5359  uvicorn main:app --reload
 5360  htop
 5361  uvicorn main:app --reload
 5362  git status
 5363  git add .
 5364  git commit -m "fixed /prompt route"
 5365  git push -u origin llm_api
 5366  git pull
 5367  git push -u origin llm_api
 5368  code .
 5369  git pull
 5370  code .
 5371  git pull
 5372  cd subtl_llm
 5373  cd app
 5374  python -m venv venv\n
 5375  source venv/bin/activate
 5376  uvicorn main:app --reload
 5377  pip install -r requirements.txt
 5378  pip install httpx
 5379  pip freeze > requirements.txt
 5380  source venv/bin/activate
 5381  uvicorn main:app --reload
 5382  pip install -r requirements.txt
 5383  source venv/bin/activate
 5384  pip install -r requirements.txt
 5385  uvicorn main:app --reload
 5386  cd subtl_llm/a
 5387  cd subtl_llm/app
 5388  uvicorn main:app --reload
 5389  git status
 5390  cd ../..
 5391  ./run.sh -d -- up --build -d llm_api nginx
 5392  sudo ./run.sh -d -- up --build -d --force-recreate nginx llm_api
 5393  sudo kill -9 $(sudo lsof -i :80\n)\n
 5394  sudo kill -9 $(sudo lsof -i :80)\n
 5395  sudo lsof -i :80
 5396  sudo kill -9 1305\n
 5397  sudo kill -9 1307\n
 5398  sudo kill -9 1308\n
 5399  sudo ./run.sh -d -- up --build -d --force-recreate nginx llm_api
 5400  sudo lsof -i :80
 5401  sudo kill -9 48119\n
 5402  sudo kill -9 48121\n
 5403  sudo kill -9 48122\n
 5404  sudo ./run.sh -d -- up --build -d --force-recreate nginx llm_api
 5405  uvicorn main:app --reload
 5406  code .
 5407  clear
 5408  cd subtl_llm/app
 5409  pip install websockets\n
 5410  uvicorn main:app --reload
 5411  pip freeze | findstr uvicorn\n
 5412  pip freeze | grep uvicorn\n
 5413  uvicorn main:app --reload
 5414  pip install -U websockets\n
 5415  uvicorn main:app --reload
 5416  code .
 5417  cd ../..
 5418  git pull
 5419  uvicorn main:app --reload
 5420  python -u "/media/chirag/DATA2/advance-python/main.py"
 5421  code .
 5422  cd backend; npm start
 5423  cd frontend; npm start
 5424  code .
 5425  ./run2.sh
 5426  chmod 600 ./run2.sh
 5427  ./run2.sh
 5428  chmod +x ./run2.sh
 5429  ./run2.sh
 5430  cd ./test_cases
 5431  cd 2
 5432  ls
 5433  ./run2.sh
 5434  cd ../..
 5435  ./run2.sh
 5436  code .
 5437  npm run start:prod
 5438  code .
 5439  cd backend; npm start
 5440  clear
 5441  cd frontend; npm start
 5442  code .
 5443  clear
 5444  cd subtl_llm/app
 5445  clear
 5446  uvicorn main:app --reload
 5447  git pull
 5448  python main.py
 5449  python -m venv venv\n
 5450  source venv/bin/activate
 5451  pip install -r requirements.txt
 5452  pip install sk-learn
 5453  pip install scikit-learn
 5454  python main.py
 5455  source venv/bin/activate
 5456  python main.py
 5457  pip install -r requirements.txt
 5458  python main.py
 5459  pip install requests
 5460  python main.py
 5461  python main.py --help
 5462  benchmark_cli
 5463  benchmark_cli question_validation
 5464  python main.py --install-completion
 5465  benchmark_cli question_validation
 5466  python main.py --install-completion
 5467  cd subtl_llm/app
 5468  clear
 5469  python main.py --install-completion
 5470  cd be
 5471  cd benchmark_cli
 5472  python main.py --install-completion
 5473  source venv/bin/activate
 5474  python main.py --install-completion
 5475  python main.py --help
 5476  python main.py --show-completion
 5477  python main.py mcq_validation
 5478  code .
 5479  source venv/bin/activate
 5480  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5481  python main.py --help
 5482  python main.py mcq_validation --help
 5483  python main.py mcq_validation llm_server=http://35.193.52.196:8090/generate validation_input_file=./data/quail_data.json output_dir=./\n
 5484  python main.py mcq_validation http://35.193.52.196:8090/generate ./data/quail_data.json ./\n
 5485  python main.py mcq_validation http://35.193.52.196:8090/generate ./data/quail_data.json ./out1\n
 5486  python main.py mcq_validation http://127.0.0.1:8000/prompt/ ./data/quail_data.json ./out1\n
 5487  python main.py mcq_validation http://127.0.0.1:8000/llmapi/prompt/ ./data/quail_data.json ./out1\n
 5488  python main.py mcq_validation http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5489  python main.py --help
 5490  python main.py question_validation --help
 5491  python main.py question_validation http://127.0.0.1:8000/llmapi/qa/ ./data/quail_data.json ./out1\n
 5492  python main.py question_validation http://127.0.0.1:8000/llmapi/qa/ ./data/validation_dataset_rbi.json ./out1\n
 5493  python main.py question_validation http://127.0.0.1:8000/llmapi/prompt/ ./data/validation_dataset_rbi.json ./out1\n
 5494  pip install pydantic
 5495  pip freeze -l > requirements.txt
 5496  python main.py question_validation http://127.0.0.1:8000/llmapi/prompt/ ./data/validation_dataset_rbi.json ./out1\n
 5497  python main.py mcq_validation http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5498  python -u "/media/chirag/DATA2/subtl.ai/subtl_bot/subtl_llm/app/benchmark_cli/commands/base.py"
 5499  pip install httpx
 5500  pip freeze -l > requirements.txt
 5501  python main.py mcq_validation http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5502  python main.py question_validation http://127.0.0.1:8000/llmapi/prompt/ ./data/validation_dataset_rbi.json ./out1\n
 5503  python main.py mcq_validation http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5504  python main.py question_validation http://127.0.0.1:8000/llmapi/prompt/ ./data/validation_dataset_rbi.json ./out1\n
 5505  python main.py mcq_validation http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5506  python main.py question_validation http://127.0.0.1:8000/llmapi/prompt/ ./data/validation_dataset_rbi.json ./out1\n
 5507  git status
 5508  git add .
 5509  git commit -m "modularized benchmark_cli"
 5510  git push -u origin llm_api
 5511  code .
 5512  python main.py --help\n
 5513  python main.py mcq_validation --help\n
 5514  python main.py --no-sync mcq_validation http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5515  python main.py --sync False mcq_validation http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5516  python main.py --sync=False mcq_validation http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5517  python main.py mcq_validation --no-sync http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5518  python main.py mcq_validation --no-sync --num-samples 20 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5519  python main.py mcq_validation --no-sync --num-samples 100 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5520  python main.py mcq_validation --no-sync --num-samples 10 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5521  python main.py mcq_validation --no-sync --num-samples 100 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5522  python main.py mcq_validation --no-sync --num-samples 10 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5523  python main.py mcq_validation --no-sync --num-samples 50 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5524  python main.py mcq_validation --num-samples 20 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5525  python main.py mcq_validation --num-samples --no-sync 20 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5526  python main.py mcq_validation --no-sync --num-samples 20 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5527  python main.py mcq_validation --no-sync --num-samples 30 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5528  python main.py mcq_validation --no-sync --num-samples 40 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5529  python
 5530  python main.py mcq_validation --no-sync --num-samples 40 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5531  uvicorn main:app --reload
 5532  python main.py mcq_validation --no-sync --num-samples 40 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5533  python main.py mcq_validation --no-sync --num-samples 60 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5534  python main.py mcq_validation --no-sync --num-samples 80 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5535  python main.py mcq_validation --num-samples 20 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5536  python main.py mcq_validation --no-sync --num-samples 20 http://127.0.0.1:8000/llmapi/mcq/ ./data/quail_data.json ./out1\n
 5537  python main.py question_validation http://127.0.0.1:8000/llmapi/prompt/ ./data/validation_dataset_rbi.json ./out1\n
 5538  python main.py question_validation --no-sync http://127.0.0.1:8000/llmapi/prompt/ ./data/validation_dataset_rbi.json ./out1\n
 5539  python main.py question_validation http://127.0.0.1:8000/llmapi/prompt/ ./data/validation_dataset_rbi.json ./out1\n
 5540  python main.py question_validation --no-sync http://127.0.0.1:8000/llmapi/prompt/ ./data/validation_dataset_rbi.json ./out1\n
 5541  python main.py question_validation --no-sync --num-samples 30 http://127.0.0.1:8000/llmapi/prompt/ ./data/validation_dataset_rbi.json ./out1\n
 5542  python main.py question_validation --no-sync --num-samples 50 http://127.0.0.1:8000/llmapi/prompt/ ./data/validation_dataset_rbi.json ./out1\n
 5543  python main.py question_validation --no-sync --num-samples 70 http://127.0.0.1:8000/llmapi/prompt/ ./data/validation_dataset_rbi.json ./out1\n
 5544  git status
 5545  git add .
 5546  git commit -m "added --no-sync option to benchmark_cli for async processing"
 5547  git push -u origin llm_api
 5548  source venv/bin/activate
 5549  pip freeze -l > requirements.txt
 5550  code .
 5551  source venv/bin/activate
 5552  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5553  source venv/bin/activate
 5554  pip install "python-jose[cryptography]"\n
 5555  pip install "passlib[bcrypt]"\n
 5556  pip freeze -l > requirements.txt
 5557  source venv/bin/activate
 5558  pip freeze -l > requirements.txt
 5559  python -m venv venv\n
 5560  source venv/bin/activate
 5561  pip install -r requirements.txt
 5562  pip install "passlib[bcrypt]"
 5563  pip install "python-jose[cryptography]"\n
 5564  pip freeze -l > requirements.txt
 5565  uvicorn main2:app --reload
 5566  pip install typing
 5567  uvicorn main2:app --reload
 5568  uvicorn main:app --reload
 5569  pip install --upgrade python\n
 5570  uvicorn main2:app --reload
 5571  source venv/bin/activate
 5572  pip install python-multipart
 5573  pip freeze -l > requirements.txt
 5574  uvicorn main2:app --reload
 5575  code .
 5576  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5577  git pull
 5578  ./run.sh -d -- up --build -d llm_api nginx
 5579  sudo ./run.sh -d -- up --build -d llm_api nginx
 5580  sudo docker ts
 5581  sudo docker ps
 5582  sudo lsof -t -i:80
 5583  ps $(sudo lsof -t -i:80)
 5584  sudo systemctl stop apache2
 5585  sudo ./run.sh -d -- up --build -d llm_api nginx
 5586  cd subtl_doc_parser
 5587  sudo ./subtl_doc_parser.sh
 5588  sudo ./subtl_doc_parser.sh -d
 5589  sudo ./subtl_doc_parser.sh -d --up --build backend
 5590  sudo ./subtl_doc_parser.sh -d --up --build -d backend
 5591  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 5592  htop
 5593  ps $(sudo lsof -t -i:5432)
 5594  sudo systemctl stop postgresql\n
 5595  ps $(sudo lsof -t -i:5432)
 5596  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 5597  code .
 5598  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5599  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 5600  source venv/bin/activate
 5601  pip install sqlalchemy\n
 5602  ./run1B.sh 
 5603  chmod +x ./run1B.sh
 5604  ./run1B.sh 
 5605  chmod +x ./run2.sh
 5606  ./run2.sh
 5607  bash run2.sh
 5608  chmod +x ./run2.sh
 5609  bash run2.sh
 5610  chmod +x ./run3.sh
 5611  bash run3.sh
 5612  cd ../2
 5613  bash run2.sh
 5614  code .
 5615  cd ../3
 5616  bash run3.sh
 5617  code .
 5618  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5619  clear
 5620  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 5621  cd subtl_doc_parser
 5622  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 5623  sudo ./subtl_doc_parser.sh -d -- up --build -d backend ngnix
 5624  sudo ./subtl_doc_parser.sh -d -- up --build -d backend nginx
 5625  ps $(sudo lsof -t -i:443)
 5626  sudo ./subtl_doc_parser.sh -d -- up --build -d backend nginx
 5627  docker ps
 5628  sudo docker ps
 5629  cd ..
 5630  sudo ./run.sh -d -- up --build -d nginx
 5631  sudo docker ps
 5632  sudo ./run.sh logs -f --tail 100 nginx
 5633  cd subtl_doc_parser
 5634  sudo ./subtl_doc_parser.sh logs --tail 100 backend
 5635  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 5636  sudo ./subtl_doc_parser.sh logs --tail 100 backend
 5637  cd ../2
 5638  ls
 5639  cd 2
 5640  bash run2.sh
 5641  cd ../3
 5642  bash run3.sh
 5643  cd ../2
 5644  bash run2.sh
 5645  cd ../3
 5646  bash run3.sh
 5647  code .
 5648  clear
 5649  cd backend; npm start
 5650  cd frontend; npm start
 5651  tar -zcvf 2021101100.tar.gz 2021101100
 5652  tar -zcvf "2021101100 (1).tar.gz" "2021101100 (1)"
 5653  code .
 5654  ls
 5655  cd 2
 5656  clear
 5657  bash run2.sh
 5658  git status
 5659  git add .
 5660  git commit -m "added tables and filters + landing page"
 5661  git push -u origin master
 5662  code .
 5663  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5664  cd subtl_llm/app
 5665  source venv/bin/activate
 5666  uvicorn main2:app --reload
 5667  uvicorn main:app --reload
 5668  pip freeze -l > requirements.txt
 5669  sudo ./run.sh -d -- up --build -d nginx llmapi
 5670  sudo ./run.sh -d -- up --build -d llmapi nginx
 5671  sudo ./run.sh -d -- up --build -d llm_api nginx
 5672  uvicorn main:app --reload
 5673  clear
 5674  uvicorn main:app --reload
 5675  pip install pydantic-settings
 5676  uvicorn main:app --reload
 5677  sudo ./run.sh logs -f --tail 100 llm_api
 5678  sudo ./run.sh -d -- up --build -d llm_api nginx
 5679  pip freeze -l > requirements.txt
 5680  sudo ./run.sh -d -- up --build -d llm_api nginx
 5681  sudo ./run.sh logs -f --tail 100 llm_api
 5682  clear
 5683  sudo ./run.sh logs -f --tail 100 llm_api
 5684  pip install pydantic[email]
 5685  pip install email-validator
 5686  pip freeze -l > requirements.txt
 5687  sudo ./run.sh -d -- up --build -d llm_api nginx
 5688  sudo ./run.sh logs -f --tail 100 llm_api
 5689  sudo ./run.sh -d -- up --build -d llm_api nginx
 5690  sudo ./run.sh logs -f --tail 100 llm_api
 5691  sudo ./run.sh -d -- up --build -d llm_api nginx
 5692  sudo ./run.sh logs -f --tail 100 llm_api
 5693  sudo ./run.sh -d -- up --build -d llm_api nginx
 5694  sudo ./run.sh logs -f --tail 100 llm_api
 5695  uvicorn main:app --reload
 5696  pip install psycopg2
 5697  source venv/bin/activate
 5698  pip install psycopg2
 5699  pip install psycopg2-binary\n
 5700  pip install psycopg2
 5701  sudo apt-get install libpq-dev python3-dev
 5702  pip install psycopg2
 5703  pip freeze -l > requirements.txt
 5704  sudo ./run.sh -d -- up --build -d llm_api nginx
 5705  sudo ./run.sh logs -f --tail 100 llm_api
 5706  git status
 5707  source venv/bin/activate
 5708  pip freeze -l > requirements.txt
 5709  git status
 5710  git add .
 5711  git commit -m "added authentication to llm_api + yapf formatting"
 5712  git push -u origin llm_api
 5713  git pull
 5714  git add .
 5715  git commit -m "resolved merge conflict"
 5716  git push -u origin llm_api
 5717  sudo ./run.sh -d -- up --build -d llm_api nginx
 5718  sudo ./run.sh logs -f --tail 100 llm_api
 5719  code .
 5720  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5721  python -u "/media/chirag/DATA2/subtl.ai/subtl_bot/test.py"
 5722  code .
 5723  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5724  clear
 5725  sudo ./run.sh logs -f --tail 100 llm_api
 5726  code .
 5727  clear
 5728  npm start
 5729  clear
 5730  npm start
 5731  npm i zustand
 5732  npm start
 5733  htop
 5734  nodejs
 5735  code .
 5736  npm start
 5737  clear
 5738  git add .
 5739  git commit -m "add/edit/delete features + total (for workshop)"
 5740  git push -u origin master
 5741  code .
 5742  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5743  cd subtl_llm/app
 5744  ls
 5745  pip install celery
 5746  pip install kombu\n
 5747  source venv/bin/activate
 5748  pip install celery
 5749  pip install kombu\n
 5750  pip freeze -l > requirements.txt
 5751  sudo ./run.sh logs -f --tail 100 llm_api
 5752  git pull
 5753  git status
 5754  git add .
 5755  git commit -m "update requirement.txt"
 5756  git pull
 5757  git log
 5758  code .
 5759  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5760  clear
 5761  sudo ./run.sh logs -f --tail 100 llm_api
 5762  sudo ./run.sh -d -- up --build -d llm_api nginx
 5763  sudo ./run.sh logs -f --tail 100 llm_api
 5764  source venv/bin/activate
 5765  pip install celery
 5766  pip freeze -l > requirements.txt
 5767  pip install -r requirements.txt
 5768  pip freeze -l > requirements.txt
 5769  sudo ./run.sh -d -- up --build -d llm_api nginx
 5770  python -m venv venv\n
 5771  source venv/bin/activate
 5772  pip install -r requirements.txt
 5773  pip install celery
 5774  pip freeze -l > requirements.txt
 5775  sudo ./run.sh -d -- up --build -d llm_api nginx
 5776  sudo ./run.sh logs -f --tail 100 llm_api
 5777  cd subtl_doc_parser
 5778  sudo ./subtl_doc_parser.sh logs --tail 100 backend
 5779  sudo ./subtl_doc_parser.sh logs -f --tail 100 backend
 5780  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 5781  sudo docker ps
 5782  sudo docker images ls
 5783  sudo docker ps
 5784  sudo ./subtl_doc_parser.sh logs -f --tail 100 backend
 5785  sudo ./run.sh -d -- up --build -d llm_api nginx
 5786  sudo ./run.sh logs -f --tail 100 llm_api
 5787  sudo ./run.sh -d -- up --build -d llm_api nginx
 5788  sudo ./run.sh logs -f --tail 100 llm_api
 5789  sudo ./run.sh -d -- up --build -d llm_api nginx
 5790  sudo ./run.sh logs -f --tail 100 llm_api
 5791  source venv/bin/activate
 5792  pip install redis
 5793  pip freeze -l > requirements.txt
 5794  sudo ./run.sh -d -- up --build -d llm_api nginx
 5795  sudo ./run.sh logs -f --tail 100 llm_api
 5796  htop
 5797  sudo ./run.sh -d -- up --build -d llm_api nginx
 5798  sudo ./run.sh logs -f --tail 100 llm_api
 5799  sudo ./run.sh -d -- up --build -d llm_api nginx
 5800  sudo ./run.sh logs -f --tail 100 llm_api
 5801  sudo docker ps
 5802  sudo ./run.sh -d -- up --build -d llm_api nginx llm_worker
 5803  sudo ./run.sh logs -f --tail 100 llm_api
 5804  sudo ./run.sh logs -f --tail 100 llm_worker
 5805  sudo ./run.sh -d -- up --rebuild -d llm_worker
 5806  sudo ./run.sh -d -- up --build -d llm_worker
 5807  sudo ./run.sh logs -f --tail 100 llm_worker
 5808  sudo docker images\n
 5809  sudo docker image prune\n
 5810  sudo docker images\n
 5811  sudo docker ps
 5812  sudo docker volume ls
 5813  sudo docker images\n
 5814  sudo ./run.sh logs -f --tail 100 llm_worker
 5815  celery --help
 5816  sudo docker ps -a\n
 5817  sudo docker container prune\n
 5818  sudo docker image prune\n
 5819  sudo docker image
 5820  sudo docker ps image
 5821  sudo docker image ls
 5822  sudo docker rmi docparser celeryworker\n
 5823  sudo docker stop e1ef03abf9a8 33d4dd11b948\n
 5824  sudo docker rm e1ef03abf9a8 33d4dd11b948
 5825  sudo docker stop e1ef03abf9a8 33d4dd11b948\n
 5826  sudo docker rmi docparser celeryworker\n
 5827  sudo docker stop f67376b17e1a\n
 5828  sudo docker rm f67376b17e1a
 5829  sudo docker image ls
 5830  sudo docker rmi celeryworker\n
 5831  sudo docker image ls
 5832  sudo ./run.sh logs -f --tail 100 llm_worker
 5833  sudo ./run.sh -d -- up --build -d llm_worker
 5834  sudo ./run.sh logs -f --tail 100 llm_worker
 5835  sudo ./run.sh -d -- up --build -d llm_worker
 5836  sudo ./run.sh logs -f --tail 100 llm_worker
 5837  sudo ./run.sh -d -- up --build -d llm_worker
 5838  sudo ./run.sh logs -f --tail 100 llm_worker
 5839  sudo ./run.sh -d -- up --build -d llm_worker
 5840  sudo ./run.sh logs -f --tail 100 llm_worker
 5841  sudo ./run.sh logs -f --tail 100 llm_api
 5842  cd ../..
 5843  sudo ./run.sh logs -f --tail 100 llm_api
 5844  sudo ./run.sh -d -- up --build -d llm_worker
 5845  sudo ./run.sh logs -f --tail 100 llm_api
 5846  sudo docker image ls
 5847  sudo docker rm 73c83a129d42
 5848  sudo docker rmi 73c83a129d42
 5849  sudo docker rmi 18a121b71ab0
 5850  sudo docker rmi 06b7e57540c1
 5851  sudo docker rmi 0b6f048da088
 5852  sudo docker image ls
 5853  sudo docker system prune -f\n\n\n\n\n\n
 5854  sudo ./run.sh -d -- up --build -d llm_worker
 5855  sudo ./run.sh logs -f --tail 100 llm_worker
 5856  sudo ./run.sh -d -- up --build -d llm_worker
 5857  sudo ./run.sh logs -f --tail 100 llm_worker
 5858  sudo docker system prune -f
 5859  sudo ./run.sh -d -- up --build -d llm_api
 5860  sudo ./run.sh logs -f --tail 100 llm_worker
 5861  sudo ./run.sh logs -f --tail 100 llm_api
 5862  sudo ./run.sh -d -- up --build -d llm_worker llm_api nginx
 5863  sudo ./run.sh logs -f --tail 100 llm_api
 5864  sudo ./run.sh logs -f --tail 100 llm_worker
 5865  sudo ./run.sh -d -- up --build -d llm_worker llm_api nginx
 5866  sudo ./run.sh logs -f --tail 100 llm_worker
 5867  sudo ./run.sh -d -- up --build -d llm_worker
 5868  sudo ./run.sh logs -f --tail 100 llm_worker
 5869  sudo docker system prune -f
 5870  sudo ./run.sh -d -- up --build -d llm_worker
 5871  wget https://downloads.apache.org//jmeter/binaries/apache-jmeter-5.4.1.tgz\n
 5872  systemctl start apache2
 5873  sudo systemctl enable apache2\n
 5874  wget https://downloads.apache.org//jmeter/binaries/apache-jmeter-5.3.zip
 5875  unzip apache-jmeter-5.3.zip\n
 5876  java --version
 5877  wget https://downloads.apache.org//jmeter/binaries/apache-jmeter-5.5.zip
 5878  unzip apache-jmeter-5.3.zip\n
 5879  unzip apache-jmeter-5.5.zip\n
 5880  cd apache-jmeter-5.3/bin
 5881  cd apache-jmeter-5.5/bin
 5882  ./jmeter\n
 5883  sudo ./run.sh -d -- up --build -d llm_worker
 5884  sudo docker system prune -f
 5885  cd subtl_llm/app\n\n\n\n\n\n
 5886  clear
 5887  uvicorn main:app --reload ^[[200~--workers 4
 5888  uvicorn main:app --reload --workers 4
 5889  source venv/bin/activate
 5890  uvicorn main:app --reload --workers 4
 5891  htop
 5892  code .
 5893  python -m venv venv\n
 5894  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5895  source venv/bin/activate
 5896  sudo lshw -numeric -C display\n
 5897  sudo lshw -C display\n
 5898  lspci | grep ' VGA ' | cut -d" " -f 1\n03:00.0\n
 5899  lspci | grep ' VGA ' | cut -d" " -f 103:00.0\n
 5900  lspci | grep ' VGA ' | cut -d" " -f 1\n
 5901  lspci | grep ' VGA ' | cut -d" " -f 1 | xargs -i lspci -v -s {}\n\n
 5902  pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
 5903  python --version
 5904  pip freeze -l > requirements.txt
 5905  pip install networkx==3.1
 5906  pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cpu
 5907  code .
 5908  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5909  clear
 5910  sudo ./run.sh -d -- up --build -d llm_api
 5911  sudo ./run.sh logs -f --tail 100 llm_api
 5912  sudo ./run.sh -d -- up --build -d llm_api
 5913  ls
 5914  cd apache-jmeter-5.5/bin
 5915  ./jmeter\n
 5916  sudo ./run.sh logs -f --tail 100 llm_api
 5917  ht
 5918  htop
 5919  sudo ./run.sh -d -- up --build -d llm_api
 5920  sudo ./run.sh logs -f --tail 100 llm_api
 5921  sudo ./run.sh -d -- up --build -d llm_api
 5922  sudo ./run.sh logs -f --tail 100 llm_api
 5923  cd subtl_llm/app\n\n\n\n\n\n
 5924  uvicorn main:app --reload --workers 4
 5925  source venv/bin/activate
 5926  uvicorn main:app --reload --workers 4
 5927  uvicorn main:app --workers 4 --reload
 5928  uvicorn main:app --workers 4 
 5929  sudo ./run.sh -d -- up --build -d llm_api llm_worker
 5930  htop
 5931  sudo ./run.sh logs -f --tail 100 llm_worker
 5932  code sample.josn
 5933  code .
 5934  clear
 5935  npm start
 5936  clear
 5937  npm start
 5938  sudo ./run.sh -d -- up --build -d llm_api llm_worker
 5939  sudo ./run.sh logs -f --tail 100 llm_worker
 5940  sudo ./run.sh -d -- up --build -d llm_api llm_worker
 5941  sudo ./run.sh logs -f --tail 100 llm_worker
 5942  clear
 5943  sudo ./run.sh logs -f --tail 100 llm_api
 5944  git pull
 5945  clear
 5946  git status
 5947  sudo ./run.sh logs -f --tail 100 llm_api
 5948  python main.py mcq_validation http://localhost/llmapi/mcq/ ./data/quail_data.json ./out1
 5949  source venv/bin/activate
 5950  python main.py mcq_validation http://localhost/llmapi/mcq/ ./data/quail_data.json ./out1
 5951  pip install -r requirements.txt
 5952  pip install wandb
 5953  python main.py mcq_validation http://localhost/llmapi/mcq/ ./data/quail_data.json ./out1
 5954  python main.py --no-sync mcq_validation http://localhost/llmapi/mcq/ ./data/quail_data.json ./out1
 5955  python main.py mcq_validation --no-sync http://localhost/llmapi/mcq/ ./data/quail_data.json ./out1
 5956  code .
 5957  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 5958  code subtl_llm/app
 5959  cd subtl_llm/app\n\n\n\n\n\n
 5960  clear
 5961  ls
 5962  source venv/bin/activate
 5963  uvicorn main:app --workers 4 
 5964  sudo ./run.sh logs -f --tail 100 llm_api
 5965  cd apache-jmeter-5.5
 5966  cd bin
 5967  ./jmeter\n
 5968  uvicorn main:app --workers 4 
 5969  sudo ./run.sh -d -- up --build -d llm_api llm_worker
 5970  sudo ./run.sh logs -f --tail 100 llm_api
 5971  sudo ./run.sh -d -- up --build -d llm_api llm_worker
 5972  sudo ./run.sh logs -f --tail 100 llm_api
 5973  sudo ./run.sh logs -f --tail 100 llm_worker
 5974  sudo ./run.sh -d -- up --build -d llm_api llm_worker
 5975  sudo docker system prune -f
 5976  sudo ./run.sh logs -f --tail 100 llm_worker
 5977  sudo ./run.sh logs -f --tail 100 llm_api
 5978  sudo ./run.sh -d -- up --build -d llm_api llm_worker
 5979  sudo ./run.sh logs -f --tail 100 llm_api
 5980  sudo ./run.sh -d -- up --build -d llm_api llm_worker
 5981  sudo ./run.sh logs -f --tail 100 llm_api
 5982  uvicorn main:app --workers 4 
 5983  uvicorn main:app --workers 1 
 5984  uvicorn main:app --workers 4
 5985  uvicorn main:app --workers 17
 5986  git status
 5987  sudo ./run.sh -d -- up --build -d llm_api llm_worker
 5988  sudo ./run.sh logs -f --tail 100 llm_api
 5989  sudo ./run.sh -d -- up --build -d llm_api llm_worker
 5990  sudo ./run.sh logs -f --tail 100 llm_api
 5991  sudo ./run.sh -d -- up --build -d llm_api llm_worker
 5992  sudo ./run.sh logs -f --tail 100 llm_api
 5993  sudo ./run.sh -d -- up --build -d llm_api llm_worker
 5994  sudo ./run.sh logs -f --tail 100 llm_api
 5995  sudo ./run.sh -d -- up --build -d llm_api llm_worker
 5996  sudo ./run.sh logs -f --tail 100 llm_api
 5997  git status
 5998  git add .
 5999  git commit -m "Add celery for MapReduce, Benchmarking"
 6000  git push -u origin llm_api
 6001  git pull
 6002  sudo ./run.sh logs -f --tail 100 llm_api
 6003  code subtl_llm/app
 6004  code .
 6005  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 6006  git status
 6007  clear
 6008  git add .
 6009  git commit -m "Fixed mcq bug"
 6010  git push -u origin llm_api
 6011  code .
 6012  cd frontend; npm start
 6013  cd backend; npm start
 6014  npm start
 6015  code .
 6016  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 6017  clear
 6018  source venv/bin/activate
 6019  pip install matplotlib
 6020  pip install nltk\n
 6021  pip install sk-learn
 6022  pip install sklearn
 6023  pip install scikit-learn
 6024  sudo docker system prune -f
 6025  htop
 6026  source venv/bin/activate
 6027  clear
 6028  pip install tensorflow
 6029  htop
 6030  code .
 6031  git log
 6032  clear
 6033  cd client
 6034  npm start
 6035  cd minio\ server
 6036  npm start
 6037  cd server
 6038  npm start
 6039  mysqldump -u dfs_root -p dfs_db > new_schema.sql
 6040  mongodump --uri 'mongodb://localhost:27017/Image_Annotation_IHUB'\n
 6041  code .
 6042  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 6043  pip install skimage
 6044  pip install scikit-image\n
 6045  htop
 6046  code .
 6047  cd server
 6048  npm start
 6049  cd minio\ server
 6050  npm start
 6051  sudo kill -9 $(sudo lsof -t -i:5001)\n
 6052  npm start
 6053  cd frontend; npm start
 6054  cd client; npm start
 6055  git origin\n
 6056  git remote origin
 6057  git remote -v
 6058  code .
 6059  cd frontend; npm start
 6060  npm start
 6061  ^[[200~npm install react-tooltip
 6062  npm install react-tooltip\n
 6063  cd frontend; npm install react-tooltip\n
 6064  git remote add origin https://github.com/virtual-labs/app-outreach-tracker-web.git
 6065  git remote rm origin
 6066  git remote add origin https://github.com/virtual-labs/app-outreach-tracker-web.git
 6067  git status
 6068  git add .
 6069  git commit -m "added cosmetic changes"
 6070  git push -u origin dev
 6071  git branch dev
 6072  git checkout dev
 6073  git push -u origin dev
 6074  git pull
 6075  git push -u origin dev
 6076  git push -u origin dev -f
 6077  git pull origin dev
 6078  git pull origin dev -f
 6079  git add .
 6080  git commit -m "added license"
 6081  git push -u origin dev 
 6082  git push -u origin dev -f
 6083  git push -u origin dev 
 6084  git push -u origin dev -f
 6085  git add .
 6086  git commit -m "moves config.json"
 6087  git push -u origin dev
 6088  git status
 6089  git add .
 6090  git commit -m "add user-doc.md"
 6091  git push -u origin dev
 6092  code .
 6093  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 6094  sudo ./run.sh logs -f --tail 100 llm_api
 6095  ./jmeter\n
 6096  sudo ./run.sh logs -f --tail 100 llm_api
 6097  sudo ./run.sh -d -- up --build -d llm_api
 6098  sudo ./run.sh -d -- up --build -d llm_worker
 6099  clear
 6100  sudo ./run.sh logs -f --tail 100 llm_api
 6101  clear
 6102  sudo ./run.sh logs -f --tail 100 llm_worker
 6103  git status
 6104  sudo ./run.sh logs -f --tail 100 llm_worker llm_api
 6105  sudo ./run.sh -d -- up --build -d llm_worker llm_api
 6106  sudo docker system prune -f
 6107  ./jmeter\n
 6108  co
 6109  code .
 6110  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 6111  sudo ./run.sh -d -- up --build -d llm_worker llm_api
 6112  sudo ./run.sh -d -- up --build -d llm_worker
 6113  sudo ./run.sh logs -f --tail 100 llm_worker
 6114  sudo ./run.sh -d -- up --build -d llm_worker
 6115  sudo ./run.sh logs -f --tail 100 llm_worker
 6116  sudo ./run.sh -d -- up --build -d llm_worker
 6117  sudo ./run.sh logs -f --tail 100 llm_worker
 6118  clear
 6119  sudo ./run.sh logs -f --tail 100 llm_api
 6120  sudo ./run.sh -d -- up --build -d llm_worker llm_api
 6121  sudo ./run.sh -d -- up --build -d llm_api
 6122  sudo ./run.sh logs -f --tail 100 llm_api
 6123  sudo ./run.sh -d -- up --build -d llm_worker
 6124  sudo ./run.sh logs -f --tail 100 llm_worker
 6125  sudo ./run.sh -d -- up --build -d llm_worker
 6126  sudo docker system prune -f
 6127  sudo docker ps
 6128  sudo docker ps image
 6129  sudo docker image ls
 6130  docker image prune
 6131  sudo docker image prune
 6132  sudo docker container prune
 6133  sudo docker volume prune
 6134  sudo docker system prune\n\n
 6135  sudo docker system prune --volumes\n
 6136  sudo docker system prune -a --volumes\n
 6137  sudo docker rm $(docker ps -f status=exited -aq)\n
 6138  sudo docker rmi $(docker images -f "dangling=true" -q)
 6139  bash sudo docker rmi $(docker images -f "dangling=true" -q)
 6140  sudo docker image ls
 6141  sudo docker ps
 6142  docker ps
 6143  sudo docker ps
 6144  sudo groupadd docker\n
 6145  newgrp docker
 6146  docker ps
 6147  sudo docker ps
 6148  sudo docker system prune -a --volumes\n
 6149  sudo docker system prune\n
 6150  sudo docker system prune -a volume\n
 6151  gnome-disks\n
 6152  sudo docker rm -vf $(docker ps -aq)
 6153  sudo docker rm -vf $(sudo docker ps -aq)
 6154  sudo docker rmi -f $(sudo docker images -aq)\n
 6155  sudo docker system prune
 6156  sudo docker system prune -f
 6157  cd .docker
 6158  ls
 6159  disk usage
 6160  df -h
 6161  du -h
 6162  ls
 6163  du -sh
 6164  sudo apt-get clean\n
 6165  sudo apt-get autoclean\n
 6166  sudo apt-get autoremove\n
 6167  du -sk * | sort -nr | head -10\n
 6168  sudo apt autoremove\n sudo apt autoclean
 6169  sudo docker ps
 6170  sudo docker image ls
 6171  cd /
 6172  cd ..
 6173  ls
 6174  cd ..
 6175  ls
 6176  sudo du -h --max-depth=1 /\n
 6177  sudo apt update\nsudo apt install gparted\n
 6178  code .
 6179  cd subtl_doc_parser
 6180  sudo ./subtl_doc_parser.sh logs -f --tail 100 backend
 6181  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 6182  sudo ./run.sh -d -- up --build -d llm_worker llm_api nginx
 6183  ./run.sh -d -- up --build -d llm_worker llm_api nginx
 6184  sudo ./run.sh -d -- up --build -d llm_worker llm_api nginx
 6185  docker system prune --all --volumes\n
 6186  sudo docker system prune --all --volumes\n
 6187  sudo docker service rm $(docker service ls -q)\n
 6188  sudo docker service rm $(sudo docker service ls -q)\n
 6189  sudodocker rm -f $(sudo docker ps -aq)\n
 6190  sudo docker rm -f $(sudo docker ps -aq)\n
 6191  sudo docker rmi -f $(sudo docker images -aq)\n
 6192  systemctl stop docker\n
 6193  sudo apt-get purge docker-ce -y\n
 6194  sudo apt-get autoremove --purge docker-ce -y\n
 6195  dpkg -l | grep -i docker\n
 6196  sudo apt-get purge -y docker-engine docker docker.io docker-ce docker-ce-cli docker-compose-plugin\nsudo apt-get autoremove -y --purge docker-engine docker docker.io docker-ce docker-compose-plugin\n
 6197  sudo rm -rf /var/lib/docker /etc/docker\nsudo rm /etc/apparmor.d/docker\nsudo groupdel docker\nsudo rm -rf /var/run/docker.sock\n
 6198  sudo groupdel docker\n
 6199  sudo rm -rf /var/run/docker.sock\n
 6200  docker
 6201  sudo docker ps
 6202  sudo apt install docker.io
 6203  docker
 6204  docker ps
 6205  systemctl docker
 6206  systemctl status docker\n
 6207  sudo docker ps
 6208  grep docker /etc/group\n
 6209  sudo usermod -aG docker $USER\n
 6210  docker ps
 6211  docker info\n
 6212  sudo docker info\n
 6213  cd /home/chirag/.docker/desktop
 6214  ls
 6215  sudo systemctl status docker\n
 6216  code .
 6217  clear
 6218  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 6219  docker --version
 6220  docker-compose --version
 6221  sudo docker-compose --version
 6222  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 6223  sudo docker compose --help
 6224  docker compose version
 6225  sudo docker compose version
 6226  apt-cache policy docker-compose-plugin
 6227  sudo apt-get install docker-compose-plugin
 6228  docker compose version\n
 6229  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 6230  sudo ./run.sh -d -- up --build -d llm_worker llm_api nginx
 6231  htop
 6232  sudo docker image ls
 6233  hadoop --version
 6234  sudo docker ps
 6235  sudo docker image ls
 6236  history > his1.txt
 6237  sudo docker network create traefik-public
 6238  code .
 6239  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 6240  clear
 6241  sudo ./run.sh -d -- up --build -d llm_worker llm_api nginx
 6242  sudo docker os
 6243  sudo docker ps
 6244  sudo ./run.sh logs -f --tail 100 llm_worker
 6245  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 6246  sudo ./subtl_doc_parser.sh -d -- up --build -d redis-queue queue
 6247  sudo ./run.sh -d -- up --build -d llm_worker llm_api nginx
 6248  sudo docker ps
 6249  sudo ./run.sh -d -- up --build -d nginx llm_worker llm_api
 6250  sudo netstat -tuln | grep ':80'\n
 6251  sudo service apache2
 6252  sudo service apache2 stop
 6253  sudo ./run.sh -d -- up --build -d nginx llm_worker llm_api
 6254  sudo ./run.sh logs -f --tail 100 llm_api
 6255  sudo docker system prune -f
 6256  sudo ./run.sh logs -f --tail 100 llm_worker
 6257  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 6258  git pull
 6259  docker volume create subtl_bot_minio-data
 6260  sudo docker volume create subtl_bot_minio-data
 6261  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 6262  sudo ./run.sh logs -f --tail 100 llm_worker
 6263  sudo netstat -tuln | grep ':5432'\n
 6264  sudo service postgresql stop\n
 6265  sudo ./subtl_doc_parser.sh -d -- up --build -d backend
 6266  sudo docker system prune -f
 6267  code .
 6268  ./jmeter\n
 6269  sudo ./run.sh logs -f --tail 100 llm_api
 6270  sudo ./run.sh -d -- up --build -d llm_api
 6271  cd subtl_doc_parser
 6272  sudo ./subtl_doc_parser.sh -d -- up --build -d flower
 6273  sudo ./run.sh logs -f --tail 100 llm_api
 6274  cd subtl_doc_parser
 6275  ./subtl_doc_parser.sh stop dumper docparser qabot tranformer
 6276  ./subtl_doc_parser.sh stop dumper docparser qabot transformer
 6277  sudo ./subtl_doc_parser.sh stop dumper docparser qabot transformer
 6278  sudo docker image ls
 6279  sudo docker rmi -f cb57f7169b07
 6280  sudo docker ps
 6281  sudo docker image ls
 6282  sudo docker rmi -f 7e9de258e56e
 6283  sudo ./subtl_doc_parser.sh restart flower
 6284  sudo ./run.sh -d -- up --build -d llm_api
 6285  sudo ./run.sh logs -f --tail 100 llm_api
 6286  sudo ./run.sh -d -- up --build -d llm_worker
 6287  ./jmeter\n
 6288  git clone https://github.com/asprenger/ray_vllm_inference.git
 6289  code .
 6290  htop
 6291  sudo docker system prune -f
 6292  htop
 6293  code .
 6294  git status
 6295  # See https://help.github.com/articles/ignoring-files/ for more about ignoring files.\n\n# dependencies\n/node_modules\n/.pnp\n.pnp.js\n\n# testing\n/coverage\n\n# production\n/build\n\n# misc\n.DS_Store\n.env.local\n.env.development.local\n.env.test.local\n.env.production.local\n\nnpm-debug.log*\nyarn-debug.log*\nyarn-error.log*\n\n.env
 6296  git rm --cached .env\n
 6297  cd backend; git rm --cached .env\n
 6298  git status\n
 6299  git add .
 6300  git commit -m "config changes"
 6301  git push -u origin dev
 6302  cd backend; git rm --cached .env\n
 6303  cd backend; npm start
 6304  cd frontend; npm start
 6305  code .
 6306  pip install factor_analyser
 6307  pip install factor_analyzer
 6308  ./jmeter\n
 6309  code .
 6310  npm start
 6311  ./jmeter\n
 6312  code .
 6313  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 6314  code .
 6315  sudo docker system prune -f
 6316  sudo ./run.sh -d -- up --build -d llm_worker
 6317  sudo docker system prune -f
 6318  sudo docker ps
 6319  sudo ./subtl_doc_parser.sh restart flower
 6320  git status\n
 6321  ./jmeter\n
 6322  code .
 6323  git status\n
 6324  git add .
 6325  git commit -m "added name to celery llm_worker "
 6326  git push -u origin llm_api
 6327  git pull
 6328  git push -u origin llm_api
 6329  code .
 6330  cd frontend; npm start
 6331  cd backend; npm start
 6332  cd frontend;
 6333  npm i react-datepicker
 6334  cd ..
 6335  clear
 6336  git status\n
 6337  git add .
 6338  git commit -m "added cosmetic changes and date filter"
 6339  git push -u origin dev
 6340  code .
 6341  git pull
 6342  cd frontend;npm start
 6343  cd backend; npm start
 6344  htop
 6345  git pull
 6346  git add .
 6347  git commit -m "size=small"
 6348  git pull
 6349  code .
 6350  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 6351  code .
 6352  cd backend; npm start
 6353  cd frontend;npm start
 6354  cd backend; npm start
 6355  htop
 6356  code .
 6357  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 6358  code .
 6359  htop
 6360  cd backend; npm start
 6361  cd frontend;npm start
 6362  git pull
 6363  git add .
 6364  git commit -m "xx"
 6365  git pull
 6366  git log
 6367  git status\n
 6368  git add .
 6369  git commit -m "added focus, slim table"
 6370  git push -u origin main
 6371  code .
 6372  cat ./subtl_llm/app/backends/config.json
 6373  clear
 6374  git status\n
 6375  git rm --cached subtl_llm/app/backends/config.json\n
 6376  git status\n
 6377  cp subtl_llm/app/backends/config.json.example subtl_llm/app/backends/config.json
 6378  clear
 6379  git add .
 6380  git commit -m "hide config.json and added config.json instructions in readme"
 6381  git status\n
 6382  git push -u origin llm_api
 6383  code .
 6384  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 6385  code .
 6386  cd frontend;
 6387  npm run build
 6388  gsutil cp -r build/* gs://nc.outreach.vlabs.ac.in
 6389  cp subtl_llm/app/backends/config.json.example subtl_llm/app/backends/config.json
 6390  code .
 6391  git pull
 6392  git log
 6393  cd backend; npm start
 6394  cd frontend;npm start
 6395  cd frontend;
 6396  npm install -D tailwindcss\nnpx tailwindcss init
 6397  cd frontend;npm start
 6398  code .
 6399  cd ..
 6400  git status\n
 6401  git add .
 6402  git commit -m "added cosmetic changes"
 6403  git push -u origin main
 6404  code .
 6405  cd frontend;npm start
 6406  code .
 6407  npm start
 6408  code .
 6409  npm start
 6410  cd ..
 6411  git status\n
 6412  git add .
 6413  git commit -m "fixed css bug"
 6414  git push -u origin main
 6415  code .
 6416  clear
 6417  npm start
 6418  clear
 6419  npm start
 6420  code .
 6421  clear
 6422  git status\n
 6423  git add .
 6424  git commit -m "added docs"
 6425  git push -u origin dev
 6426  code .
 6427  npm start
 6428  clear
 6429  git status\n
 6430  git add .
 6431  git commit -m "fidex iframe bug"
 6432  git push -u origin main
 6433  code .
 6434  gcloud app browse
 6435  gcloud config set project outreach-default
 6436  gcloud app deploy
 6437  gcloud auth login
 6438  gcloud config set project outreach-default
 6439  gcloud app deploy
 6440  code .
 6441  cd backend; npm start
 6442  cd frontend;npm start
 6443  cd frontend;
 6444  ls
 6445  clear
 6446  npm run build
 6447  npm run build:prod
 6448  gsutil cp -r build/* gs://nc.outreach.vlabs.ac.in
 6449  code .
 6450  sudo ./run.sh logs -f --tail 100 llm_api
 6451  sudo ./run.sh -d -- up --build -d llm_api
 6452  sudo ./run.sh logs -f --tail 100 llm_api
 6453  sudo docker system prune -f
 6454  curl -X POST -H "Content-Type: application/json" -d '{\n    "prompt": "write an essay on environment",\n    "max_new_tokens": 300,\n    "temperature": 0.7,\n    "top_k": 50,\n    "top_p": 0.95,\n    "stream": true\n}' http://35.193.52.196:8000/generate\n
 6455  curl -X POST \\n  http://localhost/llmapi/qa/ \\n  -H 'accept: application/json' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "backend": "vLLM/Mistra lv2AWQ",\n  "prompt_template": "[INST] <<SYS>> You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don'\''t know the answer to a question, please don'\''t share false information.Stick to the information given to you, and  Please avoid generating any additional text. After the answer, output the token %END% <</SYS>> Here is a set of contexts .\n {evidence_string} \n Choose the most relevant contexts and answer based only on them. Discard the contexts which are not relevant. Try to keep your answers as concise, short and accurate as possible. The question is: {question} [/INST]",\n  "question": "string",\n  "evidences": [\n    {\n      "document_name": "string",\n      "context": "string",\n      "metadata": {}\n    }\n  ],\n  "max_new_tokens": 300,\n  "temperature": 0.7,\n  "top_k": 50,\n  "top_p": 0.95,\n  "prune_dangling_sents": true,\n  "stream": true\n}'\n
 6456  curl -X POST \\n  http://localhost/llmapi/qa/ \\n  -H 'accept: application/json' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "backend": "vLLM/Mistra lv2AWQ",\n  "prompt_template": "[INST] <<SYS>> You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don'\''t know the answer to a question, please don'\''t share false information.Stick to the information given to you, and  Please avoid generating any additional text. After the answer, output the token %END% <</SYS>> Here is a set of contexts .\n {evidence_string} \n Choose the most relevant contexts and answer based only on them. Discard the contexts which are not relevant. Try to keep your answers as concise, short and accurate as possible. The question is: {question} [/INST]",\n  "question": "string",\n  "evidences": [\n    {\n      "document_name": "string",\n      "context": "string",\n      "metadata": {}\n    }\n  ],\n  "max_new_tokens": 300,\n  "temperature": 0.7,\n  "top_k": 50,\n  "top_p": 0.95,\n  "prune_dangling_sents": true,\n  "stream": false\n}'
 6457  curl -X POST \\n  http://localhost/llmapi/qa/ \\n  -H 'accept: application/json' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "backend": "vLLM/Mistra lv2AWQ",\n  "prompt_template": "[INST] <<SYS>> You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don'\''t know the answer to a question, please don'\''t share false information.Stick to the information given to you, and  Please avoid generating any additional text. After the answer, output the token %END% <</SYS>> Here is a set of contexts .\n {evidence_string} \n Choose the most relevant contexts and answer based only on them. Discard the contexts which are not relevant. Try to keep your answers as concise, short and accurate as possible. The question is: {question} [/INST]",\n  "question": "string",\n  "evidences": [\n    {\n      "document_name": "string",\n      "context": "string",\n      "metadata": {}\n    }\n  ],\n  "max_new_tokens": 300,\n  "temperature": 0.7,\n  "top_k": 50,\n  "top_p": 0.95,\n  "prune_dangling_sents": true,\n  "stream": true\n}'\n
 6458  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/stream_test"
 6459  clear
 6460  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/stream_test"
 6461  clear
 6462  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/stream_test"
 6463  clear
 6464  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/stream_test"
 6465  curl -X POST \\n  http://localhost/llmapi/qa/ \\n  -H 'accept: application/json' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "backend": "vLLM/Mistra lv2AWQ",\n  "prompt_template": "[INST] <<SYS>> You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don'\''t know the answer to a question, please don'\''t share false information.Stick to the information given to you, and  Please avoid generating any additional text. After the answer, output the token %END% <</SYS>> Here is a set of contexts .\n {evidence_string} \n Choose the most relevant contexts and answer based only on them. Discard the contexts which are not relevant. Try to keep your answers as concise, short and accurate as possible. The question is: {question} [/INST]",\n  "question": "string",\n  "evidences": [\n    {\n      "document_name": "string",\n      "context": "string",\n      "metadata": {}\n    }\n  ],\n  "max_new_tokens": 300,\n  "temperature": 0.7,\n  "top_k": 50,\n  "top_p": 0.95,\n  "prune_dangling_sents": true,\n  "stream": true\n}'\n
 6466  curl -X POST \\n  http://localhost/llmapi/qa/ \\n  -H 'accept: application/json' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "backend": "vLLM/Mistra lv2AWQ",\n  "prompt_template": "[INST] <<SYS>> You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don'\''t know the answer to a question, please don'\''t share false information.Stick to the information given to you, and  Please avoid generating any additional text. After the answer, output the token %END% <</SYS>> Here is a set of contexts .\n {evidence_string} \n Choose the most relevant contexts and answer based only on them. Discard the contexts which are not relevant. Try to keep your answers as concise, short and accurate as possible. The question is: {question} [/INST]",\n  "question": "string",\n  "evidences": [\n    {\n      "document_name": "string",\n      "context": "string",\n      "metadata": {}\n    }\n  ],\n  "max_new_tokens": 300,\n  "temperature": 0.7,\n  "top_k": 50,\n  "top_p": 0.95,\n  "prune_dangling_sents": true,\n  "stream": false\n}'
 6467  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/stream_test"
 6468  curl -X POST \\n  http://localhost/llmapi/qa/ \\n  -H 'accept: application/json' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "backend": "vLLM/Mistra lv2AWQ",\n  "prompt_template": "[INST] <<SYS>> You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don'\''t know the answer to a question, please don'\''t share false information.Stick to the information given to you, and  Please avoid generating any additional text. After the answer, output the token %END% <</SYS>> Here is a set of contexts .\n {evidence_string} \n Choose the most relevant contexts and answer based only on them. Discard the contexts which are not relevant. Try to keep your answers as concise, short and accurate as possible. The question is: {question} [/INST]",\n  "question": "string",\n  "evidences": [\n    {\n      "document_name": "string",\n      "context": "string",\n      "metadata": {}\n    }\n  ],\n  "max_new_tokens": 300,\n  "temperature": 0.7,\n  "top_k": 50,\n  "top_p": 0.95,\n  "prune_dangling_sents": true,\n  "stream": true\n}'
 6469  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/stream_test"
 6470  clear
 6471  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/stream_test"
 6472  curl -X POST \\n  http://localhost/llmapi/map_reduce/ \\n  -H 'accept: application/json' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "backend": "vLLM/Mistra lv2AWQ",\n  "question": "what are the purposes for which lien mark against Term deposit is permitted?",\n  "evidences": [],\n  "map_template": "[PREDICT]\n<<SYS>>\n\nGiven the question and evidence, determine if the evidence is relevant.\n\n- If the evidence is not relevant, respond with:\n    Not Relevant.\n    {{Please avoid generating any additional text}}\n\n- If the evidence is relevant, respond with Relevant + one-line summary of the relevant part in the evidence:\n    Relevant.\n    {{one-line summary of the relevant part in the evidence}}\n\n    \n<</SYS>>\n\nQuestion and Context information are below.\n\n<QUESTION> {question}\n<EVIDENCE> {evidence}\n\n[/PREDICT]\n\n\n\n",\n  "filter_string": "Not Relevant",\n  "reduce_template": "[INST] <<SYS>> You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal ontent. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.Stick to the answer you are giving and  Please avoid generating any additional text. After the answer, output the token %END% <</SYS>>Context information is below.\n {evidence} \n Only answer based on the context above, If you ask a question that is out of context, respond with 'Out of context'. \n {question}[/INST]",\n  "max_new_tokens": 300,\n  "temperature": 0.7,\n  "top_k": 50,\n  "top_p": 0.95,\n  "prune_dangling_sents": true,\n  "stream": false\n}'\n
 6473  curl -X POST \\n  http://localhost/llmapi/map_reduce/ \\n  -H 'accept: application/json' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "backend": "vLLM/Mistralv2AWQ",\n  "question": "what are the purposes for which lien mark against Term deposit is permitted?",\n  "evidences": ["string"],\n  "map_template": "[PREDICT]\n<<SYS>>\n\nGiven the question and evidence, determine if the evidence is relevant.\n\n- If the evidence is not relevant, respond with:\n    Not Relevant.\n    {{Please avoid generating any additional text}}\n\n- If the evidence is relevant, respond with Relevant + one-line summary of the relevant part in the evidence:\n    Relevant.\n    {{one-line summary of the relevant part in the evidence}}\n\n    \n<</SYS>>\n\nQuestion and Context information are below.\n\n<QUESTION> {question}\n<EVIDENCE> {evidence}\n\n[/PREDICT]\n\n\n\n",\n  "filter_string": "Not Relevant",\n  "reduce_template": "[INST] <<SYS>> You are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal ontent. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.Stick to the answer you are giving and  Please avoid generating any additional text. After the answer, output the token %END% <</SYS>>Context information is below.\n {evidence} \n Only answer based on the context above, If you ask a question that is out of context, respond with 'Out of context'. \n {question}[/INST]",\n  "max_new_tokens": 300,\n  "temperature": 0.7,\n  "top_k": 50,\n  "top_p": 0.95,\n  "prune_dangling_sents": true,\n  "stream": false\n}'\n
 6474  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/stream_test_qa"
 6475  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/stream_test_mr"
 6476  sudo ./run.sh logs -f --tail 100 llm_worker
 6477  sudo ./run.sh -d -- up --build -d llm_worker
 6478  sudo docker system prune -f
 6479  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/stream_test_mr"
 6480  git status\n
 6481  git add .
 6482  git commit -m "added streaming to qa and map_reduce pipeline"
 6483  git push -u origin llm_api
 6484  git pull
 6485  sudo docker system prune -f
 6486  htop
 6487  gcloud app browse
 6488  code .
 6489  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_mr.py"
 6490  git status\n
 6491  git add .
 6492  git commit -m "auth*"
 6493  git push -u origin llm_api
 6494  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_mr.py"
 6495  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_qa.py"
 6496  ./jmeter\n
 6497  sudo ./run.sh logs -f --tail 100 llm_api
 6498  curl -X 'POST' \\n  'https://app.subtl.ai/llmapi/prompt/' \\n  -H 'accept: application/json' \\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3MTIzMTA3OTUsInN1YiI6IjEifQ.dVHZo-P7TAAjqmvWpdwfPi6i5-fixRZaQqLXkv6EdAQ' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "backend": "vLLM/Mistralv2AWQ",\n  "prompt": "string",\n  "max_new_tokens": 300,\n  "temperature": 0.7,\n  "top_k": 50,\n  "top_p": 0.95,\n  "prune_dangling_sents": true\n}'
 6499  ./jmeter\n
 6500  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_qa.py"
 6501  curl -X 'POST' \\n  'https://app.subtl.ai/llmapi/prompt/' \\n  -H 'accept: application/json' \\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3MTIzMTA3OTUsInN1YiI6IjEifQ.dVHZo-P7TAAjqmvWpdwfPi6i5-fixRZaQqLXkv6EdAQ' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "backend": "vLLM/Mistralv2AWQ",\n  "prompt": "string",\n  "max_new_tokens": 300,\n  "temperature": 0.7,\n  "top_k": 50,\n  "top_p": 0.95,\n  "prune_dangling_sents": true\n}'
 6502  code .
 6503  clear
 6504  sudo ./run.sh logs -f --tail 100 llm_api
 6505  sudo ./run.sh logs -f --tail 100 llm_worker
 6506  /bin/python
 6507  htop
 6508  sudo ./run.sh -d -- up --build -d llm_worker
 6509  sudo ./run.sh logs -f --tail 100 llm_worker
 6510  docker exec rabbitmq rabbitmqctl stop_app && docker exec rabbitmq rabbitmqctl reset && docker exec rabbitmq rabbitmqctl start_app;
 6511  sudo docker exec rabbitmq rabbitmqctl stop_app && docker exec rabbitmq rabbitmqctl reset && docker exec rabbitmq rabbitmqctl start_app;
 6512  sudo docker ps
 6513  sudo docker exec subtl_doc_parser-queue-1 rabbitmqctl stop_app
 6514  sudo docker exec subtl_doc_parser-queue-1 rabbitmqctl reset
 6515  sudo docker exec subtl_doc_parser-queue-1 rabbitmqctl start_app
 6516  sudo ./run.sh -d -- up --build -d llm_worker
 6517  sudo ./run.sh logs -f --tail 100 llm_worker
 6518  ./jmeter\n
 6519  sudo ./run.sh -d -- up --build -d llm_api
 6520  sudo docker system prune -f
 6521  sudo ./run.sh -d -- up --build -d llm_api
 6522  sudo docker system prune -f
 6523  code .
 6524  clear
 6525  sudo ./run.sh logs -f --tail 100 llm_api
 6526  clear
 6527  sudo ./run.sh logs -f --tail 100 llm_worker
 6528  sudo docker ps
 6529  sudo docker exec subtl_doc_parser-queue-1 rabbitmqctl stop_app
 6530  sudo docker exec subtl_doc_parser-queue-1 rabbitmqctl reset
 6531  sudo docker exec subtl_doc_parser-queue-1 rabbitmqctl start_app
 6532  clear
 6533  sudo ./run.sh logs -f --tail 100 llm_worker
 6534  sudo ./run.sh -d -- up --build -d llm_worker
 6535  htop
 6536  sudo ./run.sh logs -f --tail 100 llm_worker
 6537  sudo docker exec subtl_doc_parser-queue-1 rabbitmqctl stop_app
 6538  sudo docker exec subtl_doc_parser-queue-1 rabbitmqctl reset
 6539  sudo docker exec subtl_doc_parser-queue-1 rabbitmqctl start_app
 6540  sudo ./run.sh logs -f --tail 100 llm_worker
 6541  sudo ./run.sh -d -- up --build -d llm_worker llm_api
 6542  sudo docker exec subtl_doc_parser-queue-1 rabbitmqctl stop_app
 6543  sudo docker exec subtl_doc_parser-queue-1 rabbitmqctl reset
 6544  sudo docker exec subtl_doc_parser-queue-1 rabbitmqctl start_app
 6545  sudo ./run.sh logs -f --tail 100 llm_worker
 6546  sudo ./run.sh -d -- up --build -d  llm_api
 6547  sudo docker system prune
 6548  git clone https://github.com/virtual-labs/svc-bug-report.git
 6549  code .
 6550  git checkout backend
 6551  git add .
 6552  git commit -m "added base and exp url in data obj"
 6553  git checkout backend
 6554  git checkout main
 6555  git status\n
 6556  touch LICENSE
 6557  code .
 6558  git add .
 6559  git commit -m "added LICENSE"
 6560  git push -u origin dev
 6561  code .
 6562  git checkout main
 6563  git branch new_branch\ngit checkout new_branch\n
 6564  git checkout main
 6565  git checkout dev
 6566  git status\n
 6567  git checkout dev
 6568  git checkout main
 6569  git status\n
 6570  git clone https://github.com/virtual-labs/app-lab-deployment-web.git
 6571  code .
 6572  git checkout dev
 6573  git checkout main
 6574  git branch new_branch\ngit checkout new_branch
 6575  git merge dev --allow-unrelated-histories\n
 6576  git push -u origin new_branch
 6577  code .
 6578  git status\n
 6579  git add .
 6580  git commit -m "added yaml file"
 6581  git checkout main
 6582  git checkout dev
 6583  git status\n
 6584  git push -u origin dev
 6585  git clone https://github.com/virtual-labs/app-outreach-tracker-web.git
 6586  code .
 6587  git branch new_branch\ngit checkout new_branch
 6588  git merge dev --allow-unrelated-histories\n
 6589  git checkout dev
 6590  git checkout new_branch
 6591  git merge dev --allow-unrelated-histories\n
 6592  git checkout backend
 6593  git origin\n
 6594  git remote
 6595  git remote -v
 6596  git status\n
 6597  git add .
 6598  git commit -m "added experiment_link in json payload"
 6599  git push -u origin main
 6600  code .
 6601  git checkout backend
 6602  git checkout main
 6603  git checkout backend
 6604  git checkout main
 6605  htop
 6606  code .
 6607  htop
 6608  sudo ./run.sh logs -f --tail 100 llm_ap
 6609  sudo ./run.sh logs -f --tail 100 llm_api
 6610  sudo ./run.sh logs -f --tail 100 llm_worker
 6611  cd bin; ./jmeter
 6612  cd subtl_doc_parser
 6613  sudo ./subtl_doc_parser.sh restart flower
 6614  sudo ./run.sh -d -- up --build -d  llm_worker
 6615  htop
 6616  sudo docker system prune
 6617  code .
 6618  git pull
 6619  git checkout dev
 6620  code .
 6621  cd frontend;npm start
 6622  cd frontend;npm i; npm start
 6623  npm i
 6624  npm i -f
 6625  npm start
 6626  cd backend; npm i; npm start
 6627  npm start
 6628  code .
 6629  git checkout dev
 6630  git pull
 6631  cd frontend;
 6632  npm i zustand
 6633  npm uninstall jsoneditor-react jsoneditor ajv
 6634  npm uninstall react-json-editor-ajrm
 6635  npm i zustand
 6636  code .
 6637  sudo ./run.sh logs -f --tail 100 llm_api
 6638  cd subtl_llm/app\n\n\n\n\n\n
 6639  ls
 6640  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_qa.py"
 6641  git pull
 6642  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/pipelines/map_reduce.py"
 6643  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_mr.py"
 6644  htop
 6645  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_mr.py"
 6646  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_qa.py"
 6647  sudo ./run.sh logs -f --tail 100 llm_api
 6648  cd ../..
 6649  sudo ./run.sh logs -f --tail 100 llm_api
 6650  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_qa.py"
 6651  sudo ./run.sh -d -- up --build -d  llm_worker
 6652  sudo ./run.sh logs -f --tail 100 llm_worker
 6653  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_mr.py"
 6654  /bin/python
 6655  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_mr.py"
 6656  sudo ./run.sh -d -- up --build -d  llm_worker
 6657  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_mr.py"
 6658  clear
 6659  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_mr.py"
 6660  clear
 6661  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_mr.py"
 6662  git status\n
 6663  git add .
 6664  git commit -m "added celery priority to tasks, intermediary results to map-red streaming"
 6665  git pull
 6666  git status\n
 6667  git add .
 6668  git commit -m "fixed import bug"
 6669  git push -u origin llm_api
 6670  code .
 6671  git pull
 6672  cd backend; npm start
 6673  cd frontend; npm start
 6674  git pull
 6675  git status\n
 6676  git add .
 6677  git commit -m "changed colors"
 6678  git pull
 6679  git push -u origin main
 6680  git pull
 6681  git push -u origin main
 6682  ./jmeter\n
 6683  code .
 6684  sudo ./run.sh logs -f --tail 100 llm_api
 6685  htop
 6686  code .
 6687  git pull
 6688  cd backend; npm start
 6689  cd frontend; npm start
 6690  git log
 6691  git status\n
 6692  git add .
 6693  git commit -m "added consmetic changes"
 6694  git push -u origin main
 6695  code .
 6696  clear
 6697  nodeks
 6698  nodejs
 6699  cd backend_flask
 6700  python -m venv venv\n
 6701  source venv/bin/activate
 6702  touch server.py
 6703  pip install Authlib Flask requests\n
 6704  python server.py
 6705  pip install dotenv
 6706  python server.py
 6707  pip install python-dotenv\n
 6708  python server.py
 6709  npm start
 6710  pip install flask flask-cors\n\n
 6711  python server.py
 6712  git status\n
 6713  sudo docker ps
 6714  cat .env
 6715  code .env
 6716  ./jmeter\n
 6717  pwd
 6718  ./jmeter\n
 6719  code .
 6720  tree
 6721  ls
 6722  cd src
 6723  cf pr
 6724  cf Protected.js
 6725  cd ..
 6726  cd prompts
 6727  tree
 6728  clear
 6729  python server.py
 6730  ls
 6731  clear
 6732  source venv/bin/activate
 6733  python server.py
 6734  source venv/bin/activate
 6735  pip install authlib
 6736  python server.py
 6737  clear
 6738  npm start
 6739  cd frontend; 
 6740  react-arborist
 6741  npm i react-arborist
 6742  npm i react-icons
 6743  htop
 6744  python server.py
 6745  code .
 6746  git init
 6747  git commit -m "first commit"\ngit branch -M main\ngit remote add origin https://github.com/chir263/prompt-repo.git\ngit push -u origin main\n
 6748  git add .
 6749  git commit -m "first commit"\ngit branch -M main\ngit remote add origin https://github.com/chir263/prompt-repo.git\ngit push -u origin main\n
 6750  git clone https://github.com/royari/gfs-python.git
 6751  code .
 6752  htop
 6753  clear
 6754  npm start
 6755  clear
 6756  npm start
 6757  source venv/bin/activate
 6758  python server.py
 6759  code .
 6760  sudo ./run.sh logs -f --tail 100 llm_api
 6761  htop
 6762  code .
 6763  python -m venv venv\n
 6764  source venv/bin/activate
 6765  pip install -r requirements.txt
 6766  python master_server.py
 6767  python3 -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. ./gfs.proto
 6768  python master_server.py
 6769  source venv/bin/activate
 6770  python client.py
 6771  python chunk_server.py
 6772  source venv/bin/activate
 6773  pip freeze
 6774  clear
 6775  python client.py create /file2
 6776  python client.py append /file2 hellothere
 6777  source venv/bin/activate
 6778  python chunk_server.py
 6779  python chunk_server.py 10293
 6780  python chunk_server.py 50052
 6781  clear
 6782  python chunk_server.py 50053
 6783  source venv/bin/activate
 6784  python chunk_server.py 50054
 6785  source venv/bin/activate
 6786  python chunk_server.py 50055
 6787  python chunk_server.py 50056
 6788  python chunk_server.py 50057
 6789  source venv/bin/activate
 6790  python chunk_server.py 50057
 6791  source venv/bin/activate
 6792  python chunk_server.py 50056
 6793  clear
 6794  python master_server.py
 6795  python client.py create /file2
 6796  python client.py append /file2 hellothere
 6797  clear
 6798  python master_server.py
 6799  python client.py append /file2 hellothere
 6800  clear
 6801  python chunk_server.py 50052
 6802  clear
 6803  python chunk_server.py 50053
 6804  clear
 6805  python chunk_server.py 50054
 6806  clear
 6807  python chunk_server.py 50055
 6808  clear
 6809  python client.py create /file2
 6810  clear
 6811  python client.py create /file2
 6812  python master_server.py
 6813  python client.py create /file2
 6814  python chunk_server.py 50056
 6815  clear
 6816  python chunk_server.py 50057
 6817  python client.py create /file2
 6818  clear
 6819  python master_server.py
 6820  python client.py create /file2
 6821  python client.py create /file1
 6822  python chunk_server.py 50052
 6823  python client.py create /file1
 6824  python client.py create /file11
 6825  python client.py create /file111
 6826  ./jmeter\n
 6827  code .
 6828  hadoop
 6829  hadoop --version
 6830  ./yarn-env.sh
 6831  start-all.sh\n
 6832  ssh localhost \nssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa \ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys \nchmod 0600 ~/.ssh/authorized_keys \nhadoop-3.2.3/bin/hdfs namenode -format
 6833  export PDSH_RCMD_TYPE=ssh\n
 6834  start-all.sh\n
 6835  code .
 6836  start-all.sh
 6837  ssh localhost \nssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa \ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys \nchmod 0600 ~/.ssh/authorized_keys \n
 6838  hadoop-3.3.6/bin/hdfs namenode -format\n
 6839  start-all.sh
 6840  python grade.py 1
 6841  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar "/media/chirag/DATA3/CODE_AMA/distributed-systems/assign_2/grading_script/tests/q3/9/" "1"in "1"out
 6842  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar "/media/chirag/DATA3/CODE_AMA/distributed-systems/assign_2/grading_script/tests/q3/9/" "1"in "1"out 
 6843  ./runner-script -h
 6844  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar "/media/chirag/DATA3/CODE_AMA/distributed-systems/assign_2/grading_script/tests/q3/9/" "1"in "1"out /
 6845  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar "/media/chirag/DATA3/CODE_AMA/distributed-systems/assign_2/grading_script/tests/q3/9/" 1/in 1/out /
 6846  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar "/media/chirag/DATA3/CODE_AMA/distributed-systems/assign_2/grading_script/tests/q3/9/" in/ out/ /
 6847  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar "/media/chirag/DATA3/CODE_AMA/distributed-systems/assign_2/grading_script/tests/q3/9/" / / /
 6848  hadoop fs -rm -r /*
 6849  hadoop fs ls
 6850  hdfs dfs -ls
 6851  hdfs dfs -ls /
 6852  hadoop fs -rm -r /1.in
 6853  hadoop fs -rm -r /{2..10}.in
 6854  hdfs dfs -ls /
 6855  hadoop fs -rm -r /{11..13}.in
 6856  hadoop fs -rm -r /0.in
 6857  hadoop fs mkdir /input
 6858  hadoop fs -mkdir /input
 6859  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar "/media/chirag/DATA3/CODE_AMA/distributed-systems/assign_2/grading_script/tests/q3/9/" /input /out /
 6860  hadoop fs -rm -r input/{0..13}.in
 6861  hadoop fs -rm -r /input/{0..13}.in
 6862  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar "/media/chirag/DATA3/CODE_AMA/distributed-systems/assign_2/grading_script/tests/q3/9/" /input /out ./
 6863  code .
 6864  API_KEY="AIzaSyCX-iABDno4XqHaHSfg42_dhicORB2u700"\ncurl -H 'Content-Type: application/json' \\n     -d '{"contents":[\n            {"role": "user",\n              "parts":[{"text": "Give me five subcategories of jazz?"}]}]}' \\n     "https://generativelanguage.googleapis.com/v1/models/gemini-pro:generateContent?key=${API_KEY}"
 6865  cd backend; 
 6866  source venv/bin/activate
 6867  python server.py
 6868  pip install -q -U google-generativeai\n
 6869  cd backend; 
 6870  source venv/bin/activate
 6871  pip install -q -U google-generativeai\n
 6872  pip freeze
 6873  source venv/bin/activate
 6874  pip freeze
 6875  pip install google-generativeai==0.3.1
 6876  pip install google-generativeai==0.3.10
 6877  python server.py
 6878  python --version
 6879  source venv/bin/activate
 6880  pip freeze > requirements.txt\n
 6881  deactivate
 6882  python3.10 -m venv venv\n
 6883  code .
 6884  python3.9 -m venv venv\n
 6885  sudo apt-get install python3.9
 6886  python --version
 6887  python3.9 -m venv venv\n
 6888  sudo apt install python3.9-venv
 6889  python3.9 -m venv venv\n
 6890  source venv/bin/activate
 6891  pip freeze
 6892  python server.py
 6893  pip install google-generativeai flask flask_cors
 6894  python server.py
 6895  pip install authlib
 6896  python server.py
 6897  pip install dotenv
 6898  pip install "dotenv==0.19.1"\n
 6899  pip install --upgrade pip\n
 6900  pip install dotenv
 6901  python server.py
 6902  pip install "dotenv==0.19.1"\n
 6903  pip install "dotenv==0.0.3"\n
 6904  pip install "dotenv==0.0.4"\n
 6905  pip install --upgrade pip\n
 6906  pip install "dotenv==0.0.3"\n
 6907  pip install "dotenv==0.0.2"\n
 6908  sudo pip install "dotenv==0.0.2"\n
 6909  pip install "dotenv==0.0.2"\n
 6910  pip install python-dotenv\n
 6911  python server.py
 6912  pip install grpcio\n
 6913  python server.py
 6914  pip freeze > requirements.txt\n
 6915  pip install protobuf==4.25.3
 6916  pip freeze > requirements.txt\n
 6917  python server.py
 6918  cd frontend; npm start
 6919  curl -X POST \\n  -H "Content-Type: application/json" \\n  -d '{"message": "hi"}' \\n  "https://localhost:5000/api/prompt/generate?access_token=gho_EN2SlWB5OMaCALd8Y5hM3UmyOB2MHz"\n
 6920  print(response.history)
 6921  python server.py
 6922  htop
 6923  cd frontend; npm i @uiw/react-md-editor\n
 6924  code .
 6925  htop
 6926  npx create-react-app ner-app
 6927  cd ner-app
 6928  ls
 6929  npm start
 6930  npm install uuid\n
 6931  npm i react-color-picker
 6932  cd ner-app
 6933  npm i react-color-picker
 6934  npm i primereact
 6935  ls
 6936  git remote -v
 6937  git remote add origin https://github.com/Mitanshk01/ner-Annotatrix.git
 6938  git pull
 6939  git status\n
 6940  git pull
 6941  git checkout main
 6942  git add .
 6943  git commit -m "built initial prototype"
 6944  git push -u origin master
 6945  clear
 6946  git status\n
 6947  git add .
 6948  git commit -m "fixed line bug"
 6949  git push -u origin master
 6950  code .
 6951  python grade.py 1
 6952  history 
 6953  hadoop fs -rm -r -f /in
 6954  hadoop fs -rm -r -f /input/
 6955  hadoop fs -rm -r -f /out
 6956  python grade.py 1
 6957  code .
 6958  git checkout agent_test
 6959  git status\n
 6960  sudo ./run.sh logs -f --tail 100 llm_api
 6961  sudo ./run.sh -d -- up --build -d  llm_worker llm_api nginx
 6962  sudo ./run.sh -d -- up --build -d  nginx
 6963  netstat -tulpn | grep :80
 6964  ss -tulpn | grep :80\n
 6965  lsof -i :8000
 6966  lsof -i :80
 6967  sudo lsof -i :80\n
 6968  sudo systemctl stop apache2
 6969  sudo ./run.sh -d -- up --build -d  nginx
 6970  git s
 6971  git status\n
 6972  git add .
 6973  git commit -m "fixed pruning bug"
 6974  git push -u origin llm_api
 6975  git pull
 6976  git checkout agent_test
 6977  sudo ./run.sh logs -f --tail 100 llm_api
 6978  git checkout llm_api
 6979  htop
 6980  python -u "/media/chirag/DATA3/subtl.ai/subtl_bot/subtl_llm/app/benchmark_cli/agent_test_script.py"
 6981  cd subtl_llm/app\n\n\n\n\n\n
 6982  cd benchmark_cli
 6983  ls
 6984  python  agent_test_script.py
 6985  git status\n
 6986  git add .
 6987  git commit -m "modified agent prompt"
 6988  git push -u origin agent_test
 6989  git add .
 6990  git commit -m "agent auth fix"
 6991  git push -u origin agent_test
 6992  htop
 6993  code .
 6994  python grade.py 1
 6995  htop
 6996  ssh localhost \nssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa \ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys \nchmod 0600 ~/.ssh/authorized_keys 
 6997  hadoop-3.3.6/bin/hdfs namenode -format\n
 6998  start-all.sh
 6999  export PDSH_RCMD_TYPE=ssh\n
 7000  python grade.py 1
 7001  htop
 7002  python grade.py 1
 7003  htop
 7004  python grade.py 1
 7005  htop
 7006  ssh localhost \nssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa \ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys \nchmod 0600 ~/.ssh/authorized_keys 
 7007  hadoop-3.3.6/bin/hdfs namenode -format\n
 7008  start-all.sh
 7009  clear
 7010  start-all.sh
 7011  clear
 7012  python grade.py 1
 7013  ssh localhost \nssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa \ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys \nchmod 0600 ~/.ssh/authorized_keys 
 7014  hadoop-3.3.6/bin/hdfs namenode -format\n
 7015  start-all.sh
 7016  du
 7017  df
 7018  clear
 7019  cat 14.out -h 100
 7020  cat 14.out > head 100
 7021  ;s
 7022  ls
 7023  cat 1.out
 7024  cat 2.out
 7025  cat 4.out
 7026  cat 14.out
 7027  python grade.py 1
 7028  htop
 7029  code .
 7030  python3.9
 7031  code .
 7032  cd frontend; npm start
 7033  cd backend; npm start
 7034  python server.py
 7035  python3.9 server.py
 7036  source venv/bin/activate
 7037  python server.py
 7038  python3.9 server.py
 7039  source venv/bin/activate
 7040  python3.9 server.py
 7041  python3 server.py
 7042  python server.py
 7043  pip freeze
 7044  source venv/bin/activate
 7045  pip install -r requirements.txt
 7046  pip3 install -r requirements.txt
 7047  pip3.9 install -r requirements.txt
 7048  source venv/bin/activate
 7049  pip3.9 install -r requirements.txt
 7050  pip39 install -r requirements.txt
 7051  pip3 install -r requirements.txt
 7052  pip freeze
 7053  python --version
 7054  deactivate
 7055  python3.9 -m venv venv\n
 7056  pip3 install -r requirements.txt
 7057  source venv/bin/activate
 7058  pip --version\n
 7059  curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\npython3.9 get-pip.py
 7060  pip --version\n
 7061  pip install -r requirements.txt
 7062  python server.py
 7063  git status\n
 7064  git add .
 7065  git commit -m "added generation api"
 7066  git push -u origin main
 7067  code .
 7068  git pull
 7069  git checkout dev
 7070  git pull
 7071  clear
 7072  sudo ./run.sh -d -- up --build -d  api
 7073  sudo systemctl stop apache2
 7074  sudo ./run.sh -d -- up --build -d  llm_worker llm_api nginx
 7075  sudo ./run.sh -d -- up --build api
 7076  sudo service mongod stop
 7077  sudo ./run.sh -d -- up --build api
 7078  sudo lsof -i :6379
 7079  sudo ./run.sh -d -- up -d api
 7080  sudo ./run.sh -d -- up api
 7081  docker ps
 7082  sudo docker ps
 7083  sudo ./run.sh -d -- up api
 7084  sudo ./run.sh logs -f --tail 100 api
 7085  sudo ./run.sh -d -- up api
 7086  htop
 7087  df
 7088  docker system prune f
 7089  docker system prune -f
 7090  sudo docker system prune -f
 7091  sudo ./run.sh -d -- up api
 7092  git status\n
 7093  git checkout subtl-api-temp
 7094  git pull
 7095  git checkout dev
 7096  docker ps
 7097  sudo docker ps
 7098  sudo ./run.sh -d -- up api
 7099  sudo docker ps
 7100  sudo docker stop subtl_doc_parser-redis-queue-1
 7101  sudo docker ps
 7102  sudo ./run.sh logs -f --tail 100 llm_api
 7103  git checkout llm_api
 7104  sudo ./run.sh logs -f --tail 100 llm_api
 7105  git checkout dev
 7106  sudo ./run.sh logs -f --tail 100 llm_api
 7107  sudo ./run.sh -d -- up api
 7108  sudo docker ps
 7109  sudo ./run.sh logs -f --tail 100 llm_api
 7110  sudo ./run.sh logs -f --tail 100 llm_worker
 7111  sudo ./run.sh -d -- up llm_api llm_worker
 7112  sudo ./run.sh -d -- up --build -d  llm_worker llm_api
 7113  sudo ./run.sh logs -f --tail 100 llm_worker
 7114  sudo ./run.sh logs -f --tail 100 llm_api
 7115  sudo docker ps
 7116  sudo lsof -i :6379
 7117  sudo ./run.sh -d -- up --build -d  api
 7118  sudo docker ps
 7119  cd subtl_doc_parser
 7120  sudo ./subtl_doc_parser.sh -d -- up --build -d redis-queue
 7121  sudo ./run.sh -d -- up --build -d  llm_worker llm_api
 7122  sudo ./run.sh -d restart  llm_worker llm_api
 7123  sudo ./run.sh logs -f --tail 100 llm_api
 7124  sudo ./run.sh logs -f --tail 100 llm_worker
 7125  docker ps
 7126  sudo docker ps
 7127  sudo ./run.sh -d -- up --build -d  api
 7128  cd ..
 7129  sudo ./run.sh -d -- up --build -d  api
 7130  sudo ./run.sh restart llm_api llm_worker
 7131  sudo ./run.sh logs -f --tail 100 llm_api
 7132  sudo ./run.sh logs -f --tail 100 llm_worker
 7133  sudo ./run.sh -d -- up api
 7134  sudo ./run.sh -- up --build -d  api
 7135  sudo docker ps
 7136  sudo ./run.sh logs -f --tail 100 api
 7137  sudo ./run.sh logs -f --tail 100 redis
 7138  sudo ./run.sh -- up --build -d  api
 7139  sudo ./run.sh logs -f --tail 100 redis
 7140  sudo ./run.sh logs -f --tail 100 mongo
 7141  sudo ./run.sh logs -f --tail 100 api
 7142  sudo docker ps
 7143  sudo ./run.sh restart api
 7144  sudo ./run.sh logs -f --tail 100 api
 7145  sudo docker ps
 7146  sudo ./run.sh logs -f --tail 100 api
 7147  sudo ./run.sh restart api
 7148  sudo ./run.sh logs -f --tail 100 api
 7149  sudo ./run.sh restart api
 7150  sudo ./run.sh logs -f --tail 100 api
 7151  sudo ./run.sh -- up --build -d  api
 7152  sudo ./run.sh logs -f --tail 100 api
 7153  sudo ./run.sh -- up --build -d  api
 7154  sudo ./run.sh logs -f --tail 100 api
 7155  sudo ./run.sh -- up --build -d  api
 7156  sudo ./run.sh logs -f --tail 100 api
 7157  sudo ./run.sh -- up --build -d  api
 7158  sudo ./run.sh logs -f --tail 100 api
 7159  python 
 7160  sudo ./run.sh -- up --build -d  api
 7161  sudo ./run.sh logs -f --tail 100 api
 7162  sudo ./run.sh -- up --build -d  meili
 7163  sudo ./run.sh logs -f --tail 100 meili
 7164  sudo ./run.sh logs -f --tail 100 api
 7165  sudo ./run.sh restart api
 7166  sudo ./run.sh logs -f --tail 100 api
 7167  sudo ./run.sh restart api
 7168  sudo ./run.sh logs -f --tail 100 api
 7169  sudo ./run.sh restart api
 7170  sudo ./run.sh logs -f --tail 100 api
 7171  clear
 7172  sudo ./run.sh restart api
 7173  clear
 7174  sudo ./run.sh logs -f --tail 100 api
 7175  sudo ./run.sh -- up --build -d  api
 7176  clear
 7177  sudo ./run.sh logs -f --tail 100 api
 7178  sudo ./run.sh logs -f --tail 1000 api > x.logs
 7179  sudo ./run.sh -- up --build -d  api
 7180  sudo ./run.sh logs -f --tail 100 api
 7181  sudo ./run.sh -- up --build -d  api
 7182  sudo ./run.sh logs -f --tail 1000 api
 7183  sudo ./run.sh -- up --build -d  api
 7184  sudo ./run.sh logs -f --tail 1000 api
 7185  clear
 7186  sudo ./run.sh logs -f --tail 1000 api
 7187  clear
 7188  sudo ./run.sh -- up --build -d  api
 7189  clear
 7190  sudo ./run.sh logs -f --tail 1000 api
 7191  sudo ./run.sh logs -f --tail 1000 api > x.logs
 7192  sudo ./run.sh logs  api > x.logs
 7193  sudo docker ps
 7194  sudo docker stop subtl_doc_parser-redis-queue-1
 7195  sudo ./run.sh -d -- up --build -d  api
 7196  sudo ./run.sh logs --tail 100  api 
 7197  sudo ./run.sh -d -- up --build -d  api
 7198  sudo ./run.sh logs --tail 100  api 
 7199  sudo ./run.sh logs --tail 100 -f api 
 7200  sudo ./run.sh -d -- up --build -d  api
 7201  sudo ./run.sh logs --tail 100 -f api 
 7202  git status\n
 7203  sudo ./run.sh -d -- up --build -d  api
 7204  sudo ./run.sh logs --tail 100 -f api 
 7205  sudo ./run.sh -d -- up --build -d  api
 7206  sudo ./run.sh logs --tail 100 -f api 
 7207  sudo ./run.sh logs --tail 300 -f api 
 7208  sudo docker ps
 7209  sudo ./run.sh logs --tail 300 -f mongo
 7210  sudo ./run.sh logs --tail 300 -f api 
 7211  sudo ./run.sh logs --tail 300 -f redis
 7212  sudo ./run.sh -d -- up --build -d --force-recreate --no-deps  api
 7213  sudo ./run.sh -- up --build -d --force-recreate --no-deps  api
 7214  sudo ./run.sh logs --tail 300 -f api 
 7215  cp ~/.ssh/gcloud.pem gcloud.pem
 7216  ssh -i gcloud.pem subtlbot@35.225.237.229
 7217  code .
 7218  sudo docker ps
 7219  code .
 7220  cd backend; npm start
 7221  python -m venv venv\n
 7222  pip install -r requirements.txt
 7223  npm i
 7224  rm -rf venv
 7225  npm start
 7226  cd frontend; npm start
 7227  npm i; npm start
 7228  cp .env x.env
 7229  npm start
 7230  cp .env x.env
 7231  code .
 7232  cd frontend; npm i; npm start
 7233  cd backend; npm i; npm start
 7234  cd frontend; npm i -f; npm start
 7235  code .
 7236  cd backend; 
 7237  source venv/bin/activate
 7238  python server.py
 7239  cd frontend; npm start
 7240  code .
 7241  sudo docker prune -f
 7242  sudo docker system prune -f
 7243  git clone https://github.com/dixitgarg059/Google-File-System.git
 7244  code .
 7245  python -m venv venv\n
 7246  source venv/bin/activate
 7247  cd master
 7248  ls
 7249  python primary.py
 7250  cd client
 7251  cd chunkserver
 7252  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 7253  python communcation.py 6500
 7254  python communcation.py 6501
 7255  source venv/bin/activate
 7256  cd chunkserver
 7257  python communcation.py 6501
 7258  python communcation.py 6502
 7259  cd chunkserver
 7260  python communcation.py 6502
 7261  clear
 7262  ls
 7263  python client.py
 7264  touch x.txt
 7265  python client.py
 7266  python grade.py 1
 7267  htop
 7268  cd tree
 7269  tree
 7270  deactivate
 7271  tree
 7272  htop
 7273  python grade.py 1
 7274  htop
 7275  ls
 7276  sudo docker compose up --build -d master_server
 7277  sudo docker compose up --build -d secondary_server
 7278  sudo docker compose up logs --tail 100 -f master_server
 7279  sudo docker compose up log --tail 100 -f master_server
 7280  sudo docker compose up logs  -f master_server
 7281  sudo docker compose logs --tail 100 -f master_server
 7282  sudo docker compose logs --tail 100 master_server
 7283  lsof -i :8080
 7284  sudo docker compose up --build -d secondary_server master_server
 7285  sudo docker ps
 7286  lsof -i :8081
 7287  sudo docker compose logs --tail 100 master_server
 7288  sudo docker compose logs --tail 100 secondary_serve
 7289  sudo docker compose logs --tail 100 secondary_server
 7290  sudo docker compose logs --tail 100 master_server
 7291  sudo docker exec google-file-system-secondary_server bash
 7292  sudo docker exec -it google-file-system-secondary_server bash
 7293  sudo docker exec -it google-file-system-secondary_server-1 bash
 7294  sudo docker exec -it google-file-system-master_server-1 bash
 7295  lsof -i :8081
 7296  sudo docker system prune -f
 7297  lsof -i 
 7298  sudo docker compose up --build -d secondary_server master_server
 7299  sudo docker network create traefik-public
 7300  sudo docker compose up --build -d secondary_server master_server
 7301  lsof -i :8081
 7302  sudo docker exec -it google-file-system-secondary_server-1 bash
 7303  sudo docker compose logs --tail 100 master_server
 7304  sudo docker compose logs --tail 100 secondary_server
 7305  sudo docker compose up --build -d master_server secondary_server
 7306  sudo docker compose logs --tail 100 secondary_server
 7307  sudo docker compose logs --tail 100 master_server
 7308  cd master
 7309  python primary.py
 7310  sudo kill -9 $(sudo lsof -t -i:8080)\n
 7311  sudo kill -9 $(sudo lsof -t -i:8081)\n
 7312  python primary.py
 7313  sudo docker compose restart master_server secondary_server
 7314  sudo docker compose logs --tail 100 master_server
 7315  sudo docker compose logs --tail 100 secondary_server
 7316  sudo docker ps
 7317  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/
 7318  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ /input /output
 7319  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ /in /out
 7320  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input /in /out
 7321  hadoop fs -rm -r -f /in
 7322  hadoop fs -rm -r -f /out
 7323  hadoop fs -ls
 7324  hadoop fs -ls /
 7325  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input /in /out
 7326  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input /in /out ./
 7327  python grade.py 1
 7328  lsof -i :8081
 7329  python primary.py
 7330  cd chunkserver
 7331  python communcation.py 6502
 7332  cd ..
 7333  sudo docker compose up --build -d master_server secondary_server
 7334  python communcation.py 6502
 7335  sudo docker compose logs --tail 100 secondary_server
 7336  sudo docker compose logs --tail 100 master_server
 7337  sudo docker compose logs --tail 100 -f master_server
 7338  cd client
 7339  python client.py
 7340  sudo docker compose up --build -d master_server secondary_server
 7341  python communcation.py 6502
 7342  sudo docker compose logs --tail 100 -f master_server
 7343  python client.py
 7344  sudo docker compose logs --tail 100 -f master_server
 7345  sudo docker compose up --build -d master_server secondary_server
 7346  sudo docker compose logs --tail 100 -f master_server
 7347  python communcation.py 6502
 7348  sudo docker compose logs --tail 100 -f master_server
 7349  sudo docker compose up --build -d master_server secondary_server
 7350  sudo docker ps
 7351  sudo docker compose logs --tail 100 -f master_server
 7352  python communcation.py 6502
 7353  python client.py
 7354  python communcation.py 6502
 7355  python client.py
 7356  python communcation.py 6502
 7357  python client.py
 7358  python communcation.py 6502
 7359  python client.py
 7360  sudo docker compose up --build -d master_server secondary_server
 7361  sudo docker compose logs --tail 100 -f master_server
 7362  sudo docker compose logs --tail 1000 -f master_server
 7363  python communcation.py 6502
 7364  sudo docker ps
 7365  sudo docker stop google-file-system-secondary_server-1
 7366  sudo docker stop google-file-system-master_server-1
 7367  cd master
 7368  python primary.py
 7369  python communcation.py 6502
 7370  python primary.py
 7371  python client.py
 7372  python communcation.py 6502
 7373  sudo docker compose up --build -d master_server secondary_server
 7374  sudo docker compose logs --tail 1000 -f master_server
 7375  python communcation.py 6502
 7376  sudo docker restart master_server
 7377  sudo docker ps
 7378  sudo docker restart google-file-system-master_server-1
 7379  sudo docker compose logs --tail 1000 -f master_server
 7380  sudo docker compose restart master_server
 7381  sudo docker compose logs --tail 1000 -f master_server
 7382  sudo docker compose up --build -d master_server secondary_server
 7383  sudo docker compose logs --tail 1000 -f master_server
 7384  python communcation.py 6502
 7385  python communcation.py 6501
 7386  python client.py
 7387  sudo docker compose stop master_server
 7388  sudo docker compose stop secondary_server
 7389  python primary.py
 7390  python communcation.py 6501
 7391  python client.py
 7392  sudo docker compose up --build -d master_server secondary_server
 7393  cd ..
 7394  sudo docker compose up --build -d master_server secondary_server
 7395  sudo docker compose logs --tail 1000 -f master_server
 7396  python communcation.py 6501
 7397  python client.py
 7398  sudo docker compose logs --tail 1000 -f master_server
 7399  sudo docker compose up --build -d master_server secondary_server
 7400  sudo docker compose logs --tail 1000 -f master_server
 7401  python communcation.py 6501
 7402  python client.py
 7403  sudo docker compose up --build -d master_server secondary_server
 7404  sudo docker compose logs --tail 1000 -f master_server
 7405  python communcation.py 6501
 7406  python client.py
 7407  sudo docker compose logs --tail 1000 -f master_server
 7408  sudo docker compose up --build -d master_server secondary_server
 7409  sudo docker compose logs --tail 1000 -f master_server
 7410  PORT=6051 docker-compose up --build chunk_server\n
 7411  PORT=6051 docker compose up --build chunk_server\n
 7412  PORT=6051 sudo docker compose up --build chunk_server\n
 7413  PORT=6051 docker compose up --build -d chunk_server\n
 7414  PORT=6051 sudo docker compose up --build -d chunk_server\n
 7415  sudo docker compose logs --tail 1000 -f chunk_server
 7416  PORT=6051 sudo docker compose up --build chunk_server\n
 7417  PORT=6051 sudo docker compose up --build -d chunk_server\n
 7418  sudo docker compose logs --tail 1000 -f chunk_server
 7419  PORT=6051 sudo docker compose up --build -d chunk_server\n
 7420  sudo docker compose logs --tail 1000 -f chunk_server
 7421  PORT=6051 sudo docker compose up --build -d chunk_server\n
 7422  sudo docker compose logs --tail 1000 -f chunk_server
 7423  PORT=6051 sudo docker compose up --build -d chunk_server\n
 7424  sudo docker compose logs --tail 1000 -f chunk_server
 7425  sudo docker compose up --build -d chunk_server --args PORT=6961\n
 7426  sudo docker compose up --build -d chunk_server --env PORT=6961\n
 7427  cd chunkserver\n
 7428  ^[[200~docker build -t your_image_name -f chunkserver.dockerfile .
 7429  docker build -t chunk-server -f chunkserver.dockerfile .\n
 7430  sudo docker build -t chunk-server -f chunkserver.dockerfile .\n
 7431  sudo docker images\n
 7432  sudo docker run -e PORT=1234 -p 1234:1234 chunk-server
 7433  sudo docker run -e PORT=6234 -p 1234:6234 chunk-server
 7434  sudo docker build -t chunk-server -f ./chunkserver/chunkserver.dockerfile .\n
 7435  sudo docker run -e PORT=6234 -p 1234:6234 chunk-server
 7436  sudo docker build -t chunk-server -f chunkserver.dockerfile .\n
 7437  sudo docker run -e PORT=6234 -p 1234:6234 chunk-server
 7438  sudo docker ps
 7439  sudo docker run -e PORT=6234 -p 1234:6234 chunk-server
 7440  sudo docker ps
 7441  sudo docker build -t chunk-server -f chunkserver.dockerfile .\n
 7442  sudo docker run -e PORT=6234 -p 1234:6234 chunk-server
 7443  sudo docker run -it -e PORT=6234 -p 1234:6234 chunk-server /bin/bash\n
 7444  sudo docker ps
 7445  docker ps -a\n
 7446  sudo docker ps -a\n
 7447  sudo docker logs hopeful_nash
 7448  sudo docker logs friendly_snyder
 7449  sudo docker build -t chunk-server -f chunkserver.dockerfile .\n
 7450  sudo docker run -it -e PORT=6234 -p 1234:6234 chunk-server /bin/bash\n
 7451  sudo docker run -it -e PORT=6234 -p 1234:6234 chunk-server\n
 7452  sudo docker ps
 7453  sudo docker stop google-file-system-master_server-1
 7454  sudo docker compose stop google-file-system-master_server-1
 7455  sudo docker stop google-file-system-master_server-1
 7456  sudo docker stop google-file-system-secondary_server-1
 7457  sudo docker ps
 7458  code .
 7459  hadoop fs -rm -r -f /in
 7460  hadoop fs -rm -r -f /input
 7461  hadoop fs -rm -r -f tem0 tem1
 7462  python grade.py 1
 7463  code .
 7464  git checkout llm_api
 7465  ls
 7466  git status
 7467  ssh localhost \nssh-keygen -t rsa -P '' -f ~/.ssh/id_rsa \ncat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys \nchmod 0600 ~/.ssh/authorized_keys
 7468  hadoop-3.3.6/bin/hdfs namenode -format\n
 7469  start-all.sh
 7470  python grade.py 1
 7471  htop
 7472  hadoop fs -mkdir input
 7473  hadoop fs -mkdir input/
 7474  hadoop dfs -mkdir input/
 7475  hdfs dfs -mkdir input/
 7476  code .
 7477  git status
 7478  git pull
 7479  git status
 7480  git add .
 7481  git commit -m "modified prompts in llm_api"
 7482  git push -u origin llm_api
 7483  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ input/ output/
 7484  ./runner-script /home/chirag/hadoop-3.3.6/share/hadoop/tools/lib/hadoop-streaming-3.3.6.jar ./input/ /input/ /output/
 7485  hadoop fs -rm -r -f /input /output
 7486  python grade.py 1
 7487  htop
 7488  sudo docker ps
 7489  sudo docker stop subtl_bot-meili-1
 7490  sudo docker ps
 7491  sudo docker system prune -f
 7492  code .
 7493  cd backend; npm start
 7494  cd frontend; npm start
 7495  cd backend; npm start
 7496  npm start
 7497  gcloud auth login
 7498  gcloud projects list\n
 7499  gcloud config set project lab-deployment-414310
 7500  gcloud app deploy
 7501  cd frontend;
 7502  npm run build:prod
 7503  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 7504  git status
 7505  git add .
 7506  git commit -m "added cosmetic changes"
 7507  git push -u origin new_branch
 7508  gcloud app browse
 7509  python grade.py 1
 7510  htop
 7511  code .
 7512  sudo ./run.sh logs --tail 1000 -f llm_api
 7513  sudo service apache2 stop
 7514  code .
 7515  sudo docker ps
 7516  sudo docker stop subtl_bot-redis-1
 7517  sudo docker ps
 7518  sudo docker stop subtl_bot-api-1
 7519  sudo docker stop subtl_doc_parser-backend-1
 7520  cd subtl_doc_parser
 7521  sudo ./subtl_doc_parser.sh -d -- up --build -d redis-queue queue db
 7522  sudo lsof -i :5432
 7523  sudo systemctl stop postgresql\n
 7524  sudo lsof -i :5432
 7525  sudo ./subtl_doc_parser.sh -d -- up --build -d redis-queue queue db
 7526  cd ..
 7527  sudo ./run.sh -d -- up --build -d llm_worker llm_api
 7528  sudo ./run.sh -d -- up --build -d llm_worker llm_api nginx
 7529  python grade.py 1
 7530  code .
 7531  cd backend; 
 7532  source venv/bin/activate
 7533  python server.py
 7534  cd frontend;
 7535  npm start
 7536  python server.py
 7537  code .
 7538  cd frontend;
 7539  npm run build:prod
 7540  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 7541  code .
 7542  clear
 7543  cd master
 7544  cd ..
 7545  cd master
 7546  python primary.py
 7547  cd chunkserver\n
 7548  python communcation.py
 7549  python communcation.py 6501
 7550  python communcation.py 6502
 7551  cd chunkserver\n
 7552  python communcation.py 6502
 7553  cd chunkserver\n
 7554  python communcation.py 6502
 7555  python communcation.py 6503
 7556  cd client
 7557  python client.py
 7558  cd ..
 7559  sudo docker compose up master_server
 7560  python communcation.py 6501
 7561  python communcation.py 6502
 7562  python communcation.py 6503
 7563  cd chunkserver\n
 7564  python communcation.py 6501
 7565  cd chunkserver\n
 7566  python communcation.py 6503
 7567  python client.py
 7568  sudo docker compose up master_server
 7569  python communcation.py 6501
 7570  python communcation.py 6503
 7571  python client.py
 7572  sudo docker compose up master_server
 7573  python communcation.py 6501
 7574  python communcation.py 6503
 7575  python client.py
 7576  sudo docker compose up --build master_server
 7577  python communcation.py 6501
 7578  python communcation.py 6503
 7579  python client.py
 7580  python communcation.py 6501
 7581  python communcation.py 6503
 7582  htop
 7583  code .
 7584  clear
 7585  sudo docker ps
 7586  sudo ./run.sh logs --tail 1000 -f llm_api
 7587  sudo ./run.sh -d -- up --build -d llm_worker llm_api
 7588  sudo ./run.sh logs --tail 1000 -f llm_api
 7589  sudo ./run.sh -d -- up --build -d llm_worker llm_api
 7590  sudo ./run.sh logs --tail 1000 -f llm_api
 7591  sudo ./run.sh logs --tail 1000 -f llm_w
 7592  sudo ./run.sh logs --tail 1000 -f llm_worker
 7593  sudo ./run.sh -d -- up --build -d llm_worker llm_api nginx
 7594  git status
 7595  git add .
 7596  git status
 7597  git add .
 7598  git commit -m "modified map-red prompt"
 7599  git push -u origin l
 7600  git push -u origin llm_api
 7601  git pull
 7602  code .
 7603  sudo docker ps
 7604  sudo docker compose up --build master_server
 7605  lsof -i :8080
 7606  sudo kill -9 $(sudo lsof -t -i:8000)\n
 7607  sudo docker compose up --build master_server
 7608  sudo netstat -lpn |grep :8080\n
 7609  kill -9 341366
 7610  sudo kill -9 341366
 7611  sudo docker compose up --build master_server
 7612  code .
 7613  sudo docker compose up --build master_server
 7614  sudo docker compose up --build --force-recreate master_server
 7615  sudo docke rimage
 7616  sudo docke image
 7617  sudo docke images
 7618  sudo docker images
 7619  sudo docker rmi -f google-file-system-master_server
 7620  sudo docker images
 7621  sudo docker compose up --build --force-recreate master_server
 7622  sudo docker compose logs --tail 1000 -f master_server
 7623  ls
 7624  cd master
 7625  python primary.py
 7626  cd chunkserver\n
 7627  python communcation.py 6508
 7628  cd ..
 7629  sudo docker compose logs --tail 1000 -f master_server
 7630  sudo docker compose up --build --force-recreate master_server
 7631  code .
 7632  clear
 7633  touch llama3.out
 7634  code .
 7635  sudo docker compose up --build --force-recreate master_server
 7636  clear
 7637  cd master
 7638  python primary.py
 7639  cd chunkserver\n
 7640  python communcation.py 6508
 7641  cd chunkserver\n
 7642  python communcation.py 6509
 7643  cd chunkserver\n
 7644  python communcation.py 6510
 7645  cd client
 7646  python client.py
 7647  python primary.py
 7648  python communcation.py 6508
 7649  python communcation.py 6509
 7650  python communcation.py 6510
 7651  python client.py
 7652  python primary.py
 7653  python communcation.py 6508
 7654  python communcation.py 6509
 7655  python communcation.py 6510
 7656  python client.py
 7657  python primary.py
 7658  python communcation.py 6508
 7659  python communcation.py 6509
 7660  python communcation.py 6510
 7661  python client.py
 7662  python primary.py
 7663  python client.py
 7664  python communcation.py 6508
 7665  python communcation.py 6509
 7666  python communcation.py 6510
 7667  sudo docker compose run client\n
 7668  sudo docker compose stop client\n
 7669  sudo docker compose run client\n
 7670  cd chunkserver\n
 7671  python chunk.py
 7672  stdin_open: true # Allows for interactive input\n    tty: true # Required for interactive output
 7673  docker compose run -e PORT=6008 chunk_server\n
 7674  sudo docker compose run -e PORT=6008 chunk_server\n
 7675  docker-compose build chunk_server k_server\n
 7676  docker-compose build chunk_server\n
 7677  sudo docker compose build chunk_server\n
 7678  sudo docker compose run -e PORT=6008 chunk_server\n
 7679  sudo docker compose build chunk_server\n
 7680  cd ..
 7681  sudo docker compose build master_server
 7682  sudo docker compose run master_server
 7683  sudo docker compose build chunk_server\n
 7684  sudo docker compose run -e PORT=6008 chunk_server
 7685  sudo docker compose run -e PORT=6009 chunk_server
 7686  sudo docker ps
 7687  clear
 7688  sudo docker build master_server client chunk_server
 7689  sudo docker compose build master_server client chunk_server
 7690  sudo docker compose up --build --force-recreate master_server
 7691  clear
 7692  sudo docker compose run -e PORT=6009 chunk_server
 7693  clear
 7694  sudo docker compose run -e PORT=6010 chunk_server
 7695  clear
 7696  sudo docker compose run -e PORT=6011 chunk_server
 7697  sudo docker compose up --build --force-recreate client
 7698  sudo docker compose up --build client
 7699  sudo docker compose up  client
 7700  sudo docker ps
 7701  cd ..
 7702  sudo docker compose up  client
 7703  cd client
 7704  python client.py
 7705  sudo docker compose up --build --force-recreate master_server
 7706  sudo docker compose run -e PORT=6009 chunk_server
 7707  sudo docker compose run -e PORT=6010 chunk_server
 7708  sudo docker compose run -e PORT=6011 chunk_server
 7709  python client.py
 7710  cd chunkserver\n
 7711  python communcation.py 6510
 7712  sudo docker compose run -e client
 7713  sudo docker compose run client
 7714  sudo docker compose up --build --force-recreate client
 7715  sudo docker ps
 7716  code .
 7717  sudo apt-get install terminator
 7718  clear
 7719  pwd
 7720  cd /media/chirag/DATA4/CODE_AMA/distributed-systems/project/Google-File-System-master\n
 7721  cd /media/chirag/DATA4/CODE_AMA/distributed-systems/project/Google-File-System-master\n
 7722  ls
 7723  clear
 7724  cd /media/chirag/DATA4/CODE_AMA/distributed-systems/project/Google-File-System-master\n
 7725  ls
 7726  cd master
 7727  clear
 7728  ls
 7729  clear
 7730  cd chunkserver\n
 7731  clear
 7732  cd chunkserver\n
 7733  clear
 7734  cd /media/chirag/DATA4/CODE_AMA/distributed-systems/project/Google-File-System-master\n
 7735  ls
 7736  clear
 7737  cd chunkserver\n
 7738  clear
 7739  cd /media/chirag/DATA4/CODE_AMA/distributed-systems/project/Google-File-System-master
 7740  cd /media/chirag/DATA4/CODE_AMA/distributed-systems/project/Google-File-System-master\n
 7741  cd /media/chirag/DATA4/CODE_AMA/distributed-systems/project/Google-File-System-mastercl\n
 7742  clear
 7743  clear
 7744  cd chunkserver\n
 7745  clear
 7746  clear
 7747  cd client
 7748  clear
 7749  python client.py
 7750  python communcation.py 6510
 7751  python3 communcation.py 6510
 7752  python primary.py
 7753  python communcation.py 6500
 7754  python communcation.py 6501
 7755  python communcation.py 6502
 7756  python3 communcation.py 6503
 7757  clear
 7758  clear
 7759  clear
 7760  clear
 7761  python primary.py
 7762  clear
 7763  python primary.py
 7764  python3 communcation.py 6500
 7765  python3 communcation.py 6501
 7766  python3 communcation.py 6502
 7767  python3 communcation.py 6503
 7768  clear
 7769  python client.py
 7770  clear
 7771  python primary.py
 7772  python communcation.py 6500
 7773  python communcation.py 6501
 7774  clear
 7775  python communcation.py 6502
 7776  python communcation.py 6503
 7777  clear
 7778  python client.py
 7779  python primary.py
 7780  python client.py
 7781  python primary.py
 7782  python client.py
 7783  python primary.py
 7784  python communcation.py 6503
 7785  python client.py
 7786  python primary.py
 7787  python client.py
 7788  python primary.py
 7789  python client.py
 7790  clear
 7791  cd ../master
 7792  python primary.py
 7793  clear
 7794  python client.py
 7795  cd ../chunkserver
 7796  python communcation.py 6500
 7797  python communcation.py 6501
 7798  python communcation.py 6502
 7799  clear
 7800  python communcation.py 6503
 7801  clear
 7802  python communcation.py 6500
 7803  python primary.py
 7804  clear
 7805  python primary.py
 7806  python client.py
 7807  python communcation.py 6500
 7808  python communcation.py 6501
 7809  python communcation.py 6502
 7810  python communcation.py 6503
 7811  clear
 7812  python communcation.py 6500
 7813  clear
 7814  python primary.py
 7815  clear
 7816  python primary.py
 7817  clear
 7818  python client.py
 7819  python communcation.py 6500
 7820  python communcation.py 6501
 7821  clear
 7822  python communcation.py 6502
 7823  clear
 7824  python communcation.py 6503
 7825  clear
 7826  python primary.py
 7827  clear
 7828  python primary.py
 7829  python client.py
 7830  clear
 7831  python communcation.py 6500
 7832  python communcation.py 6501
 7833  clear
 7834  python communcation.py 6502
 7835  python communcation.py 6503
 7836  python client.py
 7837  clear
 7838  python primary.py
 7839  clear
 7840  python primary.py
 7841  python client.py
 7842  clear
 7843  python communcation.py 6500
 7844  clear
 7845  python communcation.py 6501
 7846  python communcation.py 6502
 7847  python communcation.py 6503
 7848  clear
 7849  clear
 7850  python primary.py
 7851  clear
 7852  python primary.py
 7853  clear
 7854  python client.py
 7855  python communcation.py 6500
 7856  clear
 7857  python communcation.py 6501
 7858  clear
 7859  python communcation.py 6502
 7860  clear
 7861  python communcation.py 6503
 7862  clear
 7863  clear
 7864  python primary.py
 7865  python client.py
 7866  python communcation.py 6500
 7867  python communcation.py 6501
 7868  python communcation.py 6502
 7869  python communcation.py 6503
 7870  clear
 7871  clear
 7872  python primary.py
 7873  clear
 7874  python primary.py
 7875  clear
 7876  python client.py
 7877  python communcation.py 6500
 7878  clear
 7879  python communcation.py 6501
 7880  clear
 7881  python communcation.py 6502
 7882  clear
 7883  python communcation.py 6503
 7884  clear
 7885  python primary.py
 7886  clear
 7887  python primary.py
 7888  python client.py
 7889  python communcation.py 6500
 7890  python communcation.py 6501
 7891  python communcation.py 6502
 7892  python communcation.py 6503
 7893  clear
 7894  clear
 7895  clear
 7896  clear
 7897  python primary.py
 7898  python secondary.py
 7899  python client.py
 7900  clear
 7901  clear
 7902  python primary.py
 7903  python client.py
 7904  python communcation.py 6500
 7905  python communcation.py 6501
 7906  python communcation.py 6502
 7907  python communcation.py 6503
 7908  cd ../chunkserver
 7909  clear
 7910  python communcation.py 6504
 7911  python client.py
 7912  sudo docker ps
 7913  sudo docker compose up --build --force-recreate client
 7914  sudo docker compose build  client
 7915  sudo docker compose build chunk_server
 7916  sudo docker compose build master_server secondary_server
 7917  sudo docker compose run master_server
 7918  clear
 7919  sudo docker compose run master_server
 7920  sudo docker compose run secondary_server
 7921  sudo docker compose run -e PORT=6011 chunk_server
 7922  sudo docker compose build chunk_server
 7923  clear
 7924  sudo docker compose run -e PORT=6011 chunk_server
 7925  sudo docker compose run -e PORT=6012 chunk_server
 7926  sudo docker compose run -e PORT=6013 chunk_server
 7927  sudo docker compose run -e PORT=6014 chunk_server
 7928  sudo docker compose run client
 7929  code .
 7930  clear
 7931  clear
 7932  clear
 7933  clear
 7934  clear
 7935  htop
 7936  ./jmeter\n
 7937  touch qa_llama3.json
 7938  code .
 7939  git checkout agent_test
 7940  git pull
 7941  sudo ./run.sh logs --tail 1000 -f llm_api
 7942  touch agent_llama3_pormpt
 7943  touc agent_llama3_pormpt
 7944  touch agent_llama3_pormpt
 7945  ls
 7946  touch agent_llama3_pormpt
 7947  htop
 7948  code .
 7949  ./jmeter\n
 7950  sudo ./run.sh logs --tail 1000 -f llm_api
 7951  sudo ./run.sh -d -- up --build -d llm_api
 7952  code .
 7953  sudo ./run.sh logs --tail 1000 -f llm_api
 7954  sudo ./run.sh -d -- up --build -d llm_api
 7955  df
 7956  sudo docker system prune -f
 7957  sudo ./run.sh logs --tail 1000 -f llm_api
 7958  git status
 7959  git add .
 7960  git commit -m "updated qa, agent with mistrl prompt + json repair"
 7961  git checkout llm_api
 7962  git checkout agent_test
 7963  git add .
 7964  git commit -m "updated qa, agent with mistrl prompt + json repair"
 7965  git checkout agent_test
 7966  git checkout llm_api
 7967  git status
 7968  git add .
 7969  git commit -m "updated qa, agent with mistrl prompt + json repair"
 7970  git push -u origin llm_api
 7971  git add .
 7972  git commit -m "auth*"
 7973  git push -u origin llm_api
 7974  git status
 7975  git add .
 7976  git commit -m "modified agent, qa prompt"
 7977  git push -u origin llm_api
 7978  git pull
 7979  git push -u origin llm_api
 7980  htop
 7981  code .
 7982  git pull
 7983  cd backend; 
 7984  npm start
 7985  cd frontend; npm start
 7986  code .
 7987  cd frontend; npm start
 7988  cd backend; npm start
 7989  git add .
 7990  git commit -m "added search and changed navigation pane posn"
 7991  git push -u origin main
 7992  cd frontend; npm start
 7993  cd backend; npm start
 7994  git add .
 7995  git commit -m "fixed minor bug"
 7996  git push -u origin main
 7997  code .
 7998  cd backend; npm start
 7999  cd backend; 
 8000  source venv/bin/activate
 8001  python server.py
 8002  cd frontend; npm start
 8003  code .
 8004  cd frontend; npm start
 8005  cd backend; npm start
 8006  python server.py
 8007  npm start
 8008  python server.py
 8009  code .
 8010  htop
 8011  cd backend; npm start
 8012  cd frontend; npm start
 8013  cd backend; npm start
 8014  cl
 8015  clear
 8016  cd backend; npm start
 8017  clear
 8018  cd backend; npm start
 8019  npm start
 8020  node "/media/chirag/DATA4/VLABS/vlabs-lab-deployment/app-lab-deployment-web/frontend/src/utils/config_data.js"
 8021  cd frontend;
 8022  npm install is-url-http\n
 8023  npm install is-url-http -f\n
 8024  gcloud auth login
 8025  gcloud config set project lab-deployment-414310
 8026  gcloud app deploy
 8027  npm run build:prod
 8028  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 8029  cd ..
 8030  git status
 8031  git add .
 8032  git commit -m "fixed bugs"
 8033  git push -u origin new_branch
 8034  code .
 8035  cd backend; 
 8036  source venv/bin/activate
 8037  python server.py
 8038  cd frontend; npm start
 8039  python server.py
 8040  cd..
 8041  cd ..
 8042  git add .
 8043  git commit -m "added custom tree component"
 8044  git push -u origin main
 8045  code .
 8046  clear
 8047  source venv/bin/activate
 8048  python server.py
 8049  clear
 8050  cd frontend; npm start
 8051  ks
 8052  asas
 8053  sleep 20
 8054  sleep 5
 8055  clear
 8056  curl -X 'POST' \\n  'https://qa.subtl.ai/llmapi/qa/' \\n  -H 'accept: application/json' \\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3MTQ3MDkyMTYsInN1YiI6IjEifQ.aDYyRZoX317bLikW4C7fBoUkScVHUq3A7Aczpxs2tcA' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "backend": "vLLM/Mistralv2AWQ",\n  "question": "Can shadow credit be used for local cheques?",\n  "evidences": [\n    {\n      "document_name": "CE1C130812FS",\n      "context": "CO. (CHD) No. 873 / 03.09.01 / 2008-09 dated November 24, 2008, in terms of which, banks are required to specify the time line for realisation of cheques, including local cheques, in their respective CCPs. Paragraph 4(ii) of the circular also states that in case of local cheques, banks shall permit usage of the shadow credit afforded to the customers'\'' account immediately after closure of relative return clearing and in any case, withdrawal shall be allowed on the same day or maximum within an hour of the commencement of business on the next working day, subject to usual safeguards. Tel: (91-22) 2266 5336; Fax: (91-22) 2269 1557; e-mail : helpdpss@rbi.org.in Department of Payment & Settlement Systems, Central Office,",\n      "metadata": {}\n    },\n    {\n      "document_name": "39MD440D125D51C2451295A5CA7D45EF09B9",\n      "context": "Raising Money through Private Placement of Debentures etc. by CICs Applicability of Know Your Customer (KYC) Direction, 2016 Rounding off transactions to the Nearest Rupee by CICs CICs shall ensure that all transactions, including payment of interest on deposits/ charging of interest on advances, are rounded off to the nearest rupee, i.e. fractions of 50 paise and above shall be rounded off to the next higher rupee and fractions of less than 50 paise should be ignored. Further, they shall also ensure that cheques / drafts issued by clients containing fractions of a rupee are not rejected by them. Ratings for CICs CICs also issue financial products like Commercial Paper, Debentures etc.",\n      "metadata": {}\n    },\n    {\n      "document_name": "CSICLC01011994",\n      "context": "5,000/- irrespective of the category or status of the drawers of the cheques provided they are satisfied about proper conduct of the accounts and the customers desire the facility, and subject to recovering a charge of Rs. 5/- per cheque. If a customer does not wish to receive immediate credit, the cheque will be credited on realisation through clearing as hitherto. Banks may consider introducing pay-in-slips with a clause that in the event of dishonour of the cheque, the customer will have to pay normal rate of interest for the period banks were out of funds. These instructions should be implemented with immediate effect. Please acknowledge receipt to our Regional Office in the enclosed format. Yours faithfully, Sd/- Kadam)",\n      "metadata": {}\n    },\n    {\n      "document_name": "2010RCB1010",\n      "context": "BC. No. The Chairmen/Chief Executives of All State and Central Co-operative Banks Dear Sir Collection of third party account payee cheques  Prohibition on crediting proceeds to third party accounts Please refer to our circular RPCD.CO.RF.BC.No.18/07.38.03/2009-10 dated September 7, 2009 on the captioned subject, in which it has been stated that the practice of collection of cheques crossed account payee through third party accounts (of co- operative credit societies) is not permissible. However, to facilitate collection of cheques from a payment system angle, it has been clarified therein that sub-members of the clearing houses may collect the cheques of their customers for the credit to their accounts through the sponsor member, under certain circumstances referred to therein. Tel No:",\n      "metadata": {}\n    },\n    {\n      "document_name": "POSB(CBS)Manual",\n      "context": "There is also no objection to the acceptance of cheque drawn by a third party in favour of the Postmaster provided the cheque is accompanied by an application from the depositor requesting the Postmaster to credit the amount into his account. Note:- A cheque drawn on the POSB in favour of a person other than the depositor may also be accepted for credit in Post Office Savings Bank provided it has been duly endorsed in favour of the depositor. Opening of new account by cheque in case of RD/TD/MIS/SCSS/SSA/PPF/NSC/KVP accounts:- The cheque should be drawn in favour of either the Postmaster to whom the application AOF is presented or the depositor. ( signature of drawer).",\n      "metadata": {}\n    },\n    {\n      "document_name": "RRB65080410",\n      "context": "   ______________________ RESERVE BANK OF INDIA______________________ The Chairman All Regional Rural Banks (RRBs) Dear Sir, Cheque Collection Policy (CCP) - Immediate credit of Local / Outstation Cheques Please refer to our circular RPCD.CO.RRB.BC.No. 87/03.05.33/2008-09 dated February 5, 2009 advising RRBs to frame their Cheque Collection Policies covering local and outstation cheque collection as per the time frame prescribed by the National Consumer Disputes Redressal Commission. Yours faithfully ( R.C.Sarangi ) Chief General Manager Rural Planning & Credit Department Central Office, 10 th Floor, Central Office Building, Shahid Bhagat Singh Marg Mumbai - 1",\n      "metadata": {}\n    },\n    {\n      "document_name": "84035",\n      "context": "Immediate Credit of local / outstation cheques: Scheduled UCBs were advised to afford immediate credit in respect of all local/outstation cheques up to Rs.7500/- tendered by individual accountholder subject to certain conditions such as bank being satisfied about the proper conduct of the customers accounts etc. Time Frame for Collection of Local / Outstation Instruments:",\n      "metadata": {}\n    },\n    {\n      "document_name": "CE1C130812FS",\n      "context": "As you may be aware, banks are required to specify the time line for realisation of local and outstation cheques in their Cheque Collection Policies (CCP) including the compensation payable for delayed credit, if any. However, on perusal of the Cheque Collection Policies (CCPs) and Compensation Policies of various banks, it is observed that there is no mention about the compensation in respect of the delay in realisation of local cheques. Instances of delayed credit to customers'\'' accounts without any compensation for the delayed period beyond the time line indicated in the CCPs, in respect of local cheques, have been brought to our notice. In this regard, a reference is invited to our circular DPSS. CO. (CHD) No. 873 / 03.09.01 / 2008-09 dated November 24, 2008, in terms of which, banks are required to specify the time line for realisation of cheques, including local cheques, in their respective CCPs. Paragraph 4(ii) of the circular also states that in case of local cheques, banks shall permit usage of the shadow credit afforded to the customers'\'' account immediately after closure of relative return clearing and in any case, withdrawal shall be allowed on the same day or maximum within an hour of the commencement of business on the next working day, subject to usual safeguards. In view of the above, banks are advised to reframe their CCPs to include compensation payable for the delayed period in the case of collection of local cheques as well. In case, no rate is specified in the CCP for delay in realisation of local cheques, compensation at savings bank interest rate shall be paid for the corresponding period of delay. As regards the realization period and compensation for delayed credit pertaining to outstation cheques, the instructions contained in paragraph 4(iii) of our circular dated November 24, 2008 remain unchanged. Tel: (91-22) 2266 5336; Fax: (91-22) 2269 1557; e-mail : helpdpss@rbi.org.in Department of Payment & Settlement Systems, Central Office,",\n      "metadata": {}\n    },\n    {\n      "document_name": "RRB65080410",\n      "context": "INDIA______________________ The Chairman All Regional Rural Banks (RRBs) Cheque Collection Policy (CCP) - Immediate credit of Local / Outstation Cheques Please refer to our circular RPCD.CO.RRB.BC.No. 87/03.05.33/2008-09 dated February 5, 2009 advising RRBs to frame their Cheque Collection Policies covering local and outstation cheque collection as per the time frame prescribed by the National Consumer Disputes Redressal Commission. RRBs are advised that the Cheque Collection Policy should include instructions on immediate credit for local/outstation cheques in addition to the aspects of time frame for collection of local/outstation instruments and interest payment of delayed collection. Please acknowledge receipt of this circular to our Regional Offices. Yours faithfully ( R.C.Sarangi ) Chief General Manager No: 91-22-22661602 : 91-22-22621011/22610943/22610948 Email ID:cgmicrpcd@rbi.org.in",\n      "metadata": {}\n    },\n    {\n      "document_name": "Customer service in banks",\n      "context": "Banks are advised to comply with the final order on '\''timeframe for collection of outstation cheques'\'' passed by the National Consumer Disputes Redressal Commission in case no. 82 of 2006. Further, banks are advised as under: Banks shall reframe their Cheque Collection Policies (CCPs) covering local and outstation cheque collection as per the timeframe prescribed by the Commission. For local cheques, credit and debit shall be given on the same day or at the most the next day of their presentation in clearing. Ideally, in respect of local clearing, banks shall permit usage of the shadow credit afforded to the customer accounts immediately after closure of relative return clearing and in any case withdrawal shall be allowed on the same day or maximum within an hour of commencement of business on the next working day, subject to usual safeguards. Timeframe for collection of cheques drawn on State Capitals / major cities / other locations to be 7/10/14 days respectively. If there is any delay in collection beyond this period, interest at the rate specified in the CCP of the bank, shall be paid. In case the rate is not specified in the CCP, the applicable rate shall be the interest rate on Fixed Deposits for the corresponding maturity. The timeframe for collection specified by the Commission shall be treated as outer limit and credit shall be afforded if the process gets completed earlier. Banks shall not decline to accept outstation cheques deposited by its customers for collection. Banks shall give wide publicity to the CCP by prominently displaying salient features thereof in bold and visible letters on the notice board at their branches. (vi) A copy of the complete CCP shall be made available by the branch manager, if the customers require so.",\n      "metadata": {}\n    }\n  ],\n  "prompt_template": "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe.  Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature. If a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don'\''t know the answer to a question, please don'\''t share false information. Stick to the information given to you, and please avoid generating any additional text. <|eot_id|><|start_header_id|>user<|end_header_id|>\n\n Here is a set of contexts .\n {evidence_string} \n Choose the most relevant contexts and answer based only on them. Discard the contexts which are not relevant. Try to keep your answers as concise, short and accurate as possible. The question is: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>",\n  "max_new_tokens": 300,\n  "temperature": 0.7,\n  "top_k": 50,\n  "top_p": 0.95,\n  "prune_dangling_sents": true,\n  "stream": false\n}'\n
 8057  touch qa.curl
 8058  cat qa.curl > bash
 8059  cat qa.curl | bash
 8060  cat qa_.curl | bash
 8061  cat qa.curl | bash
 8062  cat qa_.curl | bash
 8063  clear
 8064  cat qa_.curl | bash
 8065  cat qa.curl | bash
 8066  code .
 8067  python -m venv venv\n
 8068  pip install fastapi requests pyaml uvicorn
 8069  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 8070  source venv/bin/activate
 8071  pip install httpx
 8072  source venv/bin/activate
 8073  uvicorn s-stream:app --host 0.0.0.0 --port 8001\n
 8074  uvicorn mid:app --host 0.0.0.0 --port 8002\n
 8075  clear
 8076  uvicorn f:app --host 0.0.0.0 --port 8003\n
 8077  curl -N http://localhost:8003/consume-stream\n
 8078  uvicorn f:app --host 0.0.0.0 --port 8003\n
 8079  uvicorn mid:app --host 0.0.0.0 --port 8002\n
 8080  uvicorn s-stream:app --host 0.0.0.0 --port 8001\n
 8081  curl -N http://localhost:8003/consume-stream\n
 8082  uvicorn s-stream:app --host 0.0.0.0 --port 8001\n
 8083  uvicorn mid:app --host 0.0.0.0 --port 8002\n
 8084  uvicorn f:app --host 0.0.0.0 --port 8003\n
 8085  uvicorn s-stream:app --host 0.0.0.0 --port 8001\n
 8086  curl -N http://localhost:8003/consume-stream\n
 8087  htop
 8088  code .
 8089  cd backend; npm start
 8090  cd frontend; npm start
 8091  code .
 8092  npm start
 8093  git pull
 8094  cat qa.curl | bash
 8095  cat qa_.curl | bash
 8096  cat qa.curl | bash
 8097  cat qa_.curl | bash
 8098  code .
 8099  npm i
 8100  npm start
 8101  cat qa_.curl | bash
 8102  code .
 8103  python -u "/media/chirag/DATA4/subtl.ai/tets/stream_test_qa.py"
 8104  cat qa_.curl | bash
 8105  cat qa.curl | bash
 8106  cat qa_.curl | bash
 8107  python -u "/media/chirag/DATA4/subtl.ai/tets/stream_test_qa.py"
 8108  cat qa_.curl | bash
 8109  python -u "/media/chirag/DATA4/subtl.ai/tets/stream_test_qa.py"
 8110  pip install httpx
 8111  python -u "/media/chirag/DATA4/subtl.ai/tets/stream_test_qa.py"
 8112  clear
 8113  python -u "/media/chirag/DATA4/subtl.ai/tets/stream_test_qa.py"
 8114  cat qa_.curl | bash
 8115  code .
 8116  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 8117  clear
 8118  source venv/bin/activate
 8119  uvicorn s-stream:app --host 0.0.0.0 --port 8001\n
 8120  uvicorn mid:app --host 0.0.0.0 --port 8001\n
 8121  uvicorn mid:app --host 0.0.0.0 --port 8002\n
 8122  uvicorn f:app --host 0.0.0.0 --port 8003\n
 8123  code .
 8124  npm start
 8125  code .
 8126  npm start
 8127  uvicorn f:app --host 0.0.0.0 --port 8003\n
 8128  uvicorn s-stream:app --host 0.0.0.0 --port 8001\n
 8129  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 8130  code .
 8131  npm start
 8132  uvicorn s-stream:app --host 0.0.0.0 --port 8001\n
 8133  uvicorn mid:app --host 0.0.0.0 --port 8002\n
 8134  uvicorn f:app --host 0.0.0.0 --port 8003\n
 8135  python -u "/media/chirag/DATA4/subtl.ai/tets/stream_test_qa.py"
 8136  curl -X 'GET' \\n  'https://qa.subtl.ai/llmapi/stream-data' \\n  -H 'accept: application/json'
 8137  curl -X 'GET' \\n  'http://qa.subtl.ai/llmapi/stream-data' \\n  -H 'accept: application/json'
 8138  curl -X 'GET' \\n  'http://qa.subtl.ai/api/stream-data' \\n  -H 'accept: application/json'
 8139  curl -X 'GET' \\n  'http://qa.subtl.ai/llmapi/stream-data' \\n  -H 'accept: application/json'
 8140  source venv/bin/activate
 8141  pip install sse-starlette
 8142  uvicorn s-stream:app --host 0.0.0.0 --port 8001\n
 8143  uvicorn s-stream:app --host 0.0.0.0 --port 8003\n
 8144  curl -X 'GET' \\n  'http://localhost:8003/consume-stream' \\n  -H 'accept: application/json'
 8145  uvicorn s-stream:app --host 0.0.0.0 --port 8003\n
 8146  curl -X 'GET' \\n  'http://localhost:8003/consume-stream' \\n  -H 'accept: application/json'
 8147  uvicorn s-stream:app --host 0.0.0.0 --port 8003\n
 8148  curl -X 'GET' \\n  'http://localhost:8003/consume-stream' \\n  -H 'accept: application/json'
 8149  code .
 8150  htop
 8151  code .
 8152  cat qa.curl | bash
 8153  code .
 8154  touch videolink
 8155  code .
 8156  cd backend;
 8157  source venv/bin/activate
 8158  pip install gspread oauth2client\n
 8159  pip freeze > requirements.txt\n
 8160  python server.py
 8161  cd frontend; npm start
 8162  code .
 8163  python server.py
 8164  /bin/python3.9
 8165  python server.py
 8166  cd backend;
 8167  source venv/bin/activate
 8168  pip show gspread\n
 8169  python server.py
 8170  cd ..
 8171  clear
 8172  git status
 8173  git add .
 8174  git commit -m "updated gsheet source + create feature"
 8175  git push -u origin main
 8176  python server.py
 8177  cd frontend; npm start
 8178  ls
 8179  clear
 8180  code .
 8181  clear
 8182  npm start
 8183  npm i @microsoft/fetch-event-source
 8184  python -u "/media/chirag/DATA4/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_qa.py"
 8185  npm i axios
 8186  touch stream_transact.py
 8187  python -u "/media/chirag/DATA4/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_transact.py"
 8188  python -u "/media/chirag/DATA4/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_qa.py"
 8189  python -u "/media/chirag/DATA4/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_transact.py"
 8190  python -u "/media/chirag/DATA4/subtl.ai/subtl_bot/subtl_llm/app/tests/stream_test_qa.py"
 8191  npm start
 8192  code .
 8193  htop
 8194  gcloud app logs read\n
 8195  gcloud app logs read -l\n
 8196  gcloud app logs -f read\n
 8197  gcloud app logs -l read\n
 8198  gcloud app logs read\n
 8199  gcloud app logs read --limit=5000 > logs\n
 8200  gcloud app logs tail\n
 8201  clear
 8202  cd backend;
 8203  gcloud app deploy
 8204  gcloud app logs tail\n
 8205  gcloud app deploy
 8206  code .
 8207  npm start
 8208  git checkout subtl-api-temp\n\n\n\n\n\n
 8209  code .
 8210  git add .
 8211  git commit -m "added stream_test"
 8212  git checkout subtl-api-temp\n\n\n\n\n\n
 8213  git pull
 8214  ls
 8215  cd subtl_frontend
 8216  ls
 8217  yarn i
 8218  yarn instal
 8219  yarn install
 8220  yarn dev
 8221  git pull
 8222  code .
 8223  yarn dev
 8224  git pull
 8225  git add .
 8226  git commit -m "minute change for chat bubble"
 8227  git pull
 8228  cd subtl_frontend
 8229  yarn install
 8230  python
 8231  git pull
 8232  yarn install; yarn dev
 8233  yarn dev
 8234  clear
 8235  yarn dev
 8236  git pull
 8237  git status
 8238  git pull
 8239  git add .
 8240  git commit -m "minute change"
 8241  git pull
 8242  htop
 8243  git status
 8244  git add .
 8245  git commit -m "added streaming and agent"
 8246  git push -u origin subtl-api-temp
 8247  git pull
 8248  git push -u origin subtl-api-temp
 8249  git status
 8250  cd subtl_frontend
 8251  yarn dev
 8252  cat .env > xx
 8253  gcloud app logs tail \n
 8254  code .
 8255  cd backend; npm start
 8256  cd frontend; npm start
 8257  cd backend; npm start
 8258  cd backend; 
 8259  gcloud app deploy
 8260  gcloud app logs tail \n
 8261  git status
 8262  gcloud app logs tail \n
 8263  htop
 8264  code .
 8265  cd backend; 
 8266  source venv/bin/activate
 8267  python server.py
 8268  source venv/bin/activate
 8269  python server.py
 8270  pip freeze
 8271  pwd
 8272  python -m venv venv\n
 8273  pip install -r requirements.txt
 8274  python3.9 -m venv venv\n
 8275  source venv/bin/activate
 8276  pip install -r requirements.txt
 8277  python server.py
 8278  cd frontend; npm start
 8279  python server.py
 8280  git status
 8281  git add .
 8282  git commit -m "added delete operations to category and directory"
 8283  git push -u origin main
 8284  code .
 8285  git checkout dev
 8286  git pull
 8287  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'\n\n\n\n\n\n
 8288  git clone https://github.com/virtual-labs/app-text-generator.git
 8289  cd app-text-generator
 8290  git branch dev
 8291  git checkout dev
 8292  git status
 8293  cd ..
 8294  ls
 8295  cp vlabs-prompt-repo/* app-text-generator/*
 8296  cp vlabs-prompt-repo/* app-text-generator/
 8297  cp -r vlabs-prompt-repo/* app-text-generator/
 8298  code .
 8299  npm start
 8300  cd frontend; npm start
 8301  cd backend; 
 8302  rm -rf venv
 8303  python3.9 -m venv venv\n
 8304  source venv/bin/activate
 8305  pip install -r requirements.txt
 8306  python server.py
 8307  git status
 8308  git add .
 8309  git commit -m "added to repo"
 8310  git push -u origin dev
 8311  code .
 8312  cd backend; 
 8313  npm start
 8314  cd frontend; npm start
 8315  code .
 8316  cd backend; npm start
 8317  cd frontend; npm start
 8318  code .
 8319  git status
 8320  git add .
 8321  git commit -m "added live search"
 8322  git push -u origin new_branch
 8323  touch token 
 8324  npm start
 8325  cd frontend; npm start
 8326  cd frontend; 
 8327  npm i valid-url
 8328  htop
 8329  cd ..
 8330  git status
 8331  git add .
 8332  git commit -m "refactored code"
 8333  git push -u origin dev
 8334  git pull
 8335  git push -u origin dev
 8336  cd backend; npm start
 8337  gcloud auth login
 8338  gcloud config set project outreach-default
 8339  gcloud app deploy
 8340  clear
 8341  npm run build:prod
 8342  gcloud app browse
 8343  npm run build:prod
 8344  gcloud app deploy
 8345  gcloud app browse
 8346  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'\n\n\n\n\n\n\n
 8347  code .
 8348  cd backend; npm start
 8349  cd frontend; 
 8350  npm start
 8351  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'\n\n\n\n\n\n\n
 8352  gsutil cp -r build/* gs://outreach.vlabs.ac.in
 8353  gcloud auth login
 8354  gcloud config set project lab-deployment-414310
 8355  gcloud app logs tail \n
 8356  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'\n\n\n\n\n\n\n
 8357  code .
 8358  cd frontend; npm start
 8359  cd backend; npm start
 8360  gcloud config set project lab-deployment-414310
 8361  cd backend; 
 8362  gcloud app deploy
 8363  cd frontend;
 8364  npm run build:prod
 8365  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 8366  gcloud app browse
 8367  code .
 8368  cd backend; 
 8369  npm start
 8370  cd frontend; npm start
 8371  code .
 8372  cd backend; npm start
 8373  cd frontend; npm start
 8374  cd frontend;
 8375  npm run build:prod
 8376  gcloud config set project outreach-default
 8377  gsutil cp -r build/* gs://outreach.vlabs.ac.in
 8378  gcloud config set project outreach-default
 8379  npm run build:prod
 8380  gsutil cp -r build/* gs://outreach.vlabs.ac.in
 8381  git status
 8382  git add .
 8383  git commit -m "added cosmetic change"
 8384  git push -u origin dev
 8385  curl \n
 8386  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'\n\n\n\n\n\n\n
 8387  curl -X 'GET' \\n  'http://34.123.225.18/api/library/a45596ed-f158-4998-b140-c73a8650a130' \\n  -H 'accept: application/json' \\n  -H 'Authorization: Bearer bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IkRMeG9MZ0RjN2NYS0taNWViaHpQRSJ9.eyJpc3MiOiJodHRwczovL2Rldi1zbXNycm1iZXlxZ24yZDEwLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2NjNiNTJmMWI1NTc2MmY1ZjU0Y2M3MGIiLCJhdWQiOiJodHRwczovL3N1YnRsLXdlYi1hcGkiLCJpYXQiOjE3MTUyMjQ1MTUsImV4cCI6MTcxNTMxMDkxNSwiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJlNnB1NURDb0hRWTgzYmJNZlhQVmRtMHdJa3JPa1RISyJ9.YuzAgl4uetp0lRaokjkGbrjB1PD5HHT4Hh8EI6hBHOPEVdsbLRWGnddHTjqXktbN7MacBeHNtXKO35htxD9TgFBQwRMppOVvj6R3n0reiYiQ5awP8tEK5GeV-5o5Kqes78DA8S0xH0NXgc7fg5ViR_l178Fh_UCByMbsTQMUk7EUkTggHHb9w7mX5YCBTa6MAwLI6uCWsOnFHJ7-nfsrFF8QGzlfdQqxbJBQuPkAJXFrJtDPcDd8iLi3dkt6MFZM-GrfALea1-ZWqFb_fKaLpLUFRKyrpNtK74IiRIauRKoPG19FhsrEbUtC3iqzfgSlL9DqEm-lYguG6PAvIPs7eQ'
 8388  code .
 8389  cd backend; npm start
 8390  cd frontend; npm start
 8391  cd backend; npm start
 8392  cd backend;
 8393  gcloud config set project outreach-default
 8394  gcloud app deploy
 8395  cd backend;
 8396  cd ../frontend
 8397  npm run build:prod
 8398  gsutil cp -r build/* gs://outreach.vlabs.ac.in
 8399  git checkout subtl-api-temp\n\n\n\n\n\n
 8400  git pull
 8401  yarn dev
 8402  code .
 8403  make
 8404  ./make
 8405  ./main
 8406  code .
 8407  htop
 8408  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 8409  code .
 8410  clear
 8411  npm start
 8412  clear
 8413  npm start
 8414  git add .
 8415  git commit -m "added changes"
 8416  git push -u origin dev
 8417  npm install react-markdown\n
 8418  npm i remark-gfm
 8419  npm i @uiw/react-markdown-preview
 8420  clear
 8421  gcloud app deploy
 8422  clear
 8423  npm run build:prod
 8424  gsutil cp -r build/* gs://outreach.vlabs.ac.in
 8425  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=testuser2@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 8426  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 8427  code .
 8428  npm i @uiw/react-markdown-preview
 8429  npm i @uiw/react-markdown-preview -f
 8430  npm start
 8431  git status
 8432  git add .
 8433  git commit -m "added changes"
 8434  git push -u origin dev
 8435  gcloud config set project lab-deployment-414310
 8436  gcloud app deploy
 8437  clear
 8438  npm run build:prod
 8439  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 8440  git status
 8441  git add .
 8442  git commit -m "added ui changes and help"
 8443  git push -u origin new_branch
 8444  cd ..
 8445  git status
 8446  git add .
 8447  git commit -m "added ui changes and help"
 8448  git push -u origin new_branch
 8449  npm start
 8450  cd frontend;
 8451  ls
 8452  npm run build:prod
 8453  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 8454  npm run build:prod
 8455  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 8456  npm start
 8457  npm run build:prod
 8458  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 8459  npm run build:prod
 8460  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 8461  cd ..
 8462  git add .
 8463  git commit -m "added redirection"
 8464  git push -u origin new_branch
 8465  gsutil cp -r build/* gs://deploy.vlabs.ac.in
 8466  code .
 8467  git pull
 8468  cd backend; npm start
 8469  cd frontend; npm start
 8470  npm i; npm start
 8471  code .
 8472  git pull
 8473  clear
 8474  cd frontend; npm start
 8475  cd backend; npm start
 8476  git add .
 8477  git commit -m "added help doc"
 8478  git push -u origin dev
 8479  git add .
 8480  git commit -m "updated help doc"
 8481  git push -u origin dev
 8482  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 8483  code .
 8484  python -m venv venv\n
 8485  touch server.py
 8486  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
 8487  source venv/bin/activate
 8488  pip install fastapi
 8489  pip install uvicorn
 8490  uvicorn server:app\n
 8491  uvicorn server:app --reload\n
 8492  curl -fsSL https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo apt-key add -
 8493  echo "deb https://artifacts.elastic.co/packages/7.x/apt stable main" | sudo tee -a /etc/apt/sources.list.d/elastic-7.x.list
 8494  sudo apt update
 8495  sudo apt install elasticsearch
 8496  wget https://download.elastic.co/elasticsearch/release/org/elasticsearch/distribution/deb/elasticsearch/2.3.1/elasticsearch-2.3.1.deb\n\n
 8497  sudo dpkg -i elasticsearch-2.3.1.deb\n
 8498  sudo systemctl enable elasticsearch.service\n
 8499  sudo nano /etc/elasticsearch/elasticsearch.yml\n
 8500  sudo systemctl restart elasticsearch\n
 8501  curl -X GET 'http://localhost:9200'
 8502  sudo systemctl status elasticsearch
 8503  java -version
 8504  sudo nano /etc/elasticsearch/elasticsearch.yml\n
 8505  journalctl -xe\n
 8506  htop
 8507  sudo systemctl stop elasticsearch
 8508  sudo systemctl status elasticsearch
 8509  sudo systemctl stop elasticsearch
 8510  sudo apt uninstall elasticsearch
 8511  sudo apt remove elasticsearch
 8512  sudo systemctl status elasticsearch
 8513  sudo systemctl delete elasticsearch
 8514  sudo systemctl remove elasticsearch
 8515  sudo systemctl kill elasticsearch
 8516  sudo systemctl status elasticsearch
 8517  wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
 8518  sudo apt-get install apt-transport-https
 8519  echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list
 8520  sudo apt-get update && sudo apt-get install elasticsearch
 8521  sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 8DD48989F43719CA
 8522  sudo gpg --keyserver pgpkeys.mit.edu --recv-key 8DD48989F43719CA
 8523  sudo apt-get update && sudo apt-get install elasticsearch
 8524  wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
 8525  echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list
 8526  sudo apt-get update && sudo apt-get install elasticsearch
 8527  wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
 8528  sudo apt-get install apt-transport-https
 8529  echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list
 8530  sudo apt-get update && sudo apt-get install elasticsearch
 8531  tee
 8532  curl -X GET 'https://5eab20ef80a746f1b2e9b6baec302809.us-central1.gcp.cloud.es.io:443'
 8533  curl -X GET 'http://localhost:9200'
 8534  curl -X GET 'c465bc7e0cfd4b91afada580a8933e54:dXMtY2VudHJhbDEuZ2NwLmNsb3VkLmVzLmlvJDVlYWIyMGVmODBhNzQ2ZjFiMmU5YjZiYWVjMzAyODA5JDUxYWJlZDYyZTMzZjQ5Y2Q4MDk1NTBhMzdmZTU5ZjMy'
 8535  apt-get install curl apt-transport-https\ncurl -s https://artifacts.elastic.co/GPG-KEY-... | apt-key add -\necho "deb https://artifacts.elastic.co/packages... stable main" | tee /etc/apt/sources.list.d/elastic-7.x.list\napt-get update\n\napt-get install elasticsearch=7.7.1
 8536  sudo apt-get install curl apt-transport-https\ncurl -s https://artifacts.elastic.co/GPG-KEY-... | apt-key add -\necho "deb https://artifacts.elastic.co/packages... stable main" | tee /etc/apt/sources.list.d/elastic-7.x.list\napt-get update\n\napt-get install elasticsearch=7.7.1
 8537  sudo apt-get install curl apt-transport-https
 8538  sudo curl -s https://artifacts.elastic.co/GPG-KEY-... | apt-key add -\n
 8539  sudo curl -s https://artifacts.elastic.co/GPG-KEY-... | sudo apt-key add -\n
 8540  echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/8.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-8.x.list
 8541  sudo apt-get update && sudo apt-get install elasticsearch
 8542  sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 0686B78420038257\n
 8543  sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys D27D666CD88E42B4\n
 8544  sudo apt update --allow-unauthenticated\n
 8545  sudo apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 8DD48989F43719CA\n
 8546  sudo apt-key adv --keyserver hkp://pool.sks-keyservers.net --recv-keys 8DD48989F43719CA\n
 8547  sudo apt remove proton-vpn
 8548  source venv/bin/activate
 8549  python -m pip install elasticsearch\n
 8550  python -u "/media/chirag/DATA5/sprinklr/mini-project/main.py"
 8551  source venv/bin/activate
 8552  pip install python-dotenv\n
 8553  python -u "/media/chirag/DATA5/sprinklr/mini-project/main.py"
 8554  python -u "/media/chirag/DATA5/sprinklr/mini-project/test.py"
 8555  python install elasticsearch
 8556  python i elasticsearch
 8557  pip install elasticsearch
 8558  uvicorn server:app --reload\n
 8559  source venv/bin/activate
 8560  pip install elasticsearch
 8561  uvicorn server:app --reload\n
 8562  git init\ngit add README.md\ngit commit -m "first commit"\ngit branch -M main\ngit remote add origin https://github.com/chir263/es-mini-proj.git\n
 8563  git status
 8564  git add .
 8565  git commit -m "first commit"
 8566  git push -u origin master
 8567  code .
 8568  git pull
 8569  cd frontend; npm start
 8570  cd backend; npm start
 8571  gcloud topic startup
 8572  git status
 8573  git add .
 8574  git commit -m "updated deployment instructions"
 8575  git push -u origin dev
 8576  sudo docker system prune -f
 8577  git pull
 8578  code .
 8579  git pull
 8580  cd frontend; npm start
 8581  cd backend; npm start
 8582  npm i; npm start
 8583  code .
 8584  history  > his.txt
 8585  gcloud app logs tail
 8586  clear
 8587  npm start
 8588  clear
 8589  npm start
 8590  npm run start:prod
 8591  gcloud config set project outreach-default
 8592  gcloud app logs tail
 8593  gcloud app deploy
 8594  gcloud config set project outreach-default
 8595  npm run start:prod
 8596  gcloud app deploy
 8597  gcloud app logs tail
 8598  git add .
 8599  git commit -m "fixed a minor bug"
 8600  git push -u origin dev
 8601  npm run build:prod
 8602  gsutil cp -r build/* gs://outreach.vlabs.ac.in
 8603  code .
 8604  git pull
 8605  git stash
 8606  git pull
 8607  clear
 8608  npm start
 8609  clear
 8610  npm start
 8611  npm init
 8612  code .
 8613  cd backend; npm i
 8614  clear
 8615  npm start
 8616  cd backend; npm install winston\n
 8617  sudo apt install redis-server
 8618  nano /etc/redis/redis.conf\n\n
 8619  sudo nano /etc/redis/redis.conf\n\n
 8620  sudo systemctl restart redis.service
 8621  sudo systemctl status redis\n\n
 8622  sudo docker ps
 8623  sudo docker stop subtl_doc_parser-redis-queue-1
 8624  sudo docker ps
 8625  sudo systemctl status redis\n\n
 8626  sudo systemctl restart redis.service
 8627  sudo systemctl status redis\n\n
 8628  redis-cli
 8629  npm install axios cheerio bull ioredis\n
 8630  redis-cli
 8631  clear
 8632  npm start
 8633  clear
 8634  npm start
 8635  clear
 8636  npm start
 8637  clear
 8638  npm start
 8639  git iniy
 8640  git init
 8641  ls
 8642  code .gitignore
 8643  git stash
 8644  git status
 8645  git add .
 8646  git commit -m "first commit"
 8647  git remote add origin https://github.com/chir263/sprinklr-inter-proj.git
 8648  git push -u origin master
 8649  clear
 8650  git status
 8651  git add .
 8652  git commit -m "added crawling functionality"
 8653  git push -u origin master
 8654  sudo docker system prune -f
 8655  cat .env > xx
 8656  code .
 8657  cd backend;
 8658  source venv/bin/activate
 8659  python server.py
 8660  cd frontend; npm start
 8661  git status
 8662  git add .
 8663  git commit -m "added README"
 8664  git push -u origin main
 8665  code .
 8666  git pull
 8667  git status
 8668  git pull
 8669  npm start
 8670  git log
 8671  git pull
 8672  git add .
 8673  git commit -m "fixed minor bug"
 8674  git push -u origin dev
 8675  git origin\n
 8676  git remote\n
 8677  git remote origin\n
 8678  code .\n
 8679  git pull
 8680  git logs
 8681  git log
 8682  git add .
 8683  git commit -m "added README.md"
 8684  git push -u origin dev
 8685  npm start
 8686  source venv/bin/activate
 8687  python server.py
 8688  git add .
 8689  git commit -m "updated README.md"
 8690  git push -u origin dev
 8691  wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.13.4-linux-x86_64.tar.gz\nwget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.13.4-linux-x86_64.tar.gz.sha512\nshasum -a 512 -c elasticsearch-8.13.4-linux-x86_64.tar.gz.sha512 \ntar -xzf elasticsearch-8.13.4-linux-x86_64.tar.gz\ncd elasticsearch-8.13.4/
 8692  ld
 8693  ls
 8694  rm elasticsearch-8.13.4-linux-x86_64.tar.gz
 8695  ls
 8696  wget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.13.4-linux-x86_64.tar.gz\nwget https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-8.13.4-linux-x86_64.tar.gz.sha512\nshasum -a 512 -c elasticsearch-8.13.4-linux-x86_64.tar.gz.sha512 \ntar -xzf elasticsearch-8.13.4-linux-x86_64.tar.gz\ncd elasticsearch-8.13.4/
 8697  ls
 8698  ./bin/elasticsearch
 8699  touch es.password
 8700  curl -X GET "localhost:9200/"\n
 8701  curl -X GET "https://localhost:9200/" -u "elastic:i4d7mnhr*e2Od9A*DIuo"\n
 8702  ./bin/elasticsearch
 8703  curl -X GET "https://localhost:9200/" -u "elastic:i4d7mnhr*e2Od9A*DIuo"\n
 8704  curl -X GET "http://localhost:9200/" -u "elastic:i4d7mnhr*e2Od9A*DIuo"\n
 8705  cd ../
 8706  cd kibana-8.13.4-linux-x86_64
 8707  ls
 8708  cd kibana-8.13.4
 8709  ls
 8710  ./bin/kibana
 8711  curl -X GET "http://localhost:9200/" -u "elastic:i4d7mnhr*e2Od9A*DIuo"\n
 8712  code .\n
 8713  git clone https://github.com/chir263/sprinklr-inter-proj.git
 8714  cd sprinklr-inter-proj
 8715  ls
 8716  cd backend;
 8717  npm i
 8718  cd frontend; npm i -f
 8719  cd sprinklr-inter-proj/frontend
 8720  npm i
 8721  npm i -f
 8722  code .
 8723  cd frontend; npm start
 8724  npm i
 8725  npm i -f
 8726  cd backend;
 8727  ls
 8728  htop
 8729  gedit .env
 8730  sudo apt install redis
 8731  redis-cli --version
 8732  sudo systemctl status redis
 8733  redis-cli
 8734  npm start
 8735  code .
 8736  npm start
 8737  code .
 8738  npm start
 8739  npm i - f
 8740  npm i -f
 8741  npm start
 8742  rm -rf node_modules\nnpm install\n
 8743  rm -rf node_modules\nnpm install -f\n
 8744  npm start
 8745  Dockerfile
 8746  touch Dockerfile
 8747  code Dockerfile
 8748  touch docker-compose.yaml
 8749  sudo docker-compose up --build\n
 8750  sudo dockercompose up --build\n
 8751  sudo docker compose up --build\n
 8752  htop
 8753  code .
 8754  sudo docker compose up --build\n
 8755  htop
 8756  code .
 8757  git status
 8758  git add .
 8759  git commit -m "added dockerfile"
 8760  git push -u origin master
 8761  ./bin/elasticsearch
 8762  cd ..
 8763  cd kibana-8.13.4-linux-x86_64
 8764  cd kibana-8.13.4
 8765  ./bin/kibana
 8766  redis-cli
 8767  htop
 8768  sudo docker compose up --build\n
 8769  sudo docker system prune -f
 8770  sudo docker compose up --build\n
 8771  sudo docker ps
 8772  htop
 8773  code .
 8774  git pull
 8775  git status
 8776  git p
 8777  git pull
 8778  code .
 8779  git pull
 8780  npm i
 8781  npm i -f
 8782  sudo docker compose up --build\n
 8783  sudo docker compose up --force-rebuild\n
 8784  sudo docker compose up \n
 8785  sudo docker compose up --build\n
 8786  docker-compose build --no-cache\n
 8787  sudo docker compose build --no-cache\n
 8788  sudo docker compose up\n
 8789  sudo docker ps
 8790  sudo docker exec -it sprinklr-inter-proj-frontend-1 /bin/bash\n
 8791  npm --version
 8792  node --version
 8793  sudo docker compose up --build\n
 8794  sudo docker system prune -f
 8795  sudo docker compose up --build\n
 8796  ./bin/elasticsearch
 8797  htop
 8798  ./bin/kibana
 8799  git pull
 8800  code .
 8801  git pull
 8802  cd frontend; 
 8803  npm run build:prod
 8804  npm i
 8805  npm run build:prod
 8806  code .
 8807  clear
 8808  npm i
 8809  sudo docker ps
 8810  sudo docker stop ^[[200~sprinklr-inter-proj-frontend-1~
 8811  sudo docker stop sprinklr-inter-proj-frontend-1
 8812  npm i
 8813  npm i -f
 8814  sudo npm i -f
 8815  npm run build:prod
 8816  sudo npm run build:prod
 8817  code .
 8818  clear
 8819  cd project
 8820  ls
 8821  npm start
 8822  npm install
 8823  npm i
 8824  npm start
 8825  sudo docker stop sprinklr-inter-proj-backend-1
 8826  make it above 16
 8827  npm start
 8828  cd project/react-app
 8829  ls
 8830  npm start
 8831  cd project/react-app
 8832  npm run build:prod
 8833  sudo npm run build:prod
 8834  sudo docker system prune -f
 8835  sudo npm run build:prod
 8836  git add .
 8837  git commit -m "changed format"
 8838  git push -u origin master
 8839  ls
 8840  clear
 8841  sudo docker build -t nodejs-app .\n
 8842  sudo docker images
 8843  docker run --name my-nodejs-app -p 3000:3000 nodejs-app\n
 8844  sudo docker run --name my-nodejs-app -p 3000:3000 nodejs-app\n
 8845  sudo docker ps
 8846  sudo docker stop my-nodejs-app
 8847  sudo docker run --name my-nodejs-app -p 5005:5005 nodejs-app\n
 8848  sudo docker ps
 8849  sudo docker run --name my-nodejs-app -p 5005:5005 nodejs-app\n
 8850  sudo docker run --name my-nodejs-app-1 -p 5005:5005 nodejs-app\n
 8851  clear
 8852  sudo docke rps
 8853  sudo docke ps
 8854  sudo docker ps
 8855  sudo docker stop my-nodejs-app-1
 8856  clear
 8857  sudo docker system prune -f
 8858  sudo docker ima
 8859  sudo docker images
 8860  sudo docker stop $(sudo docker ps -a -q)\n
 8861  sudo docker rm $(sudo docker ps -a -q)\n
 8862  sudo docker ps
 8863  sudo docker images
 8864  sudo docker image prune\n
 8865  sudo docker volume prune\n
 8866  sudo docker rm -vf $(sudo docker ps -aq)\ndocker volume prune\n
 8867  sudo docker rm -vf $(sudo docker ps -aq)\nsudo docker volume prune\n
 8868  sudo docker rmi -f $(sudo docker images -aq)\n
 8869  sudo docker rmi -f $(sudo docker images -aq) -f\n
 8870  sudo docker images
 8871  sudo docker volume prune -f\n
 8872  df -h\n
 8873  sudo docker system df\n
 8874  sudo docker builder prune -a -f
 8875  sudo docker system df\n
 8876  sudo docker volume prune -f\n
 8877  sudo docker volume ls\n
 8878  sudo docker volume rm $(sudo docker volume ls)
 8879  docker --version
 8880  clear
 8881  git status
 8882  git pull
 8883  git stash
 8884  git pull
 8885  clear
 8886  npm run build:prod
 8887  sudo npm run build:prod
 8888  cd project
 8889  clear
 8890  ls
 8891  sudo docker build -t nodejs-app .
 8892  sudo docker run --name my-nodejs-app -p 5005:5005 nodejs-app\n
 8893  sudo docker ps
 8894  sudo docker stop my-nodejs-app
 8895  sudo docker run --name my-nodejs-app-1 -p 5005:5005 nodejs-app\n
 8896  sudo docker stop my-nodejs-app
 8897  sudo docker stop my-nodejs-app-1
 8898  code .
 8899  ls
 8900  git pull
 8901  git stash
 8902  git pull
 8903  ls
 8904  sudo rm -rf project
 8905  npm i
 8906  cd web-app
 8907  npm i
 8908  npm start
 8909  cd web-app/react-app
 8910  npm i
 8911  npm start
 8912  npm run build:prod
 8913  clear
 8914  sudo docker run --name my-nodejs-app-1 -p 5005:5005 nodejs-app\n
 8915  sudo docker ps
 8916  sudo docker images
 8917  npm start
 8918  code .
 8919  git pull
 8920  git stash
 8921  git pull
 8922  clear
 8923  cd web-app/re
 8924  cd web-app/react-app
 8925  ls
 8926  npm i
 8927  npm run build:prod
 8928  npm start
 8929  npm i; npm start
 8930  cd web-app/react-app
 8931  cd ..
 8932  npm i; npm start
 8933  ls
 8934  cd web-app
 8935  sudo docker build -t learn-platform .
 8936  sudo docker run --name learn-platform-1 -p 5005:5005 learn-platform\n
 8937  sudo docker stop learn-platform-1
 8938  git stash
 8939  ^[[200~git stash pop
 8940  git stash pop
 8941  git status
 8942  git add .
 8943  git commit -m "updated dockerfile"
 8944  git push -u origin master
 8945  git stash 
 8946  git pull
 8947  clear
 8948  code .
 8949  df
 8950  sudo docker ps
 8951  sudo docker images
 8952  sudo docker rmi -f $(sudo docker images -aq) -f\n
 8953  sudo docker rmi -f $(sudo docker images -aq)
 8954  sudo docker images
 8955  sudo docker ps
 8956  code .
 8957  cp .env x.env
 8958  code .
 8959  npm start
 8960  npm i; npm start
 8961  source venv/bin/activate
 8962  python server.py
 8963  code .
 8964  ls
 8965  clear
 8966  git checkout subtl-api-temp\n\n\n\n\n\n
 8967  git pull
 8968  clear
 8969  sudo docker ps
 8970  cd subtl_frontend
 8971  yarn i; yarn start
 8972  yarn install; yarn dev
 8973  sudo ./run.sh -d -- up --build -d api_v2
 8974  sudo ./run.sh logs --tail 1000 -f api_v2
 8975  sudo ./run.sh -d -- up --build -d --no-deps nginx 
 8976  lsof -i :80
 8977  sudo kill -9 $(sudo lsof -t -i:80)\n
 8978  sudo ./run.sh -d -- up --build -d --no-deps nginx 
 8979  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF
 8980  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF\n\n\n\n\n\n\n\n\n
 8981  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF;
 8982  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 8983  code .
 8984  git branch 
 8985  git pull
 8986  docker ps -a
 8987  sudo docker ps -a
 8988  sudo docker system prune -f
 8989  sudo docker ps -a
 8990  sudo ./run.sh -d -- up --build -d nginx api_v2
 8991  sudo ^[[200~docker network create traefik-public~
 8992  sudo docker network create traefik-public~
 8993  sudo ./run.sh -d -- up --build -d nginx api_v2
 8994  docker volume create subtl_bot_minio-data
 8995  sudo docker volume create subtl_bot_minio-data
 8996  sudo ./run.sh -d -- up --build -d nginx api_v2
 8997  sudo docker network ls\n
 8998  docker network create traefik-public\n
 8999  sudo docker network create traefik-public\n
 9000  sudo ./run.sh -d -- up --build -d nginx api_v2
 9001  sudo kill -9 $(sudo lsof -t -i:80)\n
 9002  sudo ./run.sh -d -- up --build -d nginx api_v2
 9003  sudo kill -9 $(sudo lsof -t -i:80)\n
 9004  sudo ./run.sh -d -- up --build -d nginx 
 9005  sudo ./run.sh -d -- up --build -d --no-deps nginx 
 9006  sudo kill -9 $(sudo lsof -t -i:80)\n
 9007  sudo ./run.sh -d -- up --build -d --no-deps nginx 
 9008  sudo docker ps
 9009  sudo ./run.sh -d -- up --build -d api_v2
 9010  sudo ./run.sh -d -- up --build -d --no-deps nginx 
 9011  netstat -ano -p tcp |find "80"
 9012  sudo netstat -ano -p tcp |find "80"
 9013  lsof -i :80\n
 9014  sudo lsof -i :80
 9015  sudo systemctl stop apache2
 9016  sudo lsof -i :80
 9017  sudo ./run.sh -d -- up --build -d --no-deps nginx 
 9018  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9019  cd subtl_frontend
 9020  yarn dev
 9021  sudo ./run.sh logs --tail 1000 -f api_v2
 9022  sudo docke rps
 9023  sudo docke ps
 9024  sudo docker ps
 9025  sudo ./run.sh restart subtl_bot-api_v2-1
 9026  sudo docker restart subtl_bot-api_v2-1
 9027  sudo ./run.sh logs --tail 1000 -f api_v2
 9028  sudo docker restart subtl_bot-api_v2-1
 9029  sudo ./run.sh logs --tail 1000 -f api_v2
 9030  yarn dev
 9031  sudo ./run.sh logs --tail 1000 -f api_v2
 9032  git pull
 9033  code .
 9034  cd /
 9035  ls
 9036  pwd
 9037  cd ..
 9038  ls
 9039  cd DATA
 9040  ls
 9041  cd ../DATA1
 9042  ls
 9043  cd ../DATA5
 9044  ls
 9045  sudo docker ps
 9046  sudo docker images
 9047  code .
 9048  git branch 
 9049  git pull
 9050  sudo docker ps
 9051  sudo docker restart subtl_bot-api_v2-1
 9052  sudo ./run.sh -d -- up --build -d --no-deps nginx 
 9053  lsof -i :80\n
 9054  kill -9 4932
 9055  lsof -i :80\n
 9056  sudo ./run.sh -d -- up --build -d --no-deps nginx 
 9057  sudo systemctl stop apache2
 9058  sudo ./run.sh -d -- up --build -d --no-deps nginx 
 9059  sudo docker restart subtl_bot-api_v2-1
 9060  sudo ./run.sh logs --tail 1000 -f api_v2
 9061  sudo ./run.sh -d -- up --build -d api_v2
 9062  sudo ./run.sh logs --tail 1000 -f api_v2
 9063  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9064  git branch 
 9065  sudo ./run.sh logs --tail 1000 -f api_v2
 9066  git pull
 9067  git branch 
 9068  git checkout subtl-frontend
 9069  cd subtl_frontend
 9070  yarn dev
 9071  node
 9072  code .
 9073  cat ~/.ssh/config
 9074  ssh -i ~/.ssh/gcloud.pem subtlbot@35.225.237.229\n
 9075  ssh -i ~/.ssh/gcloud.pem pranav@35.193.52.196\n
 9076  ssh -i ~/.ssh/gcloud.pem subtlbot@34.173.7.239\n\n
 9077  code .
 9078  sudo docker ps
 9079  sudo ./run.sh logs --tail 1000 -f api_v2
 9080  git pull
 9081  git branch 
 9082  cd subtl_frontend
 9083  yarn dev
 9084  sudo docker restart subtl_bot-api_v2-1
 9085  sudo ./run.sh logs --tail 1000 -f api_v2
 9086  git stash 
 9087  git status
 9088  git branch 
 9089  git pull
 9090  sudo docker ps
 9091  sudo docker restart subtl_bot-api_v2-1
 9092  sudo ./run.sh logs --tail 1000 -f api_v2
 9093  sudo docker restart subtl_bot-api_v2-1
 9094  sudo ./run.sh logs --tail 1000 -f api_v2
 9095  sudo ./run.sh -d -- up --build -d api_v2
 9096  sudo ./run.sh logs --tail 1000 -f api_v2
 9097  sudo ./run.sh -d -- up --build -d --force-recreate api_v2
 9098  sudo ./run.sh logs --tail 1000 -f api_v2
 9099  sudo docker ps
 9100  sudo docker rm -f $(sudo docker ps -aq)\n
 9101  sudo docker ps
 9102  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9103  sudo ./run.sh logs --tail 1000 -f api_v2
 9104  git status
 9105  git branch 
 9106  git checkout subtl-api-v2
 9107  git pull
 9108  yarn install
 9109  yarn dev
 9110  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9111  sudo ./run.sh logs --tail 1000 -f api_v2
 9112  git branch 
 9113  git pull
 9114  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9115  sudo ./run.sh logs --tail 1000 -f api_v2
 9116  docker ps
 9117  sudo docker ps
 9118  sudo ./run.sh logs --tail 1000 -f subtl_bot-api_v2-1
 9119  sudo docker logs -df subtl_bot-api_v2-1
 9120  sudo docker logs -d subtl_bot-api_v2-1
 9121  sudo docker logs -df
 9122  sudo docker logs df
 9123  sudo ./run.sh logs --tail 1000 -f api_v2
 9124  sudo docker ps
 9125  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9126  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9127  sudo docker ps
 9128  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9129  sudo ./run.sh logs --tail 1000 -f api_v2
 9130  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9131  sudo ./run.sh logs --tail 1000 -f api_v2
 9132  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9133  sudo ./run.sh logs --tail 1000 -f api_v2
 9134  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9135  sudo ./run.sh logs --tail 1000 -f api_v2
 9136  sudo docker system prune -f
 9137  dpkg -l | grep -i docker\n
 9138  sudo apt-get purge -y docker-engine docker docker.io docker-ce docker-ce-cli docker-compose-plugin\nsudo apt-get autoremove -y --purge docker-engine docker docker.io docker-ce docker-compose-plugin\n
 9139  sudo rm -rf /var/lib/docker /etc/docker\nsudo rm /etc/apparmor.d/docker\nsudo groupdel docker\nsudo rm -rf /var/run/docker.sock\nsudo rm -rf /var/lib/containerd\nsudo rm -r ~/.docker
 9140  sudo install docker.io
 9141  sudo apt-get install docker.io
 9142  sudo systemctl status docker\n
 9143  docker --version
 9144  history  > his.txt
 9145  sudo apt-get install docker-compose-plugin
 9146  docker compose version
 9147  docker --version
 9148  docker ps
 9149  ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9150  docker network create traefik-public
 9151  docker volume create subtl_bot_minio-data\n
 9152  ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9153  docker ps
 9154  ./run.sh logs --tail 1000 -f api_v2
 9155  docker ps
 9156  docker restart subtl_bot-api_v2-1
 9157  ./run.sh logs --tail 1000 -f api_v2
 9158  docker restart subtl_bot-api_v2-1
 9159  ./run.sh logs --tail 1000 -f api_v2
 9160  docker restart subtl_bot-api_v2-1
 9161  ./run.sh logs --tail 1000 -f api_v2
 9162  ./run.sh -d -- up --build -d --force-recreate api_v2 
 9163  ./run.sh logs --tail 1000 -f api_v2
 9164  ./run.sh -d -- up --build -d --force-recreate api_v2 
 9165  ./run.sh logs --tail 1000 -f api_v2
 9166  ./run.sh -d -- up --build -d --force-recreate api_v2 
 9167  ./run.sh logs --tail 1000 -f api_v2
 9168  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9169  docker ps
 9170  docker exec -it subtl_bot-api_v2-1 /bin/sh\n
 9171  docker exec -it subtl_bot-api_v2-1 /bin/bask\n
 9172  docker exec -it subtl_bot-api_v2-1 /bin/bash\n
 9173  git status
 9174  git add .
 9175  git commit -m "created subscription, payment and workspacesubscription"
 9176  /bin/python3.9
 9177  clear
 9178  git status
 9179  git add .
 9180  git commit -m "created check wrapper for workspace creation"
 9181  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9182  git add .
 9183  git commit -m "added custom exceptions"
 9184  code .
 9185  ./run.sh -d -- up --build -d --force-recreate api_v2 
 9186  docker ps
 9187  docker restart subtl_bot-api_v2-1
 9188  ./run.sh -d -- up --build -d --force-recreate api_v2 
 9189  ./run.sh logs --tail 1000 -f api_v2
 9190  docker exec -it subtl_bot-api_v2-1 /bin/bash\n
 9191  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9192  python
 9193  git add .
 9194  git commit -m "cached daily stats"
 9195  git push -u origin subtl-api-v2
 9196  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9197  docker ps
 9198  docker restart subtl_bot-api_v2-1
 9199  ./run.sh logs --tail 1000 -f api_v2
 9200  htop
 9201  yarn dev
 9202  docker restart subtl_bot-api_v2-1
 9203  htop
 9204  ./run.sh logs --tail 1000 -f api_v2
 9205  htop
 9206  code .
 9207  pip install pydantic
 9208  python -u "/media/chirag/DATA7/enterpret/main.py"
 9209  clear
 9210  python -u "/media/chirag/DATA7/enterpret/main.py"
 9211  python -u "/media/chirag/DATA7/enterpret/main2.py"
 9212  python -u "/media/chirag/DATA7/enterpret/main.py"
 9213  python -u "/media/chirag/DATA7/enterpret/main2.py"
 9214  code .
 9215  python -u "/media/chirag/DATA8/enterpret/main.py"
 9216  python -u "/media/chirag/DATA8/enterpret/main2.py"
 9217  echo "# in-memory-cache" >> README.md\ngit init\ngit add README.md\ngit commit -m "first commit"\ngit branch -M main\ngit remote add origin https://github.com/chir263/in-memory-cache.git\ngit push -u origin main
 9218  git add .
 9219  git commit -m "first commit"
 9220  git push -u origin main
 9221  code .
 9222  cd "/media/chirag/DATA8/CODE_AMA/CP/cppp/" && g++ 1671D.cpp -o 1671D && "/media/chirag/DATA8/CODE_AMA/CP/cppp/"1671D
 9223  code .
 9224  python -u "/media/chirag/DATA8/enterpret/main2.py"
 9225  git status
 9226  git add .
 9227  git commit -m "optimized LFU"
 9228  git push -u origin main
 9229  code .
 9230  ld
 9231  ls
 9232  cd subtl_frontend
 9233  yarn add zustand
 9234  docker ps
 9235  sudo docker ps
 9236  sudo docker restart subtl_bot-api_v2-1
 9237  sudo docker ps
 9238  sudo ./run.sh logs --tail 1000 -f api_v2
 9239  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9240  sudo docker system prune -f
 9241  sudo docker network create traefik-public\n
 9242  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9243  lsof -i :80\n
 9244  sudo lsof -i :80\n
 9245  sudo systemctl stop apache2
 9246  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9247  yarn dev
 9248  sudo ./run.sh logs --tail 1000 -f api_v2
 9249  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9250  sudo docker restart subtl_bot-api_v2-1
 9251  sudo ./run.sh logs --tail 1000 -f api_v2
 9252  sudo ./run.sh logs --tail 1000 -f nginx
 9253  sudo docker restart subtl_bot-api_v2-1
 9254  sudo ./run.sh logs --tail 1000 -f api_v2
 9255  sudo docker restart subtl_bot-api_v2-1
 9256  sudo ./run.sh logs --tail 1000 -f api_v2
 9257  htop
 9258  code .
 9259  htop
 9260  yarn dev
 9261  sudo ./run.sh logs --tail 1000 -f api_v2
 9262  git status
 9263  git add .
 9264  git commit -m "added question progressbar"
 9265  code .
 9266  yarn add razorpay
 9267  yarn dev
 9268  clear
 9269  sudo docker ps
 9270  sudo ./run.sh logs --tail 1000 -f api_v2
 9271  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9272  sudo ./run.sh exec api_v2 bash\n
 9273  code .
 9274  npm i razormay
 9275  npm i razorpay
 9276  code .
 9277  npm i razorpay
 9278  sudo ./run.sh logs --tail 1000 -f api_v2
 9279  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9280  sudo ./run.sh logs --tail 1000 -f api_v2
 9281  sudo ./run.sh exec api_v2 bash\n
 9282  sudo ./run.sh logs --tail 1000 -f api_v2
 9283  sudo docker restart subtl_bot-api_v2-1
 9284  sudo ./run.sh logs --tail 1000 -f api_v2
 9285  clear
 9286  npm start
 9287  sudo docker restart subtl_bot-api_v2-1
 9288  npm start
 9289  sudo ./run.sh logs --tail 1000 -f api_v2
 9290  sudo docker restart subtl_bot-api_v2-1
 9291  sudo ./run.sh logs --tail 1000 -f api_v2
 9292  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9293  sudo ./run.sh logs --tail 1000 -f api_v2
 9294  sudo ./run.sh exec api_v2 bash\n
 9295  sudo docker restart subtl_bot-api_v2-1
 9296  sudo ./run.sh exec api_v2 bash\n
 9297  sudo ./run.sh logs --tail 1000 -f api_v2
 9298  sudo ./run.sh exec api_v2 bash\n
 9299  sudo docker restart subtl_bot-api_v2-1
 9300  sudo ./run.sh logs --tail 1000 -f api_v2
 9301  docker exec -it subtl_bot-api_v2-1 /bin/bash\n
 9302  sudo docker exec -it subtl_bot-api_v2-1 /bin/bash\n
 9303  git status
 9304  git add .
 9305  git commit -m "added delete workspace and payment route"
 9306  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9307  code .
 9308  git branch
 9309  git checkout main
 9310  git pull
 9311  cd backend;
 9312  gcloud auth login\n
 9313  gcloud config set project outreach-default\n
 9314  cd frontend; 
 9315  npm run build:prod
 9316  gcloud app deploy\n
 9317  gsutil cp -r build/* gs://outreach.vlabs.ac.in\n
 9318  history  > his.txt
 9319  gcloud app logs tail -s default
 9320  cd backend;
 9321  npm start
 9322  npm i; npm start
 9323  cd frontend; 
 9324  npm start
 9325  gcloud app deploy\n
 9326  git status
 9327  git add .
 9328  git commit -m "fixed null issue"
 9329  git push -u origin main
 9330  code .
 9331  htop
 9332  sudo docker ps
 9333  sudo docker restart subtl_bot-api_v2-1
 9334  sudo ./run.sh logs --tail 1000 -f api_v2
 9335  sudo docker restart subtl_bot-api_v2-1
 9336  sudo ./run.sh logs --tail 1000 -f api_v2
 9337  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9338  sudo systemctl stop apache2
 9339  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9340  sudo ./run.sh logs --tail 1000 -f api_v2
 9341  sudo docker exec -it subtl_bot-api_v2-1 /bin/bash\n
 9342  sudo docker restart subtl_bot-api_v2-1
 9343  sudo ./run.sh logs --tail 1000 -f api_v2
 9344  cd subtl_frontend
 9345  git status
 9346  git branch\n
 9347  git checkout -b subtl-payment-integration\n
 9348  git log
 9349  git add .
 9350  git commit -m "making subscription flow"
 9351  git push -u origin subtl-payment-integration\n
 9352  git fetch origin\ngit merge origin/snackbar-integration\n
 9353  git status
 9354  git log
 9355  yarn dev
 9356  cd ..
 9357  ls
 9358  git status
 9359  cd subtl_frontend
 9360  yarn dev
 9361  yarn install
 9362  yarn dev
 9363  sudo ./run.sh logs --tail 1000 -f api_v2
 9364  yarn dev
 9365  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9366  sudo docker restart subtl_bot-api_v2-1
 9367  sudo ./run.sh logs --tail 1000 -f api_v2
 9368  sudo docker restart subtl_bot-api_v2-1
 9369  sudo ./run.sh logs --tail 1000 -f api_v2
 9370  yarn dev
 9371  code .
 9372  npm start
 9373  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9374  sudo docker exec -it subtl_bot-api_v2-1 /bin/bash\n
 9375  git status
 9376  git add .
 9377  git commit -m "added basic payment flow"
 9378  git push -u origin subtl-payment-integration\n
 9379  python
 9380  clear
 9381  git status
 9382  from google.oauth2 import service_account\n
 9383  clear
 9384  from
 9385  clear
 9386  sudo ./run.sh logs --tail 1000 -f api_v2
 9387  clear
 9388  yarn dev
 9389  code .
 9390  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9391  code .
 9392  sudo docker restart subtl_bot-api_v2-1
 9393  sudo ./run.sh logs --tail 1000 -f api_v2
 9394  curl 'http://localhost/api_v2/workspace/all' \\n  -H 'Accept-Language: en-GB,en-US;q=0.9,en;q=0.8,hi;q=0.7' \\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IkRMeG9MZ0RjN2NYS0taNWViaHpQRSJ9.eyJpc3MiOiJodHRwczovL2Rldi1zbXNycm1iZXlxZ24yZDEwLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2Njg5MDkyYzY3MWM0MDdlOGE4ZWRiYTciLCJhdWQiOiJodHRwczovL3N1YnRsLXdlYi1hcGkiLCJpYXQiOjE3MjE2NDc4NzIsImV4cCI6MTcyMTczNDI3MiwiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJlNnB1NURDb0hRWTgzYmJNZlhQVmRtMHdJa3JPa1RISyJ9.B7DDOKYjoADQNc6OpDTQroCWrFWD9t0XPNEP1SbtG6c9w7Ts1ZnMUGyOP_eIW5_2pKljiibH-D16QVkloYJa1ks4eVD-4L-nXg2W7mlKrq7qSYEeQ2I0A7_hJQTtk47vN-85unVk6i5G3KEIeQ_osH2vZbtnF4PrtOK6vya60waXiKSzHG-WDxbhaNg89-uSwei9Rj86Obuyb3Hkyky3PCWSaT_GwIYbiSEY8xkUNgI7O2WAKGg65fweCkOCR9rHBtJwONRvviYnVQMW_hMJTCDcQjjCC2DDYxtYJ1psqkgm9r4_lu0VrENNNndQvkVPY_MuAlW1bLxzyJOIGq2u4Q' \\n  -H 'Connection: keep-alive' \\n  -H 'Cookie: g_state={"i_l":0}; _legacy_auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true; auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true' \\n  -H 'Referer: http://localhost/api_v2/docs' \\n  -H 'Sec-Fetch-Dest: empty' \\n  -H 'Sec-Fetch-Mode: cors' \\n  -H 'Sec-Fetch-Site: same-origin' \\n  -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36' \\n  -H 'accept: application/json' \\n  -H 'sec-ch-ua: "Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"' \\n  -H 'sec-ch-ua-mobile: ?0' \\n  -H 'sec-ch-ua-platform: "Linux"' \\n  --compressed
 9395  curl -X 'GET' \\n  'http://localhost/api_v2/workspace/all' \\n  -H 'accept: application/json' \\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IkRMeG9MZ0RjN2NYS0taNWViaHpQRSJ9.eyJpc3MiOiJodHRwczovL2Rldi1zbXNycm1iZXlxZ24yZDEwLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2Njg5MDkyYzY3MWM0MDdlOGE4ZWRiYTciLCJhdWQiOiJodHRwczovL3N1YnRsLXdlYi1hcGkiLCJpYXQiOjE3MjE2NDc4NzIsImV4cCI6MTcyMTczNDI3MiwiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJlNnB1NURDb0hRWTgzYmJNZlhQVmRtMHdJa3JPa1RISyJ9.B7DDOKYjoADQNc6OpDTQroCWrFWD9t0XPNEP1SbtG6c9w7Ts1ZnMUGyOP_eIW5_2pKljiibH-D16QVkloYJa1ks4eVD-4L-nXg2W7mlKrq7qSYEeQ2I0A7_hJQTtk47vN-85unVk6i5G3KEIeQ_osH2vZbtnF4PrtOK6vya60waXiKSzHG-WDxbhaNg89-uSwei9Rj86Obuyb3Hkyky3PCWSaT_GwIYbiSEY8xkUNgI7O2WAKGg65fweCkOCR9rHBtJwONRvviYnVQMW_hMJTCDcQjjCC2DDYxtYJ1psqkgm9r4_lu0VrENNNndQvkVPY_MuAlW1bLxzyJOIGq2u4Q'
 9396  python -u "/media/chirag/DATA9/enterpret/main.py"
 9397  python -u "/media/chirag/DATA9/enterpret/main2.py"
 9398  code .
 9399  git status
 9400  git add .
 9401  git commit -m "added subtl_frontend/src/components/snackbar/SnackbarContext.tsx"
 9402  git push -u origin subtl-payment-integration\n
 9403  curl -X 'GET' \\n  'http://localhost/api_v2/workspace/all' \\n  -H 'accept: application/json' \\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IkRMeG9MZ0RjN2NYS0taNWViaHpQRSJ9.eyJpc3MiOiJodHRwczovL2Rldi1zbXNycm1iZXlxZ24yZDEwLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2Njg5MDkyYzY3MWM0MDdlOGE4ZWRiYTciLCJhdWQiOiJodHRwczovL3N1YnRsLXdlYi1hcGkiLCJpYXQiOjE3MjE2NDc4NzIsImV4cCI6MTcyMTczNDI3MiwiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJlNnB1NURDb0hRWTgzYmJNZlhQVmRtMHdJa3JPa1RISyJ9.B7DDOKYjoADQNc6OpDTQroCWrFWD9t0XPNEP1SbtG6c9w7Ts1ZnMUGyOP_eIW5_2pKljiibH-D16QVkloYJa1ks4eVD-4L-nXg2W7mlKrq7qSYEeQ2I0A7_hJQTtk47vN-85unVk6i5G3KEIeQ_osH2vZbtnF4PrtOK6vya60waXiKSzHG-WDxbhaNg89-uSwei9Rj86Obuyb3Hkyky3PCWSaT_GwIYbiSEY8xkUNgI7O2WAKGg65fweCkOCR9rHBtJwONRvviYnVQMW_hMJTCDcQjjCC2DDYxtYJ1psqkgm9r4_lu0VrENNNndQvkVPY_MuAlW1bLxzyJOIGq2u4Q'
 9404  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9405  code .e
 9406  code .
 9407  npm start
 9408  sudo ./run.sh logs --tail 1000 -f api_v2
 9409  curl 'data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" width="16" height="15" aria-hidden="true"><path fill="%23fff" fill-rule="evenodd" d="M4 12h4v1H4v-1zm5-6H4v1h5V6zm2 3V7l-3 3 3 3v-2h5V9h-5zM6.5 8H4v1h2.5V8zM4 11h2.5v-1H4v1zm9 1h1v2c-.02.28-.11.52-.3.7-.19.18-.42.28-.7.3H3c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h3c0-1.11.89-2 2-2 1.11 0 2 .89 2 2h3c.55 0 1 .45 1 1v5h-1V5H3v9h10v-2zM4 4h8c0-.55-.45-1-1-1h-1c-.55 0-1-.45-1-1s-.45-1-1-1-1 .45-1 1-.45 1-1 1H5c-.55 0-1 .45-1 1z"/></svg>' \\n  -H 'Referer;' \\n  -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36' \\n  --compressed ;\ncurl 'http://localhost/api_v2/workspace/all' \\n  -H 'Accept-Language: en-GB,en-US;q=0.9,en;q=0.8,hi;q=0.7' \\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IkRMeG9MZ0RjN2NYS0taNWViaHpQRSJ9.eyJpc3MiOiJodHRwczovL2Rldi1zbXNycm1iZXlxZ24yZDEwLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2Njg5MDkyYzY3MWM0MDdlOGE4ZWRiYTciLCJhdWQiOiJodHRwczovL3N1YnRsLXdlYi1hcGkiLCJpYXQiOjE3MjE4OTQwODMsImV4cCI6MTcyMTk4MDQ4MywiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJlNnB1NURDb0hRWTgzYmJNZlhQVmRtMHdJa3JPa1RISyJ9.dKaYTv_z8bRK7SHMdbDQguskUQL5CymXqWkTVFYVY7Sz5GadjDtO1raC3IgEuyDmTb5E-HKDbV1NwzFjMpVNPZH6_RRa_Q5ymHnthK85uabqjkotcQYDcvo7wR-jm8HSS3gxBBJH0Ui8FvymkSKl92Erg_7z6eAzR8igjjguz4YT84WQzTwjRNyYmZufZvPvEshEbg6921lIOhkh2ZHLYLvDU93DExGw3WoVdlk887jDo_etbE5hs-N-h7hL7mZ-pKVae4bH7PRPXwQp9_kMLrFbR_cJ1iJyAEPvmiJ4zoaB9UwQRu5IMAv2TdcUhFEjIo3PRmPPz_vwQ2J3tEpb8A' \\n  -H 'Connection: keep-alive' \\n  -H 'Cookie: g_state={"i_l":0}; _legacy_auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true; auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true' \\n  -H 'Referer: http://localhost/api_v2/docs' \\n  -H 'Sec-Fetch-Dest: empty' \\n  -H 'Sec-Fetch-Mode: cors' \\n  -H 'Sec-Fetch-Site: same-origin' \\n  -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36' \\n  -H 'accept: application/json' \\n  -H 'sec-ch-ua: "Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"' \\n  -H 'sec-ch-ua-mobile: ?0' \\n  -H 'sec-ch-ua-platform: "Linux"' \\n  --compressed
 9410  curl 'data:image/svg+xml;charset=utf-8,<svg xmlns="http://www.w3.org/2000/svg" width="16" height="15" aria-hidden="true"><path fill="%23fff" fill-rule="evenodd" d="M4 12h4v1H4v-1zm5-6H4v1h5V6zm2 3V7l-3 3 3 3v-2h5V9h-5zM6.5 8H4v1h2.5V8zM4 11h2.5v-1H4v1zm9 1h1v2c-.02.28-.11.52-.3.7-.19.18-.42.28-.7.3H3c-.55 0-1-.45-1-1V3c0-.55.45-1 1-1h3c0-1.11.89-2 2-2 1.11 0 2 .89 2 2h3c.55 0 1 .45 1 1v5h-1V5H3v9h10v-2zM4 4h8c0-.55-.45-1-1-1h-1c-.55 0-1-.45-1-1s-.45-1-1-1-1 .45-1 1-.45 1-1 1H5c-.55 0-1 .45-1 1z"/></svg>' \\n  -H 'Referer;' \\n  -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36' \\n  --compressed ;\ncurl 'http://localhost/api_v2/workspace/all' \\n  -H 'Accept-Language: en-GB,en-US;q=0.9,en;q=0.8,hi;q=0.7' \\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IkRMeG9MZ0RjN2NYS0taNWViaHpQRSJ9.eyJpc3MiOiJodHRwczovL2Rldi1zbXNycm1iZXlxZ24yZDEwLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2Njg5MDkyYzY3MWM0MDdlOGE4ZWRiYTciLCJhdWQiOiJodHRwczovL3N1YnRsLXdlYi1hcGkiLCJpYXQiOjE3MjE4OTQwODMsImV4cCI6MTcyMTk4MDQ4MywiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJlNnB1NURDb0hRWTgzYmJNZlhQVmRtMHdJa3JPa1RISyJ9.dKaYTv_z8bRK7SHMdbDQguskUQL5CymXqWkTVFYVY7Sz5GadjDtO1raC3IgEuyDmTb5E-HKDbV1NwzFjMpVNPZH6_RRa_Q5ymHnthK85uabqjkotcQYDcvo7wR-jm8HSS3gxBBJH0Ui8FvymkSKl92Erg_7z6eAzR8igjjguz4YT84WQzTwjRNyYmZufZvPvEshEbg6921lIOhkh2ZHLYLvDU93DExGw3WoVdlk887jDo_etbE5hs-N-h7hL7mZ-pKVae4bH7PRPXwQp9_kMLrFbR_cJ1iJyAEPvmiJ4zoaB9UwQRu5IMAv2TdcUhFEjIo3PRmPPz_vwQ2J3tEpb8A' \\n  -H 'Connection: keep-alive' \\n  -H 'Cookie: g_state={"i_l":0}; _legacy_auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true; auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true' \\n  -H 'Referer: http://localhost/api_v2/docs' \\n  -H 'Sec-Fetch-Dest: empty' \\n  -H 'Sec-Fetch-Mode: cors' \\n  -H 'Sec-Fetch-Site: same-origin' \\n  -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36' \\n  -H 'accept: application/json' \\n  -H 'sec-ch-ua: "Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"' \\n  -H 'sec-ch-ua-mobile: ?0' \\n  -H 'sec-ch-ua-platform: "Linux"' \\n  --compressed ;\ncurl 'http://localhost/api_v2/workspace/all' \\n  -H 'Accept-Language: en-GB,en-US;q=0.9,en;q=0.8,hi;q=0.7' \\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IkRMeG9MZ0RjN2NYS0taNWViaHpQRSJ9.eyJpc3MiOiJodHRwczovL2Rldi1zbXNycm1iZXlxZ24yZDEwLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2Njg5MDkyYzY3MWM0MDdlOGE4ZWRiYTciLCJhdWQiOiJodHRwczovL3N1YnRsLXdlYi1hcGkiLCJpYXQiOjE3MjE4OTQwODMsImV4cCI6MTcyMTk4MDQ4MywiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJlNnB1NURDb0hRWTgzYmJNZlhQVmRtMHdJa3JPa1RISyJ9.dKaYTv_z8bRK7SHMdbDQguskUQL5CymXqWkTVFYVY7Sz5GadjDtO1raC3IgEuyDmTb5E-HKDbV1NwzFjMpVNPZH6_RRa_Q5ymHnthK85uabqjkotcQYDcvo7wR-jm8HSS3gxBBJH0Ui8FvymkSKl92Erg_7z6eAzR8igjjguz4YT84WQzTwjRNyYmZufZvPvEshEbg6921lIOhkh2ZHLYLvDU93DExGw3WoVdlk887jDo_etbE5hs-N-h7hL7mZ-pKVae4bH7PRPXwQp9_kMLrFbR_cJ1iJyAEPvmiJ4zoaB9UwQRu5IMAv2TdcUhFEjIo3PRmPPz_vwQ2J3tEpb8A' \\n  -H 'Connection: keep-alive' \\n  -H 'Cookie: g_state={"i_l":0}; _legacy_auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true; auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true' \\n  -H 'Referer: http://localhost/api_v2/docs' \\n  -H 'Sec-Fetch-Dest: empty' \\n  -H 'Sec-Fetch-Mode: cors' \\n  -H 'Sec-Fetch-Site: same-origin' \\n  -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36' \\n  -H 'accept: application/json' \\n  -H 'sec-ch-ua: "Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"' \\n  -H 'sec-ch-ua-mobile: ?0' \\n  -H 'sec-ch-ua-platform: "Linux"' \\n  --compressed ;\ncurl 'http://localhost/api_v2/workspace/all' \\n  -H 'Accept-Language: en-GB,en-US;q=0.9,en;q=0.8,hi;q=0.7' \\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IkRMeG9MZ0RjN2NYS0taNWViaHpQRSJ9.eyJpc3MiOiJodHRwczovL2Rldi1zbXNycm1iZXlxZ24yZDEwLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2Njg5MDkyYzY3MWM0MDdlOGE4ZWRiYTciLCJhdWQiOiJodHRwczovL3N1YnRsLXdlYi1hcGkiLCJpYXQiOjE3MjE4OTQwODMsImV4cCI6MTcyMTk4MDQ4MywiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJlNnB1NURDb0hRWTgzYmJNZlhQVmRtMHdJa3JPa1RISyJ9.dKaYTv_z8bRK7SHMdbDQguskUQL5CymXqWkTVFYVY7Sz5GadjDtO1raC3IgEuyDmTb5E-HKDbV1NwzFjMpVNPZH6_RRa_Q5ymHnthK85uabqjkotcQYDcvo7wR-jm8HSS3gxBBJH0Ui8FvymkSKl92Erg_7z6eAzR8igjjguz4YT84WQzTwjRNyYmZufZvPvEshEbg6921lIOhkh2ZHLYLvDU93DExGw3WoVdlk887jDo_etbE5hs-N-h7hL7mZ-pKVae4bH7PRPXwQp9_kMLrFbR_cJ1iJyAEPvmiJ4zoaB9UwQRu5IMAv2TdcUhFEjIo3PRmPPz_vwQ2J3tEpb8A' \\n  -H 'Connection: keep-alive' \\n  -H 'Cookie: g_state={"i_l":0}; _legacy_auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true; auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true' \\n  -H 'Referer: http://localhost/api_v2/docs' \\n  -H 'Sec-Fetch-Dest: empty' \\n  -H 'Sec-Fetch-Mode: cors' \\n  -H 'Sec-Fetch-Site: same-origin' \\n  -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36' \\n  -H 'accept: application/json' \\n  -H 'sec-ch-ua: "Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"' \\n  -H 'sec-ch-ua-mobile: ?0' \\n  -H 'sec-ch-ua-platform: "Linux"' \\n  --compressed ;\ncurl 'http://localhost/api_v2/workspace/all' \\n  -H 'Accept-Language: en-GB,en-US;q=0.9,en;q=0.8,hi;q=0.7' \\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IkRMeG9MZ0RjN2NYS0taNWViaHpQRSJ9.eyJpc3MiOiJodHRwczovL2Rldi1zbXNycm1iZXlxZ24yZDEwLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2Njg5MDkyYzY3MWM0MDdlOGE4ZWRiYTciLCJhdWQiOiJodHRwczovL3N1YnRsLXdlYi1hcGkiLCJpYXQiOjE3MjE4OTQwODMsImV4cCI6MTcyMTk4MDQ4MywiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJlNnB1NURDb0hRWTgzYmJNZlhQVmRtMHdJa3JPa1RISyJ9.dKaYTv_z8bRK7SHMdbDQguskUQL5CymXqWkTVFYVY7Sz5GadjDtO1raC3IgEuyDmTb5E-HKDbV1NwzFjMpVNPZH6_RRa_Q5ymHnthK85uabqjkotcQYDcvo7wR-jm8HSS3gxBBJH0Ui8FvymkSKl92Erg_7z6eAzR8igjjguz4YT84WQzTwjRNyYmZufZvPvEshEbg6921lIOhkh2ZHLYLvDU93DExGw3WoVdlk887jDo_etbE5hs-N-h7hL7mZ-pKVae4bH7PRPXwQp9_kMLrFbR_cJ1iJyAEPvmiJ4zoaB9UwQRu5IMAv2TdcUhFEjIo3PRmPPz_vwQ2J3tEpb8A' \\n  -H 'Connection: keep-alive' \\n  -H 'Cookie: g_state={"i_l":0}; _legacy_auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true; auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true' \\n  -H 'Referer: http://localhost/api_v2/docs' \\n  -H 'Sec-Fetch-Dest: empty' \\n  -H 'Sec-Fetch-Mode: cors' \\n  -H 'Sec-Fetch-Site: same-origin' \\n  -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36' \\n  -H 'accept: application/json' \\n  -H 'sec-ch-ua: "Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"' \\n  -H 'sec-ch-ua-mobile: ?0' \\n  -H 'sec-ch-ua-platform: "Linux"' \\n  --compressed ;\ncurl 'http://localhost/api_v2/workspace/all' \\n  -H 'Accept-Language: en-GB,en-US;q=0.9,en;q=0.8,hi;q=0.7' \\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IkRMeG9MZ0RjN2NYS0taNWViaHpQRSJ9.eyJpc3MiOiJodHRwczovL2Rldi1zbXNycm1iZXlxZ24yZDEwLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2Njg5MDkyYzY3MWM0MDdlOGE4ZWRiYTciLCJhdWQiOiJodHRwczovL3N1YnRsLXdlYi1hcGkiLCJpYXQiOjE3MjE4OTQwODMsImV4cCI6MTcyMTk4MDQ4MywiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJlNnB1NURDb0hRWTgzYmJNZlhQVmRtMHdJa3JPa1RISyJ9.dKaYTv_z8bRK7SHMdbDQguskUQL5CymXqWkTVFYVY7Sz5GadjDtO1raC3IgEuyDmTb5E-HKDbV1NwzFjMpVNPZH6_RRa_Q5ymHnthK85uabqjkotcQYDcvo7wR-jm8HSS3gxBBJH0Ui8FvymkSKl92Erg_7z6eAzR8igjjguz4YT84WQzTwjRNyYmZufZvPvEshEbg6921lIOhkh2ZHLYLvDU93DExGw3WoVdlk887jDo_etbE5hs-N-h7hL7mZ-pKVae4bH7PRPXwQp9_kMLrFbR_cJ1iJyAEPvmiJ4zoaB9UwQRu5IMAv2TdcUhFEjIo3PRmPPz_vwQ2J3tEpb8A' \\n  -H 'Connection: keep-alive' \\n  -H 'Cookie: g_state={"i_l":0}; _legacy_auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true; auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true' \\n  -H 'Referer: http://localhost/api_v2/docs' \\n  -H 'Sec-Fetch-Dest: empty' \\n  -H 'Sec-Fetch-Mode: cors' \\n  -H 'Sec-Fetch-Site: same-origin' \\n  -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36' \\n  -H 'accept: application/json' \\n  -H 'sec-ch-ua: "Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"' \\n  -H 'sec-ch-ua-mobile: ?0' \\n  -H 'sec-ch-ua-platform: "Linux"' \\n  --compressed ;\ncurl 'http://localhost/api_v2/workspace/all' \\n  -H 'Accept-Language: en-GB,en-US;q=0.9,en;q=0.8,hi;q=0.7' \\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IkRMeG9MZ0RjN2NYS0taNWViaHpQRSJ9.eyJpc3MiOiJodHRwczovL2Rldi1zbXNycm1iZXlxZ24yZDEwLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2Njg5MDkyYzY3MWM0MDdlOGE4ZWRiYTciLCJhdWQiOiJodHRwczovL3N1YnRsLXdlYi1hcGkiLCJpYXQiOjE3MjE4OTQwODMsImV4cCI6MTcyMTk4MDQ4MywiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJlNnB1NURDb0hRWTgzYmJNZlhQVmRtMHdJa3JPa1RISyJ9.dKaYTv_z8bRK7SHMdbDQguskUQL5CymXqWkTVFYVY7Sz5GadjDtO1raC3IgEuyDmTb5E-HKDbV1NwzFjMpVNPZH6_RRa_Q5ymHnthK85uabqjkotcQYDcvo7wR-jm8HSS3gxBBJH0Ui8FvymkSKl92Erg_7z6eAzR8igjjguz4YT84WQzTwjRNyYmZufZvPvEshEbg6921lIOhkh2ZHLYLvDU93DExGw3WoVdlk887jDo_etbE5hs-N-h7hL7mZ-pKVae4bH7PRPXwQp9_kMLrFbR_cJ1iJyAEPvmiJ4zoaB9UwQRu5IMAv2TdcUhFEjIo3PRmPPz_vwQ2J3tEpb8A' \\n  -H 'Connection: keep-alive' \\n  -H 'Cookie: g_state={"i_l":0}; _legacy_auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true; auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true' \\n  -H 'Referer: http://localhost/api_v2/docs' \\n  -H 'Sec-Fetch-Dest: empty' \\n  -H 'Sec-Fetch-Mode: cors' \\n  -H 'Sec-Fetch-Site: same-origin' \\n  -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36' \\n  -H 'accept: application/json' \\n  -H 'sec-ch-ua: "Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"' \\n  -H 'sec-ch-ua-mobile: ?0' \\n  -H 'sec-ch-ua-platform: "Linux"' \\n  --compressed ;\ncurl 'http://localhost/api_v2/workspace/all' \\n  -H 'Accept-Language: en-GB,en-US;q=0.9,en;q=0.8,hi;q=0.7' \\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IkRMeG9MZ0RjN2NYS0taNWViaHpQRSJ9.eyJpc3MiOiJodHRwczovL2Rldi1zbXNycm1iZXlxZ24yZDEwLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2Njg5MDkyYzY3MWM0MDdlOGE4ZWRiYTciLCJhdWQiOiJodHRwczovL3N1YnRsLXdlYi1hcGkiLCJpYXQiOjE3MjE4OTQwODMsImV4cCI6MTcyMTk4MDQ4MywiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJlNnB1NURDb0hRWTgzYmJNZlhQVmRtMHdJa3JPa1RISyJ9.dKaYTv_z8bRK7SHMdbDQguskUQL5CymXqWkTVFYVY7Sz5GadjDtO1raC3IgEuyDmTb5E-HKDbV1NwzFjMpVNPZH6_RRa_Q5ymHnthK85uabqjkotcQYDcvo7wR-jm8HSS3gxBBJH0Ui8FvymkSKl92Erg_7z6eAzR8igjjguz4YT84WQzTwjRNyYmZufZvPvEshEbg6921lIOhkh2ZHLYLvDU93DExGw3WoVdlk887jDo_etbE5hs-N-h7hL7mZ-pKVae4bH7PRPXwQp9_kMLrFbR_cJ1iJyAEPvmiJ4zoaB9UwQRu5IMAv2TdcUhFEjIo3PRmPPz_vwQ2J3tEpb8A' \\n  -H 'Connection: keep-alive' \\n  -H 'Cookie: g_state={"i_l":0}; _legacy_auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true; auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true' \\n  -H 'Referer: http://localhost/api_v2/docs' \\n  -H 'Sec-Fetch-Dest: empty' \\n  -H 'Sec-Fetch-Mode: cors' \\n  -H 'Sec-Fetch-Site: same-origin' \\n  -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36' \\n  -H 'accept: application/json' \\n  -H 'sec-ch-ua: "Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"' \\n  -H 'sec-ch-ua-mobile: ?0' \\n  -H 'sec-ch-ua-platform: "Linux"' \\n  --compressed ;\ncurl 'http://localhost/api_v2/workspace/all' \\n  -H 'Accept-Language: en-GB,en-US;q=0.9,en;q=0.8,hi;q=0.7' \\n  -H 'Authorization: Bearer eyJhbGciOiJSUzI1NiIsInR5cCI6IkpXVCIsImtpZCI6IkRMeG9MZ0RjN2NYS0taNWViaHpQRSJ9.eyJpc3MiOiJodHRwczovL2Rldi1zbXNycm1iZXlxZ24yZDEwLnVzLmF1dGgwLmNvbS8iLCJzdWIiOiJhdXRoMHw2Njg5MDkyYzY3MWM0MDdlOGE4ZWRiYTciLCJhdWQiOiJodHRwczovL3N1YnRsLXdlYi1hcGkiLCJpYXQiOjE3MjE4OTQwODMsImV4cCI6MTcyMTk4MDQ4MywiZ3R5IjoicGFzc3dvcmQiLCJhenAiOiJlNnB1NURDb0hRWTgzYmJNZlhQVmRtMHdJa3JPa1RISyJ9.dKaYTv_z8bRK7SHMdbDQguskUQL5CymXqWkTVFYVY7Sz5GadjDtO1raC3IgEuyDmTb5E-HKDbV1NwzFjMpVNPZH6_RRa_Q5ymHnthK85uabqjkotcQYDcvo7wR-jm8HSS3gxBBJH0Ui8FvymkSKl92Erg_7z6eAzR8igjjguz4YT84WQzTwjRNyYmZufZvPvEshEbg6921lIOhkh2ZHLYLvDU93DExGw3WoVdlk887jDo_etbE5hs-N-h7hL7mZ-pKVae4bH7PRPXwQp9_kMLrFbR_cJ1iJyAEPvmiJ4zoaB9UwQRu5IMAv2TdcUhFEjIo3PRmPPz_vwQ2J3tEpb8A' \\n  -H 'Connection: keep-alive' \\n  -H 'Cookie: g_state={"i_l":0}; _legacy_auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true; auth0.DGWWtBbvuQImVTf4qaN0NvRde7dowxAI.is.authenticated=true' \\n  -H 'Referer: http://localhost/api_v2/docs' \\n  -H 'Sec-Fetch-Dest: empty' \\n  -H 'Sec-Fetch-Mode: cors' \\n  -H 'Sec-Fetch-Site: same-origin' \\n  -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36' \\n  -H 'accept: application/json' \\n  -H 'sec-ch-ua: "Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"' \\n  -H 'sec-ch-ua-mobile: ?0' \\n  -H 'sec-ch-ua-platform: "Linux"' \\n  --compressed
 9411  git status
 9412  git add .
 9413  git commit -m "fixed custom error bug"
 9414  git push -u origin subtl-payment-integration\n
 9415  sudo docker exec -it subtl_bot-api_v2-1 /bin/bash\n
 9416  sudo docker restart subtl_bot-api_v2-1
 9417  sudo ./run.sh logs --tail 1000 -f api_v2
 9418  clear
 9419  git status
 9420  git add .
 9421  git commit -m "refactored frontend"
 9422  git push -u origin subtl-payment-integration\n
 9423  sudo docker exec -it subtl_bot-api_v2-1 /bin/bash\n
 9424  git status
 9425  git add .
 9426  git commit -m "deleted latest alembic"
 9427  git push -u origin subtl-payment-integration\n
 9428  code .
 9429  sudo docker ps
 9430  cd frontend; 
 9431  cd subtl_frontend
 9432  yarn dev
 9433  sudo ./run.sh logs --tail 1000 -f api_v2
 9434  git status
 9435  git add .
 9436  git commit -m "fixed sub options bug"
 9437  git push -u origin subtl-payment-integration\n
 9438  git pull origin subtl-api-v2\n
 9439  git log\n
 9440  git status
 9441  git push -u origin subtl-payment-integration\n
 9442  sudo ./run.sh logs --tail 1000 -f api_v2
 9443  htop
 9444  clear
 9445  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9446  htop
 9447  sudo yum-config-manager --add-repo  https://repo.fortinet.com/repo/forticlient/7.4/centos/8/os/x86_64/fortinet.repo\n
 9448  wget -O - https://repo.fortinet.com/repo/forticlient/7.4/ubuntu22/DEB-GPG-KEY | gpg --dearmor | sudo tee /usr/share/keyrings/repo.fortinet.com.gpg
 9449  deb [arch=amd64 signed-by=/usr/share/keyrings/repo.fortinet.com.gpg] https://repo.fortinet.com/repo/forticlient/7.4/ubuntu22/ stable non-free\n
 9450  sudo apt install forticlient\n
 9451  wget -O - https://repo.fortinet.com/repo/forticlient/7.4/ubuntu22/DEB-GPG-KEY | gpg --dearmor | sudo tee /usr/share/keyrings/repo.fortinet.com.gpg
 9452  deb [arch=amd64 signed-by=/usr/share/keyrings/repo.fortinet.com.gpg] https://repo.fortinet.com/repo/forticlient/7.4/ubuntu22/ stable non-free\n
 9453  deb arch=amd64 signed-by=/usr/share/keyrings/repo.fortinet.com.gpg] https://repo.fortinet.com/repo/forticlient/7.4/ubuntu22/ stable non-free\n
 9454  echo 'deb [arch=amd64 signed-by=/usr/share/keyrings/repo.fortinet.com.gpg] https://repo.fortinet.com/repo/forticlient/7.4/ubuntu22/ stable non-free' | sudo tee /etc/apt/sources.list.d/fortinet.list\n
 9455  sudo apt-get update\n
 9456  sudo apt install forticlient\n
 9457  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9458  htop
 9459  git status
 9460  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9461  code .
 9462  git pull
 9463  cd subtl_frontend
 9464  clear
 9465  ls
 9466  yarn dev
 9467  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'
 9468  curl -s -X POST https://api.creatomate.com/v1/renders \\n  -H 'Authorization: Bearer YOUR_API_KEY' \\n  -H 'Content-Type: application/json' \\n  --data-binary @- << EOF\n{\n  "template_id": "58c1163e-f250-49df-b98d-e8c4aad01a2d",\n\n  "modifications": {\n    "Image-1": "https://cdn.creatomate.com/demo/living-room.jpg",\n    "Image-2": "https://cdn.creatomate.com/demo/bathroom.jpg",\n    "Image-3": "https://cdn.creatomate.com/demo/kitchen.jpg"\n  }\n}\nEOF
 9469  code .
 9470  git pull
 9471  cd backend;
 9472  npm start
 9473  cd frontend; 
 9474  npm start
 9475  htop
 9476  npm start
 9477  clear
 9478  npm start
 9479  gcloud auth login\n
 9480  gcloud config set project lab-deployment-414310
 9481  gcloud app deploy\n
 9482  git status
 9483  git add .
 9484  git commit -m "fixed lab url bug"
 9485  git push -u origin new_branch
 9486  sudo ./run.sh -d -- up --build -d --force-recreate llmapi
 9487  cd ..
 9488  sudo ./run.sh -d -- up --build -d --force-recreate llmapi
 9489  sudo ./run.sh -d -- up --build -d --force-recreate llm_api
 9490  sudo ./run.sh logs --tail 1000 -f llm_api
 9491  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9492  lsof -i :80\n
 9493  sudo lsof -i :80\n
 9494  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9495  sudo lsof -i :80\n
 9496  sudo systemctl stop apache2
 9497  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9498  sudo ./run.sh logs --tail 1000 -f llm_api
 9499  sudo docker ps
 9500  sudo ./run.sh logs --tail 1000 -f llm_api
 9501  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9502  sudo ./run.sh logs --tail 1000 -f llm_api
 9503  sudo docker ps
 9504  sudo docker exec -it subtl_bot-api_v2-1 /bin/bash\n
 9505  sudo docker ps\n
 9506  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
 9507  sudo ./run.sh logs --tail 1000 -f llm_api
 9508  sudo ./run.sh logs --tail 1000 -f nginx
 9509  sudo ./run.sh -d -- up --build -d --force-recreate api_v2
 9510  git pull
 9511  sudo ./run.sh logs --tail 1000 -f api_v2
 9512  sudo ./run.sh -d -- up --build -d --force-recreate api_v2
 9513  sudo docker exec -it subtl_bot-api_v2-1 /bin/bash\n
 9514  sudo docker restart subtl_bot-api_v2-1
 9515  sudo ./run.sh logs --tail 1000 -f api_v2
 9516  htop
 9517  code .
 9518  cd "/media/chirag/DATA10/CODE_AMA/CP/cppp/" && g++ AGGRCOW.cpp -o AGGRCOW && "/media/chirag/DATA10/CODE_AMA/CP/cppp/"AGGRCOW
 9519  code .
 9520  cat .env
 9521  htop
 9522  ./jmeter\n
 9523  code .
 9524  sudo docker system prune -f
 9525  tar -xzvf android-studio-2024.1.1.12-linux.tar.gz
 9526  ./studio.sh
 9527  htop
 9528  ./studio.sh
 9529  htop
 9530  sudo apt-get clean\n
 9531  du -sh /var/cache/apt/archives\n
 9532  sudo du -sh /var/cache/apt/archives\n
 9533  sudo apt-get autoremove --purge\n
 9534  htop
 9535  code .
 9536  python -u "/media/chirag/DATA10/subtl.ai/subtl_bot/tests/llama3.1-test.py"
 9537  python -u "/media/chirag/DATA10/subtl.ai/subtl_bot/tests/llama3.1-test-qa.py"
 9538  ./jmeter\n
 9539  python -u "/media/chirag/DATA10/subtl.ai/subtl_bot/tests/llama3.1-test-qa.py"
 9540  htop
 9541  python -u "/media/chirag/DATA10/subtl.ai/subtl_bot/tests/llama3.1-test-qa.py"
 9542  cd "/home/chirag/" && g++ x.cpp -o x && "/home/chirag/"x
 9543  python -u "/home/chirag/x.py"
 9544  python -u "/media/chirag/DATA10/subtl.ai/subtl_bot/tests/llama3.1-test-qa.py"
 9545  git pull
 9546  python -u "/media/chirag/DATA10/subtl.ai/subtl_bot/tests/llama3.1-test.py"
 9547  git checkout -b llama-3.1-llmapi-update
 9548  python -u "/media/chirag/DATA10/subtl.ai/subtl_bot/tests/llama3.1-test.py"
 9549  ls
 9550  sudo systemctl stop apache2
 9551  sudo ./run.sh -d -- up --build -d --force-recreate llm_api nginx llm_worker
 9552  sudo ./run.sh logs --tail 1000 -f llm_api
 9553  sudo ./run.sh -d -- up --build -d --force-recreate llm_api nginx llm_worker
 9554  sudo ./run.sh logs --tail 1000 -f llm_worker
 9555  htop
 9556  cd subtl_doc_parser
 9557  sudo ./subtl_doc_parser.sh -d -- up --build -d redis-queue queue
 9558  sudo systemctl stop redis
 9559  sudo ./subtl_doc_parser.sh -d -- up --build -d redis-queue queue
 9560  sudo ./run.sh -d -- up --build -d --force-recreate llm_api nginx llm_worker flower
 9561  sudo ./subtl_doc_parser.sh -d -- up --build -d flower
 9562  python -u "/media/chirag/DATA10/subtl.ai/subtl_bot/tests/llama3.1-test-qa.py"
 9563  sudo ./run.sh -d -- up --build -d --force-recreate llm_api nginx llm_worker
 9564  htop
 9565  sudo ./run.sh -d -- up --build -d --force-recreate llm_api nginx llm_worker
 9566  history  > his.txt
 9567  curl -X POST -H "Content-Type: application/json" -d '{\n    "prompt": "write an essay on environment",\n    "max_new_tokens": 300,\n    "temperature": 0.7,\n    "top_k": 50,\n    "top_p": 0.95,\n    "stream": true\n}' http://35.193.52.196:8000/generate
 9568  curl -X 'POST' \\n  'http://localhost/llmapi/qa/' \\n  -H 'accept: application/json' \\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3MjM2MjM5MjgsInN1YiI6IjEifQ.IM8edjo9l3j72kcJoyby_PA4FxhoZnZZuXH2mUV77pU' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "backend": "vLLM/Llama3.1",\n  "question": "Can shadow credit be used for local cheques?",
 9569  curl -X 'POST' \\n  'http://localhost/llmapi/qa/' \\n  -H 'accept: application/json' \\n  -H 'Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJleHAiOjE3MjM2MjM5MjgsInN1YiI6IjEifQ.IM8edjo9l3j72kcJoyby_PA4FxhoZnZZuXH2mUV77pU' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "backend": "vLLM/Llama3.1",\n  "question": "Can shadow credit be used for local cheques?",\n  "stream": true\n  }'
 9570  bash x.sh
 9571  htop
 9572  code .
 9573  bash test.sh
 9574  docker ps
 9575  sudo docker ps
 9576  python -u "/media/chirag/DATA10/subtl.ai/subtl_bot/tests/llama3.1-test-qa.py"
 9577  sudo ./run.sh logs --tail 1000 -f llm_worker
 9578  sudo ./run.sh logs --tail 1000 -f llm_api
 9579  git status
 9580  git add .
 9581  git commit -m "updated llmapi for llama 3.1"
 9582  git push -u origin llama-3.1-llmapi-update
 9583  ./jmeter\n
 9584  git checkout -b subtl-api-v2
 9585  git checkout subtl-api-v2
 9586  git pull
 9587  clear
 9588  cd subtl_frontend
 9589  yarn dev
 9590  git pull
 9591  git status
 9592  git commit -m "fixed /config bug"
 9593  git add .
 9594  git commit -m "fixed /config bug"
 9595  git push -u origin subtl-api-v2
 9596  htop
 9597  git checkout llama-3.1-llmapi-update
 9598  docker ps
 9599  sudo docker ps
 9600  sudo docker logs -f subtl_bot-llm_api-1
 9601  ./jmeter\n
 9602  curl -X 'POST' \\n  'http://35.193.52.196:8000/v1/chat/completions' \\n  -H 'accept: application/json' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "messages": [\n    {\n      "content": "string",\n      "role": "system",\n      "name": "string"\n    },\n    {\n      "content": "string",\n      "role": "user",\n      "name": "string"\n    }\n  ],\n  "model": "solidrust/Phi-3-mini-4k-instruct-AWQ",\n  "logprobs": false,\n  "max_tokens": 300,\n  "temperature": 0.7,\n  "top_p": 1\n}\n'
 9603  sudo ./run.sh -d -- up --build -d --force-recreate llm_api nginx llm_worker
 9604  sudo rm -rf android-studio\n\n
 9605  rm -rf ~/Android/Sdk
 9606  sudo snap remove android-studio or sudo apt remove android-studio\n\n
 9607  sudo rm -rf /etc/android-studio\n\n
 9608  sudo apt autoremove\n\n
 9609  sudo apt-get autoremove purge\n\n
 9610  curl -X 'POST' \\n  'http://35.193.52.196:8000/v1/chat/completions' \\n  -H 'accept: application/json' \\n  -H 'Content-Type: application/json' \\n  -d '{\n  "messages": [\n    {\n      "content": "Answer to user queries.",\n      "role": "system"\n    },\n    {\n      "content": "what is your name?",\n      "role": "user"\n    }\n  ],\n  "model": "solidrust/Phi-3-mini-4k-instruct-AWQ",\n  "logprobs": false,\n  "max_tokens": 300,\n  "temperature": 0.7,\n  "top_p": 1\n}\n'\n
 9611  sudo ./run.sh logs --tail 1000 -f llm_api
 9612  code .
 9613  git stash 
 9614  sudo ./run.sh -d -- up --build -d --force-recreate llm_api nginx llm_worker
 9615  cd ~/.android
 9616  ls
 9617  cd ..
 9618  rm -rf ~/.android
 9619  sudo ./run.sh -d -- up --build -d --force-recreate llm_api nginx llm_worker
 9620  sudo ./run.sh logs --tail 1000 -f llm_api
 9621  sudo ./run.sh logs --tail 1000 -f llm_worker
 9622  sudo ./run.sh -d -- up --build -d --force-recreate llm_api nginx llm_worker
 9623  bash test
 9624  bash test.sh
 9625  git status
 9626  git add .
 9627  git commit -m "modularised code"
 9628  git status
 9629  docker ps
 9630  sudo docker ps
 9631  sudo docker logs -f subtl_bot-api_v2-1
 9632  sudo ./run.sh -d -- up --build -d --force-recreate llm_api nginx llm_worker
 9633  sudo docker exec -it subtl_bot-api_v2-1 /bin/bash\n
 9634  sudo docker restart subtl_bot-api_v2-1
 9635  sudo docker logs -f subtl_bot-api_v2-1
 9636  sudo docker restart subtl_bot-api_v2-1
 9637  sudo docker logs -f subtl_bot-api_v2-1
 9638  sudo ./run.sh -d -- up --build -d --force-recreate llm_api nginx llm_worker
 9639  cs subtl_frontend
 9640  cd subtl_frontend
 9641  yarn dev
 9642  sudo docker exec -it subtl_bot-api_v2-1 /bin/bash\n
 9643  sudo docker restart subtl_bot-api_v2-1
 9644  sudo docker logs -f subtl_bot-api_v2-1
 9645  sudo docker restart subtl_bot-api_v2-1
 9646  sudo docker logs -f subtl_bot-api_v2-1
 9647  sudo docker restart subtl_bot-api_v2-1
 9648  sudo docker logs -f subtl_bot-api_v2-1
 9649  sudo docker restart subtl_bot-api_v2-1
 9650  sudo docker logs -f subtl_bot-api_v2-1
 9651  sudo docker restart subtl_bot-api_v2-1
 9652  sudo docker logs -f subtl_bot-api_v2-1
 9653  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=admin@subtl.ai' \\n  --data 'password=Subtl@1234' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'\n\n\n\n\n\n
 9654  git status
 9655  git add .
 9656  git commit -m "updated api-v2 for llama 3.1"
 9657  git push -u origin llama-3.1-llmapi-update
 9658  git status
 9659  yarn dev
 9660  docker ps
 9661  ./jmeter\n
 9662  code .
 9663  cd subtl_frontend
 9664  yarn dev
 9665  sudo docker ps
 9666  sudo docker system prune -f
 9667  sudo docker ps
 9668  sudo docker image
 9669  sudo docker images
 9670  code .
 9671  ls
 9672  cs subtl_frontend
 9673  cd subtl_frontend
 9674  git checkout subtl-api-v2
 9675  git pull
 9676  yarn dev
 9677  code .
 9678  yarn dev
 9679  cd subtl_frontend
 9680  git pull
 9681  git status
 9682  git add .
 9683  git commit -m "added notifs"
 9684  git push -u origin subtl-api-v2
 9685  curl --request POST \\n  --url 'https://dev-smsrrmbeyqgn2d10.us.auth0.com/oauth/token' \\n  --header 'content-type: application/x-www-form-urlencoded' \\n  --data grant_type=password \\n  --data 'username=chirag.j@students.iiit.ac.in' \\n  --data 'password=JAIN263@gari' \\n  --data 'client_id=e6pu5DCoHQY83bbMfXPVdm0wIkrOkTHK' \\n  --data 'client_secret=lnUsCdWVy7xiIsCX4jkm-qagTs-uVZzEZ-S3qKO6L9SsHuQDSCq3X15FcVBzUchF'\n\n\n\n\n\n
 9686  yarn dev
 9687  git status
 9688  git add .
 9689  git commit -m "added polling to doc upload status"
 9690  git push -u origin subtl-api-v2
 9691  code .
 9692  yarn dev
 9693  git status
 9694  git add .
 9695  git commit -m "added description to library"
 9696  git push -u origin subtl-api-v2
 9697  git pull
 9698  git push -u origin subtl-api-v2
 9699  yarn add date-fns
 9700  htop
 9701  clear
 9702  git add .
 9703  git commit -m "added timestamps to chat"
 9704  git push -u origin subtl-api-v2
 9705  code .
 9706  yarn dev
 9707  git add .
 9708  git commit -m "added pagination to doc tab"
 9709  git push -u origin subtl-api-v2
 9710  git add .
 9711  git commit -m "added progressbar to doc upload"
 9712  git push -u origin subtl-api-v2
 9713  git pull
 9714  git push -u origin subtl-api-v2
 9715  htop
 9716  git add .
 9717  git commit -m "fixed progressbar bug"
 9718  git push -u origin subtl-api-v2
 9719  htop
 9720  docker pull postgres\n
 9721  sudo docker pull postgres\n
 9722  docker run --name   my-pgadmin -p 82:80 -e 'PGADMIN_DEFAULT_EMAIL=admin@x.com' -e 'PGADMIN_DEFAULT_PASSWORD=123' -d dpage/pgadmin4\n
 9723  sudo docker run --name   my-pgadmin -p 82:80 -e 'PGADMIN_DEFAULT_EMAIL=admin@x.com' -e 'PGADMIN_DEFAULT_PASSWORD=123' -d dpage/pgadmin4\n
 9724  docker run --name -d pg -p 5432:5432 -e POSTGRES_PASSWORD='123' postgres
 9725  sudo docker run --name -d pg -p 5432:5432 -e POSTGRES_PASSWORD='123' postgres
 9726  sudo docker ps
 9727  sudo docker stop $(sudo docker ps -a -q)
 9728  sudo docker rm $(sudo docker ps -a -q)
 9729  sudo docker ps -a
 9730  sudo docker images
 9731  sudo docker rmi -f subtl_bot-llm_worker
 9732  sudo docker rmi -f subtl_bot-llm_api
 9733  sudo docker rmi -f subtl_bot-api
 9734  sudo docker images
 9735  sudo docker system prune -f\n
 9736  sudo docker images
 9737  sudo docker images -a
 9738  sudo docker run --name pg -e POSTGRES_PASSWORD=123 -p 5432:5432 -d postgres\n
 9739  lsof -i :5432
 9740  sudo lsof -i :5432
 9741  sudo systemctl status postgress
 9742  sudo lsof -i :5432\n
 9743  sudo kill -9 1411\n
 9744  sudo lsof -i :5432\n
 9745  sudo docker run --name pg -e POSTGRES_PASSWORD=123 -p 5432:5432 -d postgres\n
 9746  sudo docker ps
 9747  sudo docker ps -a
 9748  sudo docker rm $(sudo docker ps -a -q)
 9749  sudo docker run --name pg -e POSTGRES_PASSWORD=123 -p 5432:5432 -d postgres\n
 9750  sudo docker ps -
 9751  sudo docker ps 
 9752  docker run --name pgadmin-container -p 5050:80 -e PGADMIN_DEFAULT_EMAIL=user@domain.com -e PGADMIN_DEFAULT_PASSWORD=123 -d dpage/pgadmin4\n
 9753  sudo docker run --name pgadmin-container -p 5050:80 -e PGADMIN_DEFAULT_EMAIL=user@domain.com -e PGADMIN_DEFAULT_PASSWORD=123 -d dpage/pgadmin4\n
 9754  sudo docker ps 
 9755  history --tail 10
 9756  sudo docker ps
 9757  sudo docker rm $(sudo docker ps -a -q)
 9758  sudo docker stop $(sudo docker ps -a -q)
 9759  sudo docker rm $(sudo docker ps -a -q)
 9760  touch docker-compose.yaml
 9761  docker compose up
 9762  sudo docker compose up
 9763  sudo docker ps
 9764  sudo docker compose up
 9765  sudo docker ps
 9766  git clone https://github.com/Mitanshk01/conllu-Annotatrix.git
 9767  code .
 9768  git clone https://github.com/Mitanshk01/conllu-Annotatrix.git
 9769  code .
 9770  git clone https://github.com/alperencubuk/fastapi-with-pydantic-v2-postgres-alembic-docker-template.git
 9771  cd api
 9772  ls -al
 9773  rm -rf .git .github
 9774  code .
 9775  git clone https://github.com/fastapi/full-stack-fastapi-template.git
 9776  code .e
 9777  code .
 9778  ls -al
 9779  rm -rf .git .github
 9780  sudo docker compose up db pgadmin
 9781  sudo docker network create traefik-public\n
 9782  sudo docker compose up db pgadmin
 9783  sudo docker ps
 9784  sudo docker compose up backend
 9785  sudo docker ps
 9786  sudo docker exec -it full-stack-fastapi-template-backend-1 /bin/bash
 9787  sudo docker compose up --force-recreate backend
 9788  sudo docker ps
 9789  sudo docker exec -it full-stack-fastapi-template-backend-1 /bin/bash
 9790  sudo docker compose up --force-recreate backend
 9791  sudo docker exec -it full-stack-fastapi-template-backend-1 /bin/bash
 9792  sudo docker ps
 9793  sudo docker compose up --force-recreate backend
 9794  code .
 9795  yarn dev
 9796  git status subtl_frontend
 9797  git add .
 9798  git commit -m "added product changes"
 9799  git push -u origin subtl-api-v2
 9800  git pull
 9801  git push -u origin subtl-api-v2
 9802  git status subtl_frontend
 9803  git add .
 9804  git commit -m "added multi select delete "
 9805  git push -u origin subtl-api-v2
 9806  ./jmeter\n
 9807  python -u "/media/chirag/DATA10/subtl.ai/subtl_bot/tests/first-token-latency.py"
 9808  ipconfig
 9809  ifconfig
 9810  sudo apt install gnupg software-properties-common
 9811  sudo mkdir -m755 -p /etc/apt/keyrings  # not needed since apt version 2.4.0 like Debian 12 and Ubuntu 22 or newer\nsudo wget -O /etc/apt/keyrings/qgis-archive-keyring.gpg https://download.qgis.org/downloads/qgis-archive-keyring.gpg\n
 9812  vim /etc/apt/sources.list.d/qgis.sources
 9813  nano /etc/apt/sources.list.d/qgis.sources
 9814  sudo nano /etc/apt/sources.list.d/qgis.sources
 9815  sudo apt update\n
 9816  sudo apt install qgis qgis-plugin-grass\n
 9817  saga_cmd
 9818  sudo apt-get install saga\n\n
 9819  code .
 9820  git pull
 9821  clear
 9822  yarn dev
 9823  git status subtl_frontend
 9824  clear
 9825  git status subtl_frontend
 9826  git add .
 9827  git status
 9828  git commit -m "added tooltip to Add Library"
 9829  git push -u origin subtl-api-v2
 9830  code .
 9831  cd subtl_frontend
 9832  ls
 9833  yarn dev
 9834  git add .
 9835  git status
 9836  git commit -m "fixed white screen bug"
 9837  git push -u origin subtl-api-v2
 9838  git pull
 9839  htop
 9840  yarn dev
 9841  git status
 9842  git add .
 9843  git commit -m "fixed multi select syntax error"
 9844  git push -u origin subtl-api-v2
 9845  yarn add react-markdown\n
 9846  yarn dev
 9847  ^[[200~yarn add @types/react@latest @types/react-dom@latest --dev
 9848  yarn add @types/react@latest @types/react-dom@latest --dev\n
 9849  yarn dev
 9850  yarn install
 9851  yarn dev
 9852  yarn add markdown-to-jsx
 9853  yarn add react/jsx-runtime
 9854  ^[[200~npm cache clean --force
 9855  ~
 9856  npm cache clean --force
 9857  rm -rf node_modules package-lock.json\nnpm install
 9858  rm -rf node_modules package-lock.jsonyaen install
 9859  yarn install
 9860  ls
 9861  cd subtl_frontend
 9862  rm -rf node_modules package-lock.json\nnpm install
 9863  npm i marked-react\n
 9864  git status
 9865  git add .
 9866  git status
 9867  git commit -m "added md support"
 9868  git push -u origin subtl-api-v2
 9869  git add .
 9870  git commit -m "added md support"
 9871  git push -u origin subtl-api-v2
 9872  code .
 9873  git status
 9874  git checkout https://github.com/subtlai/subtl_bot.git
 9875  git checkout integrate-chat-history
 9876  git pull origin integrate-chat-history
 9877  sudo docke ps
 9878  sudo docker ps
 9879  sudo docker ps -a
 9880  cd subtl_doc_parser
 9881  history > his1.txt
 9882  sudo ./subtl_doc_parser.sh -d -- up --build -d redis-queue queue
 9883  sudo ./run.sh -d -- up --build -d --force-recreate llm_api nginx llm_worker
 9884  cd subtl_frontend
 9885  yarn dev
 9886  yarn install
 9887  yarn dev
 9888  sudo ./run.sh logs --tail 1000 -f llm_api llm_wprker
 9889  sudo ./run.sh logs --tail 1000 -f llm_api llm_worker
 9890  cd ..
 9891  sudo ./run.sh logs --tail 1000 -f api_v2\\n
 9892  sudo docker ps
 9893  sudo ./run.sh -d -- up --build -d --force-recreate api_v2
 9894  sudo ./run.sh logs --tail 1000 -f api_v2\n
 9895  sudo ./run.sh -d -- up --build -d --force-recreate api_v2
 9896  sudo ./run.sh logs --tail 1000 -f api_v2\n
 9897  yarn dev
 9898  cat /etc/NetworkManager/system-connections/myHotspot
 9899  cat /etc/NetworkManager/system-connections
 9900  cd /etc/NetworkManager/system-connections/myHotspot
 9901  cd /etc/NetworkManager/system-connections
 9902  ls
 9903  sudo apt-get update\nsudo apt-get install dnsmasq\n
 9904  ip a\n
 9905  ls /etc/NetworkManager/system-connections/\n
 9906  sudo nano /etc/NetworkManager/system-connections/Hotspot.nmconnection\n
 9907  sudo vim /etc/NetworkManager/system-connections/Hotspot.nmconnection\n
 9908  sudo systemctl restart NetworkManager\n
 9909  sudo vim /etc/NetworkManager/system-connections/Hotspot.nmconnection\n
 9910  sudo systemctl restart NetworkManager\n
 9911  sudo vim /etc/NetworkManager/system-connections/Hotspot.nmconnection\n
 9912  sudo systemctl restart NetworkManager\n
 9913  sudo vim /etc/NetworkManager/system-connections/Hotspot.nmconnection\n
 9914  nmcli connection up Hotspot\n
 9915  sudo act /etc/NetworkManager/system-connections/Hotspot.nmconnection\n
 9916  sudo cat /etc/NetworkManager/system-connections/Hotspot.nmconnection\n
 9917  sudo vim /etc/NetworkManager/system-connections/Hotspot.nmconnection\n
 9918  sudo systemctl restart NetworkManager\n
 9919  sudo vim /etc/NetworkManager/system-connections/Hotspot.nmconnection\n
 9920  sudo systemctl restart NetworkManager\n
 9921  code .
 9922  clear
 9923  yarn dev
 9924  git status
 9925  git stash
 9926  git checkout subtl-tl-api-v2
 9927  git checkout subtl-api-v2
 9928  yarn dev
 9929  yarn install
 9930  yarn dev
 9931  git pull
 9932  git pull origin subtl-api-v2\n
 9933  git pull
 9934  git stash
 9935  git pull
 9936  yarn install
 9937  yarn dev
 9938  npm i rehype-raw
 9939  cd subtl_frontend
 9940  yarn install
 9941  git status
 9942  git add src/components/chat-window/ChatWindow.tsx
 9943  git commit -m "fixed lagging in inputbox"
 9944  git push -u origin subtl-api-v2
 9945  code .
 9946  clear
 9947  git init
 9948  git add .
 9949  git commit -m "first commit"
 9950  git remote add origin https://github.com/chir263/C-shell.git\ngit branch -M main\ngit push -u origin main
 9951  code .
 9952  git init
 9953  git remote add origin https://github.com/chir263/SMAI.git\ngit branch -M main\ngit push -u origin main
 9954  git add .
 9955  git commit -m "first commit"
 9956  git remote add origin https://github.com/chir263/SMAI.git\ngit branch -M main\ngit push -u origin main
 9957  code .
 9958  git pull
 9959  cd subtl_frontend
 9960  yarn dev
 9961  git status
 9962  git add .
 9963  git commit -m "updated feedback form"
 9964  git push -u origin subtl-api-v2
 9965  htop
 9966  code .
 9967  clear
 9968  yarn dev
 9969  code .
 9970  yarn dev
 9971  git status
 9972  git add .
 9973  git commit -m "updated feedback form"
 9974  git push -u origin subtl-api-v2
 9975  git status
 9976  git add .
 9977  git commit -m "added cosmetic changes"
 9978  git push -u origin subtl-api-v2
 9979  git pull
 9980  git push -u origin subtl-api-v2
 9981  git add .
 9982  git commit -m "added cosmetic changes"
 9983  git push -u origin subtl-api-v2
 9984  git status
 9985  code .
 9986  sudo docker system prune -f\n
 9987  sudo docker compose up
 9988  lsof -i :5432
 9989  sudo lsof -i :5432\n
 9990  sudo kill -9 1428
 9991  sudo docker compose up
 9992  ls
 9993  sudo rm -rf subtl_api
 9994  ls
 9995  sudo docker ps
 9996  sudo docker compose up -f
 9997  sudo docker compose -d up 
 9998  sudo docker compose up -d
 9999  sudo docker ps
10000  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10001  sudo docker ps
10002  sudo docker ps -a
10003  sudo docker restart full-stack-fastapi-template-db-1 full-stack-fastapi-template-pgadmin-1
10004  sudo lsof -i :5432\n
10005  sudo kill -9 1390
10006  sudo docker restart full-stack-fastapi-template-db-1 full-stack-fastapi-template-pgadmin-1
10007  code .
10008  sudo docker ps
10009  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10010  code .
10011  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10012  sudo docker ps
10013  sudo docker restart full-stack-fastapi-template-backend-1
10014  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10015  clear
10016  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10017  sudo docker compose up -d
10018  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10019  sudo docker compose up -d
10020  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10021  sudo docker compose up -d --force-recreate
10022  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10023  sudo docker compose up -d --force-recreate
10024  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10025  sudo docker exec -it full-stack-fastapi-template-backend-1 /bin/bash
10026  code .
10027  ./jmeter\n
10028  python -u "/media/chirag/DATA12/subtl.ai/subtl_bot/tests/llama3.1-test.py"
10029  python -u "/media/chirag/DATA12/subtl.ai/subtl_bot/tests/llama3.1-test-qa.py"
10030  htop
10031  cd frontend; 
10032  clear
10033  ls
10034  npm start
10035  npm i; npm start
10036  cd free-react-tailwind-admin-dashboard-main
10037  ls
10038  npm i; npm start
10039  yarn dev
10040  cd free-react-tailwind-admin-dashboard-main
10041  cd frontend
10042  yarn dev
10043  code .
10044  htop
10045  cd frontend
10046  npm i axios
10047  yarn add zustand
10048  yarn install; yarn dev
10049  yarn cache clean\nrm -rf node_modules\nyarn install\n
10050  yarn dev
10051  yarn add jsvectormap\n
10052  yarn dev
10053  code .
10054  ls
10055  cd subtl_frontend
10056  yarn dev
10057  git status
10058  git add .
10059  git commit -m "updated tests"
10060  git add .
10061  git commit -m "updated tests"
10062  git pull
10063  git commit -m "updated tests"
10064  git status
10065  cd ..
10066  git add .
10067  git commit -m "updated tests"
10068  git checkout -b ui-update
10069  cd subtl_frontend
10070  yarn dev
10071  code .
10072  yarn dev
10073  code .
10074  git pull origin subtl-api-v2\n
10075  cd subtl_frontend
10076  code .
10077  git checkout ui-update
10078  yarn dev
10079  ls -al
10080  rm -rf .git
10081  ls
10082  git status
10083  git add .
10084  git commit -m "updated font family"
10085  git push -u origin ui-update
10086  code .
10087  python -m venv venv\n
10088  source venv/bin/activate
10089  touch export.py
10090  /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
10091  python -u "/media/chirag/DATA12/subtl.ai/models onnx/export.py"
10092  pip install transformers torch
10093  sudo docker system prune -f\n
10094  dpkg -l | grep -i docker\n
10095  sudo dpkg -l | grep -i docker\n
10096  sudo apt-get purge -y docker-engine docker docker.io docker-ce docker-ce-cli docker-compose-plugin\nsudo apt-get autoremove -y --purge docker-engine docker docker.io docker-ce docker-compose-plugin\n
10097  pip freeze > requirements.txt\n
10098  source venv/bin/activate
10099  sudo rm -rf /var/lib/docker /etc/docker\nsudo rm /etc/apparmor.d/docker\nsudo groupdel docker\nsudo rm -rf /var/run/docker.sock\nsudo rm -rf /var/lib/containerd\nsudo rm -r ~/.docker
10100  sudo groupdel docker
10101  sudo rm -rf /var/run/docker.sock
10102  sudo rm -rf /var/lib/containerd
10103  sudo rm -r ~/.docker
10104  pip install transformers torch
10105  code .
10106  htop
10107  python -u "/media/chirag/DATA12/subtl.ai/models onnx/export.py"
10108  pip install onnx
10109  python -u "/media/chirag/DATA12/subtl.ai/models onnx/export.py"
10110  code .
10111  history > his1.txt
10112  ^[[200~sudo apt install docker.io~
10113  sudo apt install docker.io
10114  docker compose --help
10115  docker-compose
10116  docker-compose --version
10117  sudo docker compose up -d --force-recreate
10118  curl -SL https://github.com/docker/compose/releases/download/v2.29.2/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose
10119  sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
10120  sudo curl -SL https://github.com/docker/compose/releases/download/v2.29.2/docker-compose-linux-x86_64 -o /usr/local/bin/docker-compose
10121  sudo ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose
10122  docker compose --version
10123  docker-compose --version
10124  docker compose up
10125  docker-compose up
10126  docker ps
10127  sudo docker ps
10128  sudo docker ps -a
10129  sudo docker compose up
10130  sudo docker-compose up
10131  sudo apt-get install docker-compose-plugin
10132  sudo docker compose up
10133  sudo docker ps
10134  sudo docker network create traefik-public\n
10135  sudo docker ps
10136  sudo docker compose up
10137  sudo docker ps
10138  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10139  sudo docker restart full-stack-fastapi-template-backend-1
10140  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10141  cs frontend
10142  cd frontend
10143  yarn dev
10144  yarn install; yarn dev
10145  cd frontend
10146  yarn install; 
10147  yarn dev
10148  yarn add jsvectormap\n
10149  yarn dev
10150  sudo docker exec -it full-stack-fastapi-template-backend-1 /bin/bash
10151  cd frontend
10152  npm install react-select\n
10153  code .
10154  yarn dev
10155  git checkout subtl-api-v2
10156  git stash
10157  git checkout subtl-api-v2
10158  git pull origin subtl-api-v2\n
10159  git checkout ui-update
10160  git pull
10161  thop
10162  htop
10163  code .
10164  sudo docker ps
10165  sudo docker compose up -d
10166  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10167  cd frontend
10168  yarn dev
10169  sudo docker exec -it full-stack-fastapi-template-backend-1 /bin/bash
10170  cd frontend
10171  npm install @mui/material @emotion/react @emotion/styled\n
10172  npm install @mui/icons-material\n
10173  npm install @mui/x-data-grid\n
10174  sudo docker exec -it full-stack-fastapi-template-backend-1 /bin/bash
10175  code .
10176  git stash
10177  git checkout subtl-api-v2
10178  git status .
10179  git add .
10180  git commit -m "changed config"
10181  git push -u origin subtl-api-v2
10182  python -u "/media/chirag/DATA12/ANLP/2021101100_assignment1/script.py"
10183  tree
10184  code .
10185  sudo docker ps
10186  sudo docker compose up -d
10187  cd frontend
10188  yarn dev
10189  code .
10190  clear
10191  sudo docker compose up -d
10192  yarn dev
10193  code .
10194  clear
10195  yarn dev
10196  code .
10197  cd subtl_llm
10198  git status .
10199  git add .
10200  git commit -m "updated qa prompt to avoid ref"
10201  git push -u origin subtl-api-v2
10202  git pull
10203  git push -u origin subtl-api-v2
10204  code .
10205  clear
10206  cd ..
10207  ls
10208  cd subtl_frontend
10209  yarn dev
10210  git pull
10211  git status 
10212  git add subtl_api/app/helpers/workspace.py
10213  git commit -m "fixed invite issue"
10214  git push -u origin subtl-api-v2
10215  git status 
10216  git add subtl_api/app/helpers/workspace.py
10217  git commit -m "fixed invite issue"
10218  git push -u origin subtl-api-v2
10219  code .
10220  clear
10221  sudo docker compose up -d
10222  clear
10223  yarn dev
10224  sudo docker exec -it full-stack-fastapi-template-backend-1 /bin/bash
10225  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10226  sudo docker compose up -d
10227  git status 
10228  ls
10229  git init
10230  git status 
10231  git add .
10232  git commit -m "first commit"
10233  git push -u origin master
10234  git remote add origin https://github.com/chir263/conllu.git\ngit branch -M main\ngit push -u origin master
10235  git remote add origin https://github.com/chir263/conllu.git\ngit branch -M main\ngit push -u origin main
10236  yarn dev
10237  history > his1.txt
10238  code his1.txt
10239  code .
10240  clear
10241  yarn dev
10242  git pull
10243  git checkout ui-update
10244  git pull
10245  git pull origin ui-update
10246  git checkout -b invite-link
10247  yarn dev
10248  clear
10249  cd subtl_frontend
10250  npm install react-router-dom\n
10251  sudo ./run.sh -d -- up --build -d --force-recreate api_v2
10252  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
10253  sudo lsof -i :80
10254  sudo systemctl stop apache2
10255  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
10256  sudo ./run.sh logs --tail 1000 -f api_v2\n
10257  sudo ./run.sh -d -- up --build -d --force-recreate api_v2 nginx
10258  sudo ./run.sh logs --tail 1000 -f api_v2\n
10259  sudo docker exec -it subtl_bot-api_v2-1 /bin/bash\n
10260  git status 
10261  git add .
10262  git commit -m "added invite"
10263  git push -u origin invite-link
10264  yarn dev
10265  sudo ./run.sh logs --tail 1000 -f api_v2\n
10266  git status 
10267  git push -u origin invite-link
10268  sudo systemctl restart NetworkManager
10269  sudo systemctl stop NetworkManager\nsudo systemctl start NetworkManager\n
10270  sudo rm /etc/NetworkManager/NetworkManager.conf\nsudo systemctl restart NetworkManager\n
10271  nmcli connection show\n
10272  sudo nmcli connection delete <connection-name>\n
10273  sudo dpkg-reconfigure network-manager\n
10274  ip a\n
10275  sudo reboot\n
10276  tree
10277  code .
10278  sudo docker compose up -d
10279  cd frontend
10280  git origin\n
10281  yarn dev\n
10282  sudo lsof -i :5432\n
10283  sudo kill -9 1396
10284  sudo docker compose up -d
10285  git clone https://github.com/hkproj/pytorch-transformer.git
10286  git clone https://github.com/advin4603/Transformer-From-Scratch.git
10287  code .
10288  python -u "/media/chirag/DATA13/ANLP/ASSIGNMENT 2/Transformer-From-Scratch/script.py"
10289  touch README.md
10290  git clone https://github.com/shu7bh/Contract-NLI.git
10291  code .
10292  clear
10293  sudo docker compose up -d
10294  clear
10295  yarn dev\n
10296  sudo docker compose up -d
10297  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10298  sudo docker exec -it subtl_bot-api_v2-1 /bin/bash\n
10299  clear\n
10300  sudo docker ps
10301  sudo docker exec -it full-stack-fastapi-template-db-1 /bin/bash
10302  docker ps
10303  sudo docker ps
10304  sudo docker exec -it full-stack-fastapi-template-backend-1 /bin/bash
10305  /bin/python3.9
10306  yarn dev\n
10307  sudo rm -rf .
10308  sudo rm -rf 
10309  sudo rm -rf 7f211a7a-3443-4a2e-adbc-2e983a69cbe7_country-03.svg
10310  sudo rm -rf ${ls}
10311  ls | sudo rm -rf 
10312  ls
10313  ls | sudo rm -rf 
10314  sudo rm -rf $(ls)
10315  git status 
10316  git add .
10317  git commit -m "added multi lang support"
10318  code .
10319  cd "/media/chirag/DATA13/hydro/assign 2/" && gcc -framework Cocoa inflow.m -o inflow && "/media/chirag/DATA13/hydro/assign 2/"inflow
10320  cd
10321  ls
10322  code .
10323  pip install rasterio
10324  code .
10325  ls
10326  python3 BRED_PROJECT.py
10327  pip installl xgboost
10328  pip install xgboost
10329  pwd
10330  code .
10331  sudo docker compose up -d
10332  cd frontend
10333  yarn dev\n
10334  code .
10335  yarn dev\n
10336  sudo docker logs -f --tail 100 full-stack-fastapi-template-backend-1
10337  cd backend/app/files
10338  ls
10339  sudo rm -rf $(ls)
10340  sudo docker exec -it full-stack-fastapi-template-backend-1 /bin/bash
10341  sudo docker compose up -d
10342  git clone https://github.com/parameshkrishnaa/NER-Annotation.git
10343  code .
10344  git clone https://github.com/parameshkrishnaa/NER-Annotation.git
10345  code .
10346  npm start
10347  npm i; npm start
10348  npm i react-router-dom
10349  npm i axios
10350  npm i; npm start
10351  sudo docker compose up -d
10352  sudo docker exec -it full-stack-fastapi-template-backend-1 /bin/bash
10353  git status 
10354  git checkout -b integration-branch
10355  git add .
10356  git commit -m "added integration"
10357  git push -u origin integration-branch
10358  npm i; npm start
10359  touch code.py
10360  touch README.md
10361  code .
10362  clear\n
10363  sudo docker exec -it full-stack-fastapi-template-backend-1 /bin/bash
10364  sudo docker compose up -d
10365  clear\n
10366  yarn dev\n
10367  code .
10368  ls
10369  npm start
10370  code .
10371  ls
10372  ls -al
10373  rm -rf .git
10374  git status 
10375  code .
10376  git clone https://github.com/shu7bh/Contract-NLI.git
10377  code .
10378  git status 
10379  ls
10380  cd Contract-NLI
10381  git status 
10382  git clone https://github.com/patanjali-b/Contract-NLI.git
10383  code .
10384  ls
10385  python -m venv venv\n
10386  source venv/bin/activate
10387  pip install -r requirements.txt
10388  python app.py
10389  source venv/bin/activate
10390  cd helpers
10391  ls
10392  python hydrological_data.py
10393  pip install numpy
10394  python hydrological_data.py
10395  pip install geopandas
10396  python hydrological_data.py
10397  pip install rasterio
10398  python hydrological_data.py
10399  pip install matplotlib
10400  python hydrological_data.py
10401  pip install skimage
10402  pip install scikit-image
10403  python hydrological_data.py
10404  source venv/bin/activate
10405  pip install -r requirements.txt
10406  python hydrological_data.py
10407  deactivate
10408  rm -rf venv\n
10409  python3.10 -m venv venv\n
10410  sudo apt install python3.10 python3.10-venv python3.10-dev -y\n
10411  python3 -m venv venv
10412  source venv/bin/activate
10413  pip install -r requirements.txt
10414  source venv/bin/activate
10415  cd ..
10416  source venv/bin/activate
10417  cd helpers
10418  ls
10419  python hydrological_data.py
10420  pip install numpy>=1.24.0 geopandas>=0.13.0 rasterio>=1.3.0 matplotlib>=3.7.0 scikit-image>=0.21.0 scipy>=1.10.0 fiona>=1.9.0 shapely>=2.0.0 pyproj>=3.0.0
10421  pip install numpy\npip install geopandas\npip install rasterio\npip install matplotlib\npip install scikit-image\npip install scipy\npip install fiona\npip install shapely\npip install pyproj
10422  pip install -r requirements.txt
10423  python hydrological_data.py
10424  pip install -r requirements.txt
10425  python hydrological_data.py
10426  clear\n
10427  python hydrological_data.py
10428  clear\n
10429  python app.py
10430  source venv/bin/activate
10431  python app.py
10432  pip install -r requirements.txt
10433  python app.py
10434  pip install -r requirements.txt
10435  python app.py
10436  echo "# hydro-backend" >> README.md\ngit init\ngit add README.md\ngit commit -m "first commit"\ngit branch -M main\ngit remote add origin https://github.com/chir263/hydro-backend.git\ngit push -u origin main
10437  git status 
10438  git add .
10439  git commit -m "added integration"
10440  git push -u origin main
10441  clear\n
10442  python app.py
10443  git clone https://github.com/Yashpal-0/HMSD-Project.git
10444  code .
10445  npm i; npm start
10446  source venv/bin/activate
10447  pip install pip install flask-cors\n
10448  pip install \ flask-cors\n
10449  rim -rf .git
10450  rm -rf .git
10451  git status 
10452  git add .
10453  git commit -m "added FE"
10454  git push -u origin main
10455  code Repo.md
10456  code .
10457  source venv/bin/activate
10458  python app.py
10459* /bin/python /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/printEnvVariablesToFile.py /home/chirag/.vscode/extensions/ms-python.python-2024.2.1/pythonFiles/deactivate/zsh/envVars.txt
10460  python app.py
10461  deactivate
10462  python app.py
10463  source venv/bin/activate
10464  python3 app.py
10465  pip install flask_restx
10466  python3 app.py
